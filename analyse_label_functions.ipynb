{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 00:12:55,180][INFO] fonduer.meta:49 - Setting logging directory to: /tmp/2023-07-05_00-12-55\n",
      "[2023-07-05 00:12:55,389][INFO] fonduer.candidates.mentions:467 - Clearing table: name_abbr\n",
      "[2023-07-05 00:13:11,849][INFO] fonduer.candidates.mentions:467 - Clearing table: name_full\n",
      "[2023-07-05 00:13:11,882][INFO] fonduer.candidates.mentions:467 - Clearing table: task\n",
      "[2023-07-05 00:13:12,046][INFO] fonduer.candidates.mentions:467 - Clearing table: all_authors\n",
      "[2023-07-05 00:13:12,053][INFO] fonduer.candidates.mentions:475 - Cascading to clear table: name_full_abbr\n",
      "[2023-07-05 00:13:12,871][INFO] fonduer.candidates.mentions:475 - Cascading to clear table: all_authors_task\n",
      "[2023-07-05 00:13:12,874][INFO] fonduer.candidates.mentions:475 - Cascading to clear table: name_abbr_task\n",
      "[2023-07-05 00:13:13,142][INFO] fonduer.utils.udf:67 - Running UDF...\n",
      " 30%|████████████▉                              | 12/40 [03:38<11:15, 24.14s/it]"
     ]
    }
   ],
   "source": [
    "!python bio-medrxiv.py marctestzwei -M -C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "from fonduer.supervision.models import GoldLabel\n",
    "from fonduer.features import Featurizer\n",
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from fonduer.supervision.models import LabelKey\n",
    "\n",
    "from MeMoKBC.pipeline.utils import get_session, load_candidates, match_label_matrix\n",
    "from MeMoKBC.definitions.candidates import NameFullAbbr, NameAbbrTask\n",
    "from MeMoKBC.pipeline.lfs.name_short_long_lfs import short_long_lfs\n",
    "from MeMoKBC.pipeline.lfs.name_short_task_lfs import name_abbr_task_lfs\n",
    "from MeMoKBC.gold_label_matcher import match_gold_label\n",
    "from importlib import reload\n",
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-04 23:42:08,689][INFO] fonduer.meta:134 - Connecting user:postgres to fonduer-postgres-dev:5432/marctestzwei\n",
      "[2023-07-04 23:42:08,692][INFO] fonduer.meta:162 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "session = get_session(db_name=\"marctestzwei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define candidates and Labeler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [NameFullAbbr, NameAbbrTask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Goldlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-04 23:42:12,406][INFO] fonduer.meta:134 - Connecting user:postgres to fonduer-postgres-dev:5432/marctestzwei\n",
      "[2023-07-04 23:42:12,407][INFO] fonduer.meta:162 - Initializing the storage schema\n",
      "[2023-07-04 23:42:12,555][INFO] root:88 - Found relations for 22 documents\n",
      "[2023-07-04 23:42:12,746][INFO] root:93 - Found 6820 candidates for <class 'fonduer.candidates.models.candidate.NameAbbrTask'>\n",
      "[2023-07-04 23:42:13,268][INFO] root:93 - Found 28105 candidates for <class 'fonduer.candidates.models.candidate.NameFullAbbr'>\n",
      "[2023-07-04 23:42:13,686][INFO] root:102 - Found candidates for 40 documents\n"
     ]
    }
   ],
   "source": [
    "# Load goldlabels from json file and compare to candidates in database\n",
    "gold_labels = match_gold_label(\n",
    "    \"marctestzwei\",\n",
    "    \"/data/Goldlabel_biomedRxiv/goldlabel1_docs801-840_laura/goldlabel_authorlong_short_task_medRxiv.json\",\n",
    "    [NameAbbrTask, NameFullAbbr]\n",
    ")\n",
    "\n",
    "# filter potential goldlabels after candidate class\n",
    "nat_cands = []\n",
    "nfa_cands = []\n",
    "for cand in gold_labels:\n",
    "    if type(cand) == NameAbbrTask:\n",
    "        # remove candidates where short and long name are not in the same sentence\n",
    "        if cand[0].context.sentence.id == cand[1].context.sentence.id:\n",
    "            # append the id of the candidate to the list\n",
    "            nat_cands.append(cand.id)\n",
    "    elif type(cand) == NameFullAbbr:\n",
    "        # append the id of the candidate to the list\n",
    "        nfa_cands.append(cand.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/fonduer/utils/utils_udf.py:217: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n",
      "[2023-07-04 23:42:27,776][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 0)\n",
      "/usr/local/lib/python3.8/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "[2023-07-04 23:42:27,785][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9cf481bad344b2b78f32502d80f15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create labeler object\n",
    "labeler = Labeler(session, candidates)\n",
    "\n",
    "# write function that returns gold label for a candidate\n",
    "def gold(c: Candidate) -> int:\n",
    "\n",
    "    if type(c) == NameAbbrTask:\n",
    "\n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nat_cands:\n",
    "            return 1\n",
    "\n",
    "    elif type(c) == NameFullAbbr:\n",
    "        \n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nfa_cands:\n",
    "            return 1\n",
    "\n",
    "    # if the candidate id is not inside the list of goldlabel candidate id's return FALSE\n",
    "    return 0\n",
    "\n",
    "# Apply the gold label function for each candidate class\n",
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidates\n",
    "train_cands = load_candidates(session, 0, candidates)\n",
    "\n",
    "# match the candidates with the outcome of the labeling functions to generate input for the label model\n",
    "L_train_NFA, L_train_NAT = match_label_matrix(session, candidates, 0) \n",
    "\n",
    " # load gold labels list\n",
    "L_gold_train_NFA, L_gold_train_NAT = labeler.get_gold_labels(train_cands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameFull + Abrreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check_all_uppercase_letters</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.238114</td>\n",
       "      <td>0.238114</td>\n",
       "      <td>0.237132</td>\n",
       "      <td>134</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.110561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_horizont_abr_short</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_long_name_not_upper</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.965422</td>\n",
       "      <td>0.510413</td>\n",
       "      <td>0.510413</td>\n",
       "      <td>4780</td>\n",
       "      <td>134</td>\n",
       "      <td>0.972731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.143811</td>\n",
       "      <td>131</td>\n",
       "      <td>606</td>\n",
       "      <td>0.177748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters_short_in_long</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.143811</td>\n",
       "      <td>131</td>\n",
       "      <td>606</td>\n",
       "      <td>0.177748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_full_in_top_percentile_sentence_wise</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.260118</td>\n",
       "      <td>0.256974</td>\n",
       "      <td>0.255796</td>\n",
       "      <td>0</td>\n",
       "      <td>1324</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_short_outside_half_percentile_sentence_wise</th>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_letter_count</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.069745</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.066994</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.098232</td>\n",
       "      <td>0.095874</td>\n",
       "      <td>0.095481</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  j Polarity  Coverage  \\\n",
       "check_all_uppercase_letters                       0      [1]  0.238114   \n",
       "check_horizont_abr_short                          1       []  0.000000   \n",
       "check_long_name_not_upper                         2      [0]  0.965422   \n",
       "check_uppercase_letters                           3      [1]  0.144794   \n",
       "check_uppercase_letters_short_in_long             4      [1]  0.144794   \n",
       "name_full_in_top_percentile_sentence_wise         5      [1]  0.260118   \n",
       "name_short_outside_half_percentile_sentence_wise  6       []  0.000000   \n",
       "small_letter_count                                7      [1]  0.069745   \n",
       "word_count                                        8      [1]  0.098232   \n",
       "\n",
       "                                                  Overlaps  Conflicts  \\\n",
       "check_all_uppercase_letters                       0.238114   0.237132   \n",
       "check_horizont_abr_short                          0.000000   0.000000   \n",
       "check_long_name_not_upper                         0.510413   0.510413   \n",
       "check_uppercase_letters                           0.144794   0.143811   \n",
       "check_uppercase_letters_short_in_long             0.144794   0.143811   \n",
       "name_full_in_top_percentile_sentence_wise         0.256974   0.255796   \n",
       "name_short_outside_half_percentile_sentence_wise  0.000000   0.000000   \n",
       "small_letter_count                                0.068173   0.066994   \n",
       "word_count                                        0.095874   0.095481   \n",
       "\n",
       "                                                  Correct  Incorrect  \\\n",
       "check_all_uppercase_letters                           134       1078   \n",
       "check_horizont_abr_short                                0          0   \n",
       "check_long_name_not_upper                            4780        134   \n",
       "check_uppercase_letters                               131        606   \n",
       "check_uppercase_letters_short_in_long                 131        606   \n",
       "name_full_in_top_percentile_sentence_wise               0       1324   \n",
       "name_short_outside_half_percentile_sentence_wise        0          0   \n",
       "small_letter_count                                      0        355   \n",
       "word_count                                              0        500   \n",
       "\n",
       "                                                  Emp. Acc.  \n",
       "check_all_uppercase_letters                        0.110561  \n",
       "check_horizont_abr_short                           0.000000  \n",
       "check_long_name_not_upper                          0.972731  \n",
       "check_uppercase_letters                            0.177748  \n",
       "check_uppercase_letters_short_in_long              0.177748  \n",
       "name_full_in_top_percentile_sentence_wise          0.000000  \n",
       "name_short_outside_half_percentile_sentence_wise   0.000000  \n",
       "small_letter_count                                 0.000000  \n",
       "word_count                                         0.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NFA,\n",
    "    lfs=sorted(short_long_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NFA.reshape(-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameAbbr + Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_medical_abbreviation</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1627</td>\n",
       "      <td>109</td>\n",
       "      <td>0.937212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_length_more_than_three_words</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_name_short_in_first_words</th>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "is_medical_abbreviation          0      [0]  1.000000  0.020737        0.0   \n",
       "lf_length_more_than_three_words  1      [0]  0.020737  0.020737        0.0   \n",
       "lf_name_short_in_first_words     2       []  0.000000  0.000000        0.0   \n",
       "\n",
       "                                 Correct  Incorrect  Emp. Acc.  \n",
       "is_medical_abbreviation             1627        109   0.937212  \n",
       "lf_length_more_than_three_words       36          0   1.000000  \n",
       "lf_name_short_in_first_words           0          0   0.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NAT,\n",
    "    lfs=sorted(name_abbr_task_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NAT.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
