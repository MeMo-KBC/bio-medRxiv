{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-07-05 01:11:02,265][INFO] fonduer.meta:49 - Setting logging directory to: /tmp/2023-07-05_01-11-02\n",
      "[2023-07-05 01:11:02,399][INFO] fonduer.supervision.labeler:358 - Clearing ALL Labels and LabelKeys.\n",
      "/usr/local/lib/python3.8/site-packages/fonduer/utils/utils_udf.py:217: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n",
      "[2023-07-05 01:11:02,878][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 0)\n",
      "/usr/local/lib/python3.8/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "[2023-07-05 01:11:02,889][INFO] fonduer.utils.udf:67 - Running UDF...\n",
      "100%|███████████████████████████████████████████| 14/14 [00:04<00:00,  3.50it/s]\n",
      "[2023-07-05 01:11:07,205][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 1)\n",
      "[2023-07-05 01:11:07,211][INFO] fonduer.utils.udf:67 - Running UDF...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:07<00:00,  1.67it/s]\n",
      "[2023-07-05 01:11:15,396][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 2)\n",
      "[2023-07-05 01:11:15,405][INFO] fonduer.utils.udf:67 - Running UDF...\n",
      "100%|███████████████████████████████████████████| 13/13 [00:08<00:00,  1.56it/s]\n",
      "Applied label functions\n"
     ]
    }
   ],
   "source": [
    "!python bio-medrxiv.py marctestzwei -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "from fonduer.supervision.models import GoldLabel\n",
    "from fonduer.features import Featurizer\n",
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from fonduer.supervision.models import LabelKey\n",
    "\n",
    "from MeMoKBC.pipeline.utils import get_session, load_candidates, match_label_matrix\n",
    "from MeMoKBC.definitions.candidates import NameFullAbbr, NameAbbrTask\n",
    "from MeMoKBC.pipeline.lfs.name_short_long_lfs import short_long_lfs\n",
    "from MeMoKBC.pipeline.lfs.name_short_task_lfs import name_abbr_task_lfs\n",
    "from MeMoKBC.gold_label_matcher import match_gold_label\n",
    "from importlib import reload\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 01:11:29,499][INFO] fonduer.meta:134 - Connecting user:postgres to fonduer-postgres-dev:5432/marctestzwei\n",
      "[2023-07-05 01:11:29,501][INFO] fonduer.meta:162 - Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "session = get_session(db_name=\"marctestzwei\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define candidates and Labeler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [NameFullAbbr, NameAbbrTask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRUE = 1\n",
    "ABSTAIN = 0\n",
    "\n",
    "def lf_name_short_in_first_words(c):\n",
    "    name_abbr, task = c\n",
    "    name = name_abbr.context.get_span()\n",
    "    sentence = re.sub(r'[^\\w\\s]', '', task.context.get_span())\n",
    "    first_words = re.findall(r'\\b\\w+\\b', sentence)[:3]\n",
    "\n",
    "    for word in first_words:\n",
    "        if word.isupper() and word == name:\n",
    "            return TRUE\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NameAbbrTask(NameAbbr(SpanMention(\"SPARSEMODr\", sentence=14843, chars=[0,9], words=[0,0])), Task(SpanMention(\"This corresponds with the release of version 1.2.0 of SPARSEMODr, which encapsulates technical changes requested by reviewers.\", sentence=23515, chars=[0,125], words=[0,18])))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cands = session.query(NameAbbrTask).all()\n",
    "cands[10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NameAbbrTask(NameAbbr(SpanMention(\"RNA\", sentence=22781, chars=[27,29], words=[5,5])), Task(SpanMention(\"D) The estimated infection incidence per day from normalized RNA concentrations (top), case reports (middle) and testing-adjusted cases (bottom).\", sentence=32532, chars=[0,144], words=[0,29])))\n",
      "0\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"SNPs\", sentence=47926, chars=[100,103], words=[18,18])), Task(SpanMention(\"For human studies between 1 and 10 million SNPs are usually considered, and in most GWAS, each SNP is tested independently for correlation with the phenotype.\", sentence=47530, chars=[0,157], words=[0,28])))\n",
      "0\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"LW\", sentence=12769, chars=[0,1], words=[0,0])), Task(SpanMention(\"LW, AS and DF conceived and designed the study.\", sentence=12769, chars=[0,46], words=[0,10])))\n",
      "1\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"DF\", sentence=14294, chars=[0,1], words=[0,0])), Task(SpanMention(\"DF launched the study and contributed to its original concept and design.\", sentence=14294, chars=[0,72], words=[0,12])))\n",
      "1\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"SNPs\", sentence=47926, chars=[100,103], words=[18,18])), Task(SpanMention(\"By now, thousands of such GWAS have been conducted that identified a plethora of statistically significant associations of SNPs with complex traits.\", sentence=47539, chars=[0,147], words=[0,23])))\n",
      "0\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"SPARSEMODr\", sentence=20686, chars=[0,9], words=[0,0])), Task(SpanMention(\"This corresponds with the release of version 1.2.0 of SPARSEMODr, which encapsulates technical changes requested by reviewers.\", sentence=23515, chars=[0,125], words=[0,18])))\n",
      "0\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"MRI\", sentence=14730, chars=[98,100], words=[19,19])), Task(SpanMention(\"B.H. - MRI data analysis.\", sentence=16375, chars=[0,24], words=[0,5])))\n",
      "1\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"LW\", sentence=12769, chars=[0,1], words=[0,0])), Task(SpanMention(\"LW analysed the data and wrote the first draft.\", sentence=12777, chars=[0,46], words=[0,9])))\n",
      "1\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"SNPs\", sentence=47926, chars=[100,103], words=[18,18])), Task(SpanMention(\"For most traits-in particular complex diseases or their risk factors that have been assessed in very large cohorts (100K or more subjects)-hundreds of SNPs usually turn out to be significant, even after stringent correction for multiple hypotheses testing.\", sentence=47546, chars=[0,255], words=[0,43])))\n",
      "0\n",
      "NameAbbrTask(NameAbbr(SpanMention(\"SIRS\", sentence=43752, chars=[102,105], words=[18,18])), Task(SpanMention(\"AG, KG, TK, and ES conceived the VAP-SIRS model - with input and feedback on the model and results from TC, GG, MP, EP and MR.\", sentence=55210, chars=[0,125], words=[0,34])))\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "i = 100\n",
    "while i<110:\n",
    "    output = lf_name_short_in_first_words(cands[i])\n",
    "    print(cands[i])\n",
    "    print(output)\n",
    "    i = i+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Goldlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-05 01:11:40,299][INFO] fonduer.meta:134 - Connecting user:postgres to fonduer-postgres-dev:5432/marctestzwei\n",
      "[2023-07-05 01:11:40,300][INFO] fonduer.meta:162 - Initializing the storage schema\n",
      "[2023-07-05 01:11:40,464][INFO] root:88 - Found relations for 22 documents\n",
      "[2023-07-05 01:11:40,542][INFO] root:93 - Found 6820 candidates for <class 'fonduer.candidates.models.candidate.NameAbbrTask'>\n",
      "[2023-07-05 01:11:41,179][INFO] root:93 - Found 28105 candidates for <class 'fonduer.candidates.models.candidate.NameFullAbbr'>\n",
      "[2023-07-05 01:11:41,582][INFO] root:102 - Found candidates for 40 documents\n"
     ]
    }
   ],
   "source": [
    "# Load goldlabels from json file and compare to candidates in database\n",
    "gold_labels = match_gold_label(\n",
    "    \"marctestzwei\",\n",
    "    \"/data/Goldlabel_biomedRxiv/goldlabel1_docs801-840_laura/goldlabel_authorlong_short_task_medRxiv.json\",\n",
    "    [NameAbbrTask, NameFullAbbr]\n",
    ")\n",
    "\n",
    "# filter potential goldlabels after candidate class\n",
    "nat_cands = []\n",
    "nfa_cands = []\n",
    "for cand in gold_labels:\n",
    "    if type(cand) == NameAbbrTask:\n",
    "        # remove candidates where short and long name are not in the same sentence\n",
    "        if cand[0].context.sentence.id == cand[1].context.sentence.id:\n",
    "            # append the id of the candidate to the list\n",
    "            nat_cands.append(cand.id)\n",
    "    elif type(cand) == NameFullAbbr:\n",
    "        # append the id of the candidate to the list\n",
    "        nfa_cands.append(cand.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/fonduer/utils/utils_udf.py:217: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n",
      "[2023-07-05 01:11:56,576][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 0)\n",
      "/usr/local/lib/python3.8/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "[2023-07-05 01:11:56,627][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd864e98275e45eeb102ad9060fd672f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create labeler object\n",
    "labeler = Labeler(session, candidates)\n",
    "\n",
    "# write function that returns gold label for a candidate\n",
    "def gold(c: Candidate) -> int:\n",
    "\n",
    "    if type(c) == NameAbbrTask:\n",
    "\n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nat_cands:\n",
    "            return 1\n",
    "\n",
    "    elif type(c) == NameFullAbbr:\n",
    "        \n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nfa_cands:\n",
    "            return 1\n",
    "\n",
    "    # if the candidate id is not inside the list of goldlabel candidate id's return FALSE\n",
    "    return 0\n",
    "\n",
    "# Apply the gold label function for each candidate class\n",
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidates\n",
    "train_cands = load_candidates(session, 0, candidates)\n",
    "\n",
    "# match the candidates with the outcome of the labeling functions to generate input for the label model\n",
    "L_train_NFA, L_train_NAT = match_label_matrix(session, candidates, 0) \n",
    "\n",
    " # load gold labels list\n",
    "L_gold_train_NFA, L_gold_train_NAT = labeler.get_gold_labels(train_cands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameFull + Abrreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check_all_uppercase_letters</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.238114</td>\n",
       "      <td>0.238114</td>\n",
       "      <td>0.237132</td>\n",
       "      <td>134</td>\n",
       "      <td>1078</td>\n",
       "      <td>0.110561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_horizont_abr_short</th>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_long_name_not_upper</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.965422</td>\n",
       "      <td>0.510413</td>\n",
       "      <td>0.510413</td>\n",
       "      <td>4780</td>\n",
       "      <td>134</td>\n",
       "      <td>0.972731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.143811</td>\n",
       "      <td>131</td>\n",
       "      <td>606</td>\n",
       "      <td>0.177748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters_short_in_long</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.144794</td>\n",
       "      <td>0.143811</td>\n",
       "      <td>131</td>\n",
       "      <td>606</td>\n",
       "      <td>0.177748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_full_in_top_percentile_sentence_wise</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.260118</td>\n",
       "      <td>0.256974</td>\n",
       "      <td>0.255796</td>\n",
       "      <td>0</td>\n",
       "      <td>1324</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_short_outside_half_percentile_sentence_wise</th>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_letter_count</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.069745</td>\n",
       "      <td>0.068173</td>\n",
       "      <td>0.066994</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.098232</td>\n",
       "      <td>0.095874</td>\n",
       "      <td>0.095481</td>\n",
       "      <td>0</td>\n",
       "      <td>500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  j Polarity  Coverage  \\\n",
       "check_all_uppercase_letters                       0      [1]  0.238114   \n",
       "check_horizont_abr_short                          1       []  0.000000   \n",
       "check_long_name_not_upper                         2      [0]  0.965422   \n",
       "check_uppercase_letters                           3      [1]  0.144794   \n",
       "check_uppercase_letters_short_in_long             4      [1]  0.144794   \n",
       "name_full_in_top_percentile_sentence_wise         5      [1]  0.260118   \n",
       "name_short_outside_half_percentile_sentence_wise  6       []  0.000000   \n",
       "small_letter_count                                7      [1]  0.069745   \n",
       "word_count                                        8      [1]  0.098232   \n",
       "\n",
       "                                                  Overlaps  Conflicts  \\\n",
       "check_all_uppercase_letters                       0.238114   0.237132   \n",
       "check_horizont_abr_short                          0.000000   0.000000   \n",
       "check_long_name_not_upper                         0.510413   0.510413   \n",
       "check_uppercase_letters                           0.144794   0.143811   \n",
       "check_uppercase_letters_short_in_long             0.144794   0.143811   \n",
       "name_full_in_top_percentile_sentence_wise         0.256974   0.255796   \n",
       "name_short_outside_half_percentile_sentence_wise  0.000000   0.000000   \n",
       "small_letter_count                                0.068173   0.066994   \n",
       "word_count                                        0.095874   0.095481   \n",
       "\n",
       "                                                  Correct  Incorrect  \\\n",
       "check_all_uppercase_letters                           134       1078   \n",
       "check_horizont_abr_short                                0          0   \n",
       "check_long_name_not_upper                            4780        134   \n",
       "check_uppercase_letters                               131        606   \n",
       "check_uppercase_letters_short_in_long                 131        606   \n",
       "name_full_in_top_percentile_sentence_wise               0       1324   \n",
       "name_short_outside_half_percentile_sentence_wise        0          0   \n",
       "small_letter_count                                      0        355   \n",
       "word_count                                              0        500   \n",
       "\n",
       "                                                  Emp. Acc.  \n",
       "check_all_uppercase_letters                        0.110561  \n",
       "check_horizont_abr_short                           0.000000  \n",
       "check_long_name_not_upper                          0.972731  \n",
       "check_uppercase_letters                            0.177748  \n",
       "check_uppercase_letters_short_in_long              0.177748  \n",
       "name_full_in_top_percentile_sentence_wise          0.000000  \n",
       "name_short_outside_half_percentile_sentence_wise   0.000000  \n",
       "small_letter_count                                 0.000000  \n",
       "word_count                                         0.000000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NFA,\n",
    "    lfs=sorted(short_long_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NFA.reshape(-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameAbbr + Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>is_medical_abbreviation</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166475</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>1627</td>\n",
       "      <td>109</td>\n",
       "      <td>0.937212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_length_more_than_three_words</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_name_short_in_first_words</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>35</td>\n",
       "      <td>229</td>\n",
       "      <td>0.132576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "is_medical_abbreviation          0      [0]  1.000000  0.166475   0.152074   \n",
       "lf_length_more_than_three_words  1      [0]  0.020737  0.020737   0.006336   \n",
       "lf_name_short_in_first_words     2      [1]  0.152074  0.152074   0.152074   \n",
       "\n",
       "                                 Correct  Incorrect  Emp. Acc.  \n",
       "is_medical_abbreviation             1627        109   0.937212  \n",
       "lf_length_more_than_three_words       36          0   1.000000  \n",
       "lf_name_short_in_first_words          35        229   0.132576  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NAT,\n",
    "    lfs=sorted(name_abbr_task_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NAT.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
