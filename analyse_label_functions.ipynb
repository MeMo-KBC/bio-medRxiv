{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "from fonduer.supervision.models import GoldLabel\n",
    "from fonduer.features import Featurizer\n",
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "from fonduer.supervision.models import LabelKey\n",
    "\n",
    "from MeMoKBC.pipeline.utils import get_session, load_candidates, match_label_matrix\n",
    "from MeMoKBC.definitions.candidates import NameFullAbbr, NameAbbrTask\n",
    "from MeMoKBC.pipeline.lfs.name_short_long_lfs import short_long_lfs\n",
    "from MeMoKBC.pipeline.lfs.name_short_task_lfs import name_abbr_task_lfs\n",
    "from MeMoKBC.gold_label_matcher import match_gold_label\n",
    "from importlib import reload\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 20:22:15,436][INFO] fonduer.meta:49 - Setting logging directory to: /tmp/2023-07-06_20-22-15\n"
     ]
    }
   ],
   "source": [
    "session = get_session(db_name=\"pipeline6\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define candidates and Labeler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [NameFullAbbr, NameAbbrTask]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Goldlabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 20:22:15,662][INFO] fonduer.meta:134 - Connecting user:postgres to fonduer-postgres-dev:5432/pipeline6\n",
      "[2023-07-06 20:22:15,664][INFO] fonduer.meta:162 - Initializing the storage schema\n",
      "[2023-07-06 20:22:15,965][INFO] root:88 - Found relations for 22 documents\n",
      "[2023-07-06 20:22:16,323][INFO] root:93 - Found 6820 candidates for <class 'fonduer.candidates.models.candidate.NameAbbrTask'>\n",
      "[2023-07-06 20:22:16,886][INFO] root:93 - Found 28105 candidates for <class 'fonduer.candidates.models.candidate.NameFullAbbr'>\n",
      "[2023-07-06 20:22:17,300][INFO] root:102 - Found candidates for 40 documents\n"
     ]
    }
   ],
   "source": [
    "# Load goldlabels from json file and compare to candidates in database\n",
    "gold_labels = match_gold_label(\n",
    "    \"pipeline6\",\n",
    "    \"/data/Goldlabel_biomedRxiv/goldlabel1_docs801-840_laura/goldlabel_authorlong_short_task_medRxiv.json\",\n",
    "    [NameAbbrTask, NameFullAbbr]\n",
    ")\n",
    "\n",
    "# filter potential goldlabels after candidate class\n",
    "nat_cands = []\n",
    "nfa_cands = []\n",
    "for cand in gold_labels:\n",
    "    if type(cand) == NameAbbrTask:\n",
    "        # remove candidates where short and long name are not in the same sentence\n",
    "        if cand[0].context.sentence.id == cand[1].context.sentence.id:\n",
    "            # append the id of the candidate to the list\n",
    "            nat_cands.append(cand.id)\n",
    "    elif type(cand) == NameFullAbbr:\n",
    "        # append the id of the candidate to the list\n",
    "        nfa_cands.append(cand.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/fonduer/utils/utils_udf.py:217: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n",
      "[2023-07-06 20:22:31,295][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 0)\n",
      "/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "[2023-07-06 20:22:31,335][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1d8b1a423c4b8fb68eb3e0b8781bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 20:22:36,396][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 1)\n",
      "[2023-07-06 20:22:36,444][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b8ce4d6ad3a47cebfefcd8cd8417dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-06 20:22:43,418][INFO] fonduer.supervision.labeler:330 - Clearing Labels (split 2)\n",
      "[2023-07-06 20:22:43,482][INFO] fonduer.utils.udf:67 - Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be2969e17764ac4a93b8b4ad809a891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create labeler object\n",
    "labeler = Labeler(session, candidates)\n",
    "\n",
    "# write function that returns gold label for a candidate\n",
    "def gold(c: Candidate) -> int:\n",
    "    if type(c) == NameAbbrTask:\n",
    "\n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nat_cands:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    elif type(c) == NameFullAbbr:\n",
    "        \n",
    "        # check if the candidate id is inside the list of goldlabel candidate id's\n",
    "        if c.id in nfa_cands:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    # if the candidate id is not inside the list of goldlabel candidate id's return FALSE\n",
    "    return 0\n",
    "\n",
    "# Apply the gold label function for each candidate class\n",
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, split=0, clear=True)\n",
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, split=1)\n",
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load candidates\n",
    "train_cands = load_candidates(session, 0, candidates)\n",
    "\n",
    "# match the candidates with the outcome of the labeling functions to generate input for the label model\n",
    "L_train_NFA, L_train_NAT = match_label_matrix(session, candidates, 0) \n",
    "\n",
    " # load gold labels list\n",
    "L_gold_train_NFA, L_gold_train_NAT = labeler.get_gold_labels(train_cands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameFull + Abrreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>check_all_abbr_letters_in_long</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>4511</td>\n",
       "      <td>579</td>\n",
       "      <td>0.886248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_all_uppercase_letters</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.145187</td>\n",
       "      <td>0.145187</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>605</td>\n",
       "      <td>134</td>\n",
       "      <td>0.818674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_horizont_abr_short</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.001768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_long_name_not_upper</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.092731</td>\n",
       "      <td>0.092731</td>\n",
       "      <td>0.021611</td>\n",
       "      <td>472</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.132417</td>\n",
       "      <td>0.132417</td>\n",
       "      <td>0.131041</td>\n",
       "      <td>540</td>\n",
       "      <td>134</td>\n",
       "      <td>0.801187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>check_uppercase_letters_short_in_long</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.132417</td>\n",
       "      <td>0.132417</td>\n",
       "      <td>0.131041</td>\n",
       "      <td>540</td>\n",
       "      <td>134</td>\n",
       "      <td>0.801187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_full_in_top_percentile_sentence_wise</th>\n",
       "      <td>6</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>4956</td>\n",
       "      <td>134</td>\n",
       "      <td>0.973674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name_short_outside_half_percentile_sentence_wise</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.456974</td>\n",
       "      <td>0.456974</td>\n",
       "      <td>0.077996</td>\n",
       "      <td>2251</td>\n",
       "      <td>75</td>\n",
       "      <td>0.967756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small_letter_count</th>\n",
       "      <td>8</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.893713</td>\n",
       "      <td>0.893713</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>4415</td>\n",
       "      <td>134</td>\n",
       "      <td>0.970543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_count</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.977210</td>\n",
       "      <td>0.140079</td>\n",
       "      <td>4840</td>\n",
       "      <td>134</td>\n",
       "      <td>0.973060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  j Polarity  Coverage  \\\n",
       "check_all_abbr_letters_in_long                    0   [0, 1]  1.000000   \n",
       "check_all_uppercase_letters                       1      [0]  0.145187   \n",
       "check_horizont_abr_short                          2      [0]  0.001768   \n",
       "check_long_name_not_upper                         3      [0]  0.092731   \n",
       "check_uppercase_letters                           4      [0]  0.132417   \n",
       "check_uppercase_letters_short_in_long             5      [0]  0.132417   \n",
       "name_full_in_top_percentile_sentence_wise         6      [0]  1.000000   \n",
       "name_short_outside_half_percentile_sentence_wise  7      [0]  0.456974   \n",
       "small_letter_count                                8      [0]  0.893713   \n",
       "word_count                                        9      [0]  0.977210   \n",
       "\n",
       "                                                  Overlaps  Conflicts  \\\n",
       "check_all_abbr_letters_in_long                    1.000000   0.140079   \n",
       "check_all_uppercase_letters                       0.145187   0.140079   \n",
       "check_horizont_abr_short                          0.001768   0.000000   \n",
       "check_long_name_not_upper                         0.092731   0.021611   \n",
       "check_uppercase_letters                           0.132417   0.131041   \n",
       "check_uppercase_letters_short_in_long             0.132417   0.131041   \n",
       "name_full_in_top_percentile_sentence_wise         1.000000   0.140079   \n",
       "name_short_outside_half_percentile_sentence_wise  0.456974   0.077996   \n",
       "small_letter_count                                0.893713   0.140079   \n",
       "word_count                                        0.977210   0.140079   \n",
       "\n",
       "                                                  Correct  Incorrect  \\\n",
       "check_all_abbr_letters_in_long                       4511        579   \n",
       "check_all_uppercase_letters                           605        134   \n",
       "check_horizont_abr_short                                9          0   \n",
       "check_long_name_not_upper                             472          0   \n",
       "check_uppercase_letters                               540        134   \n",
       "check_uppercase_letters_short_in_long                 540        134   \n",
       "name_full_in_top_percentile_sentence_wise            4956        134   \n",
       "name_short_outside_half_percentile_sentence_wise     2251         75   \n",
       "small_letter_count                                   4415        134   \n",
       "word_count                                           4840        134   \n",
       "\n",
       "                                                  Emp. Acc.  \n",
       "check_all_abbr_letters_in_long                     0.886248  \n",
       "check_all_uppercase_letters                        0.818674  \n",
       "check_horizont_abr_short                           1.000000  \n",
       "check_long_name_not_upper                          1.000000  \n",
       "check_uppercase_letters                            0.801187  \n",
       "check_uppercase_letters_short_in_long              0.801187  \n",
       "name_full_in_top_percentile_sentence_wise          0.973674  \n",
       "name_short_outside_half_percentile_sentence_wise   0.967756  \n",
       "small_letter_count                                 0.970543  \n",
       "word_count                                         0.973060  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NFA,\n",
    "    lfs=sorted(short_long_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NFA.reshape(-1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameAbbr + Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abbr_is_complete</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.190668</td>\n",
       "      <td>0.190668</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common_verbs_following_abbr</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>0.288889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_medical_abbreviation</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459101</td>\n",
       "      <td>0.253456</td>\n",
       "      <td>1627</td>\n",
       "      <td>109</td>\n",
       "      <td>0.937212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_length_more_than_three_words</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.020737</td>\n",
       "      <td>0.010369</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lf_name_short_in_first_words</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>0.152074</td>\n",
       "      <td>35</td>\n",
       "      <td>229</td>\n",
       "      <td>0.132576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_beginning</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.120392</td>\n",
       "      <td>0.120392</td>\n",
       "      <td>0.120392</td>\n",
       "      <td>44</td>\n",
       "      <td>165</td>\n",
       "      <td>0.210526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verbs_ending_with_past</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>0.047811</td>\n",
       "      <td>25</td>\n",
       "      <td>58</td>\n",
       "      <td>0.301205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word_before_abbr</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 j Polarity  Coverage  Overlaps  Conflicts  \\\n",
       "abbr_is_complete                 0      [0]  0.190668  0.190668   0.006336   \n",
       "common_verbs_following_abbr      1      [1]  0.025922  0.025922   0.025922   \n",
       "is_medical_abbreviation          2      [0]  1.000000  0.459101   0.253456   \n",
       "lf_length_more_than_three_words  3      [0]  0.020737  0.020737   0.010369   \n",
       "lf_name_short_in_first_words     4      [1]  0.152074  0.152074   0.152074   \n",
       "sentence_beginning               5      [1]  0.120392  0.120392   0.120392   \n",
       "verbs_ending_with_past           6      [1]  0.047811  0.047811   0.047811   \n",
       "word_before_abbr                 7      [0]  0.013249  0.013249   0.000576   \n",
       "\n",
       "                                 Correct  Incorrect  Emp. Acc.  \n",
       "abbr_is_complete                     331          0   1.000000  \n",
       "common_verbs_following_abbr           13         32   0.288889  \n",
       "is_medical_abbreviation             1627        109   0.937212  \n",
       "lf_length_more_than_three_words       36          0   1.000000  \n",
       "lf_name_short_in_first_words          35        229   0.132576  \n",
       "sentence_beginning                    44        165   0.210526  \n",
       "verbs_ending_with_past                25         58   0.301205  \n",
       "word_before_abbr                      23          0   1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NAT,\n",
    "    lfs=sorted(name_abbr_task_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary(Y=L_gold_train_NAT.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.17 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
