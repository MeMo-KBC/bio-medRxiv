{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "from fonduer.supervision.models import GoldLabel\n",
    "from fonduer.features import Featurizer\n",
    "from fonduer.candidates.models import Candidate\n",
    "from fonduer.parser.models import Document\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "from MeMoKBC.pipeline.utils import get_session, load_candidates, match_label_matrix\n",
    "from MeMoKBC.definitions.candidates import NameFullAbbr, NameAbbrTask\n",
    "from MeMoKBC.pipeline.lfs.name_short_long_lfs import short_long_lfs\n",
    "from MeMoKBC.pipeline.lfs.name_short_task_lfs import name_abbr_task_lfs\n",
    "from MeMoKBC.gold_label_matcher import match_gold_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fonduer.meta:Connecting user:postgres to fonduer-postgres-dev:5432/pipeline6\n",
      "INFO:fonduer.meta:Initializing the storage schema\n"
     ]
    }
   ],
   "source": [
    "session = get_session(\"pipeline6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [NameFullAbbr, NameAbbrTask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:fonduer.meta:Connecting user:postgres to fonduer-postgres-dev:5432/pipeline6\n",
      "INFO:fonduer.meta:Initializing the storage schema\n",
      "INFO:root:Found relations for 22 documents\n",
      "INFO:root:Found 6820 candidates for <class 'fonduer.candidates.models.candidate.NameAbbrTask'>\n",
      "INFO:root:Found 28105 candidates for <class 'fonduer.candidates.models.candidate.NameFullAbbr'>\n",
      "INFO:root:Found candidates for 40 documents\n"
     ]
    }
   ],
   "source": [
    "gold_labels = match_gold_label(\n",
    "    \"pipeline6\",\n",
    "    \"/data/Goldlabel_biomedRxiv/goldlabel1_docs801-840_laura/goldlabel_authorlong_short_task_medRxiv.json\",\n",
    "    [NameAbbrTask, NameFullAbbr]\n",
    ")\n",
    "\n",
    "nat_cands = []\n",
    "nfa_cands = []\n",
    "for cand in gold_labels:\n",
    "    if type(cand) == NameAbbrTask:\n",
    "        if cand[0].context.sentence.id == cand[1].context.sentence.id:\n",
    "            nat_cands.append(cand.id)\n",
    "    elif type(cand) == NameFullAbbr:\n",
    "        nfa_cands.append(cand.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = Labeler(session, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gold(c: Candidate) -> int:\n",
    "    if type(c) == NameAbbrTask:\n",
    "        if c.id in nat_cands:\n",
    "            return 1\n",
    "\n",
    "    elif type(c) == NameFullAbbr:\n",
    "        if c.id in nfa_cands:\n",
    "            return 1\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/fonduer/utils/utils_udf.py:217: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  .filter(candidate_class.id.in_(sub_query))\n",
      "INFO:fonduer.supervision.labeler:Clearing Labels (split 0)\n",
      "/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/fonduer/supervision/labeler.py:340: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  query = self.session.query(table).filter(table.candidate_id.in_(sub_query))\n",
      "INFO:fonduer.utils.udf:Running UDF...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56894739a0bd4f8e96f0d959bda947ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeler.apply(lfs=[[gold], [gold]], table=GoldLabel, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/bio-medRxiv/MeMoKBC/src/MeMoKBC/pipeline/utils.py:55: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  cands = (session.query(candidate_class).filter(candidate_class.id.in_(sub_query)).order_by(candidate_class.id).all())\n"
     ]
    }
   ],
   "source": [
    "train_cands = load_candidates(session, 0, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_gold_train = labeler.get_gold_labels(train_cands, annotator=\"gold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "gen_model_NFA = LabelModel(cardinality=2)\n",
    "gen_model_NAT = LabelModel(cardinality=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/bio-medRxiv/MeMoKBC/src/MeMoKBC/pipeline/utils.py:55: SAWarning: Coercing Subquery object into a select() for use in IN(); please pass a select() construct explicitly\n",
      "  cands = (session.query(candidate_class).filter(candidate_class.id.in_(sub_query)).order_by(candidate_class.id).all())\n"
     ]
    }
   ],
   "source": [
    "L_train_NFA, L_train_NAT = match_label_matrix(session, candidates, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Computing O...\n",
      "INFO:root:Estimating \\mu...\n",
      "  0%|          | 0/500 [00:00<?, ?epoch/s]INFO:root:[0 epochs]: TRAIN:[loss=0.066]\n",
      "INFO:root:[100 epochs]: TRAIN:[loss=0.003]\n",
      " 27%|██▋       | 133/500 [00:00<00:00, 1326.84epoch/s]INFO:root:[200 epochs]: TRAIN:[loss=0.002]\n",
      " 55%|█████▌    | 277/500 [00:00<00:00, 1388.29epoch/s]INFO:root:[300 epochs]: TRAIN:[loss=0.001]\n",
      "INFO:root:[400 epochs]: TRAIN:[loss=0.000]\n",
      "100%|██████████| 500/500 [00:00<00:00, 1405.08epoch/s]\n",
      "INFO:root:Finished Training\n"
     ]
    }
   ],
   "source": [
    "gen_model_NFA.fit(L_train_NFA, n_epochs=500, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "L_train should have at least 3 labeling functions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gen_model_NAT\u001b[39m.\u001b[39;49mfit(L_train_NAT, n_epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, log_freq\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n",
      "File \u001b[0;32m/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/snorkel/labeling/model/label_model.py:897\u001b[0m, in \u001b[0;36mLabelModel.fit\u001b[0;34m(self, L_train, Y_dev, class_balance, progress_bar, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m \u001b[39mif\u001b[39;00m L_shift\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcardinality:\n\u001b[1;32m    893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    894\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mL_train has cardinality \u001b[39m\u001b[39m{\u001b[39;00mL_shift\u001b[39m.\u001b[39mmax()\u001b[39m}\u001b[39;00m\u001b[39m, cardinality=\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcardinality\u001b[39m}\u001b[39;00m\u001b[39m passed in.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m     )\n\u001b[0;32m--> 897\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_constants(L_shift)\n\u001b[1;32m    898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_class_balance(class_balance, Y_dev)\n\u001b[1;32m    899\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_tree()\n",
      "File \u001b[0;32m/workspaces/bio-medRxiv/.venv/lib/python3.8/site-packages/snorkel/labeling/model/label_model.py:597\u001b[0m, in \u001b[0;36mLabelModel._set_constants\u001b[0;34m(self, L)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m=\u001b[39m L\u001b[39m.\u001b[39mshape\n\u001b[1;32m    596\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mL_train should have at least 3 labeling functions\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: L_train should have at least 3 labeling functions"
     ]
    }
   ],
   "source": [
    "gen_model_NAT.fit(L_train_NAT, n_epochs=500, log_freq=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if Path(\"models/label_model_NFA_v1.pkl\").is_file() and Path(\"models/label_model_NFT_v1.pkl\").is_file():\n",
    "    gen_model_NFA.load(source=\"models/label_model_NFA_v1.pkl\")\n",
    "    gen_model_NFT.load(source=\"models/label_model_NFT_v1.pkl\")\n",
    "    print(\"Loaded Models\")\n",
    "else:\n",
    "    gen_model_NFT.fit(L_train_NFT, n_epochs=500, log_freq=100)\n",
    "    gen_model_NFT.save(\"models/label_model_NFT_v1.pkl\")\n",
    "\n",
    "    gen_model_NFA.fit(L_train_NFA, n_epochs=500, log_freq=100)\n",
    "    gen_model_NFA.save(\"models/label_model_NFA_v1.pkl\")\n",
    "    print(\"Fit and saved models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating train marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals_NFA = gen_model_NFA.predict_proba(L_train_NFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals_NFT = gen_model_NFT.predict_proba(L_train_NFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_tight_layout(\"w_pad\")\n",
    "\n",
    "bins=20\n",
    "\n",
    "ax[0].hist(train_marginals_NFA[:, 0], bins=bins)\n",
    "ax[0].set_title(\"NFA(TRUE)\")\n",
    "\n",
    "ax[1].hist(train_marginals_NFT[:, 0], bins=bins)\n",
    "ax[1].set_title(\"NFT(TRUE)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = Labeler(session, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cands = load_candidates(session, split=1, candidate_list=candidates)\n",
    "\n",
    "L_dev_NFA, L_dev_NFT = labeler.get_label_matrices(dev_cands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract words from train_cands and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# calculate the diff between true and false prediction probability of each candidate\n",
    "# the bigger the difference the more certain the model is\n",
    "# Example True = 0.4 False = 0.6\n",
    "# diff = 0.6 - 0.4 = 0.2 --> model is very unsure \n",
    "diffs = train_marginals_NFT.max(axis=1) - train_marginals_NFT.min(axis=1)\n",
    "\n",
    "# filter out all candidates where labelmodel is very unsure\n",
    "# unsure is a diff of smaller then 0.000001\n",
    "train_idxs = np.where(diffs > 0.2)[0].astype(np.int64)\n",
    "filtered = train_marginals_NFT[train_idxs, 1]\n",
    "\n",
    "# Cast continous values to binary for logistic regression model\n",
    "y = np.where(filtered > 0.5, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature matrix and filter with previous filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(session, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_train_NFT = featurizer.get_feature_matrices(train_cands)[0]\n",
    "X = F_train_NFT[train_idxs, :]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "\n",
    "clf = LogisticRegression(max_iter=200).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cands = load_candidates(session, 2, candidates)\n",
    "F_test_NFT = featurizer.get_feature_matrices(test_cands)[0]\n",
    "\n",
    "preds = clf.predict(F_test_NFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge().fit(X.toarray(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
