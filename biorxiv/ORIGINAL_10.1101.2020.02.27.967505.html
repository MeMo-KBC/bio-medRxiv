<html lang="en" dir="ltr" xmlns="http://www.w3.org/1999/xhtml" xmlns:mml="http://www.w3.org/1998/Math/MathML">
 <head prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article# book: http://ogp.me/ns/book#">
  <link rel="dns-prefetch" href="//d33xdlntwy0kbs.cloudfront.net"/>
  <link rel="dns-prefetch" href="//www.google.com"/>
  <link rel="dns-prefetch" href="//scholar.google.com"/>
  <link rel="dns-prefetch" href="//www.google-analytics.com"/>
  <link rel="dns-prefetch" href="//stats.g.doubleclick.net"/>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <link rel="shortcut icon" href="https://www.biorxiv.org/sites/default/files/images/favicon.ico" type="image/vnd.microsoft.icon"/>
  <link rel="alternate" type="application/pdf" title="Full Text (PDF)" href="/content/10.1101/2020.02.27.967505v2.full.pdf"/>
  <link rel="alternate" type="text/plain" title="Full Text (Plain)" href="/content/10.1101/2020.02.27.967505v2.full.txt"/>
  <link rel="alternate" type="application/vnd.ms-powerpoint" title="Powerpoint" href="/content/10.1101/2020.02.27.967505v2.ppt"/>
  <meta name="article_thumbnail" content="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-1.gif"/>
  <meta name="type" content="article"/>
  <meta name="category" content="article"/>
  <meta name="HW.identifier" content="/biorxiv/early/2022/04/15/2020.02.27.967505.atom"/>
  <meta name="HW.pisa" content="biorxiv;2020.02.27.967505v2"/>
  <meta name="DC.Format" content="text/html"/>
  <meta name="DC.Language" content="en"/>
  <meta name="DC.Title" content="Improving the validity of neuroimaging decoding tests of invariant and configural neural representation"/>
  <meta name="DC.Identifier" content="10.1101/2020.02.27.967505"/>
  <meta name="DC.Date" content="2022-04-15"/>
  <meta name="DC.Publisher" content="Cold Spring Harbor Laboratory"/>
  <meta name="DC.Rights" content="© 2022, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/"/>
  <meta name="DC.AccessRights" content="restricted"/>
  <meta name="DC.Description" content="Many research questions in sensory neuroscience involve determining whether the neural representation of a stimulus property is invariant or specific to a particular stimulus context (e.g., Is object representation invariant to translation? Is the representation of a face feature specific to the context of other face features?). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging studies have used operational tests in which a target property is inferred from a significant test against the null hypothesis of the opposite property. For example, the popular cross-classification test concludes that representations are invariant or tolerant when the null hypothesis of specificity is rejected. A recently developed neurocomputational theory provides two insights regarding such tests. First, tests against the null of context-specificity, and for the alternative of context-invariance, are prone to false positives due to the way in which the underlying neural representations are transformed into indirect measurements in neuroimaging studies. Second, jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. Here, we provide empirical and computational evidence supporting both of these theoretical insights. In our empirical study, we use encoding of orientation and spatial position in primary visual cortex as a case study, as previous research has established that these properties are encoded in a context-sensitive way. Using fMRI decoding, we show that the cross-classification test produces false-positive conclusions of invariance, but that more valid conclusions can be reached by jointly performing tests against the null of invariance. The results of two simulations further support both of these conclusions. We conclude that more valid inferences about invariance or specificity of neural representations can be reached by jointly testing against both hypotheses, and using neurocomputational theory to guide the interpretation of results.

Author Summary Many research questions in sensory neuroscience involve determining whether the representation of a stimulus property is invariant or specific to a change in stimulus context (e.g., translation-invariant object representation; configural representation of face features). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging research has studied invariance using operational tests, among which the most widely used in recent years is cross-classification. We provide evidence from a functional MRI study, simulations, and theoretical results supporting two insights regarding such tests: (1) tests that seek to provide evidence for invariance (like cross-classification) have an inflated false positive rate, but (2) using complementary tests that seek evidence for context-specificity leads to more valid conclusions.

### Competing Interest Statement

The authors have declared no competing interest."/>
  <meta name="DC.Contributor" content="Fabian A. Soto"/>
  <meta name="DC.Contributor" content="Sanjay Narasiwodeyar"/>
  <meta name="article:published_time" content="2022-04-15"/>
  <meta name="article:section" content="New Results"/>
  <meta name="citation_title" content="Improving the validity of neuroimaging decoding tests of invariant and configural neural representation"/>
  <meta name="citation_abstract" lang="en" content="<h3>Abstract</h3>
<p>Many research questions in sensory neuroscience involve determining whether the neural representation of a stimulus property is invariant or specific to a particular stimulus context (e.g., Is object representation invariant to translation? Is the representation of a face feature specific to the context of other face features?). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging studies have used operational tests in which a target property is inferred from a significant test against the null hypothesis of the opposite property. For example, the popular cross-classification test concludes that representations are invariant or tolerant when the null hypothesis of specificity is rejected. A recently developed neurocomputational theory provides two insights regarding such tests. First, tests against the null of context-specificity, and for the alternative of context-invariance, are prone to false positives due to the way in which the underlying neural representations are transformed into indirect measurements in neuroimaging studies. Second, jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. Here, we provide empirical and computational evidence supporting both of these theoretical insights. In our empirical study, we use encoding of orientation and spatial position in primary visual cortex as a case study, as previous research has established that these properties are encoded in a context-sensitive way. Using fMRI decoding, we show that the cross-classification test produces false-positive conclusions of invariance, but that more valid conclusions can be reached by jointly performing tests against the null of invariance. The results of two simulations further support both of these conclusions. We conclude that more valid inferences about invariance or specificity of neural representations can be reached by jointly testing against both hypotheses, and using neurocomputational theory to guide the interpretation of results.</p><h3>Author Summary</h3>
<p>Many research questions in sensory neuroscience involve determining whether the representation of a stimulus property is invariant or specific to a change in stimulus context (e.g., translation-invariant object representation; configural representation of face features). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging research has studied invariance using operational tests, among which the most widely used in recent years is cross-classification. We provide evidence from a functional MRI study, simulations, and theoretical results supporting two insights regarding such tests: (1) tests that seek to provide evidence for invariance (like cross-classification) have an inflated false positive rate, but (2) using complementary tests that seek evidence for context-specificity leads to more valid conclusions.</p>"/>
  <meta name="citation_journal_title" content="bioRxiv"/>
  <meta name="citation_publisher" content="Cold Spring Harbor Laboratory"/>
  <meta name="citation_publication_date" content="2022/01/01"/>
  <meta name="citation_mjid" content="biorxiv;2020.02.27.967505v2"/>
  <meta name="citation_id" content="2020.02.27.967505v2"/>
  <meta name="citation_public_url" content="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2"/>
  <meta name="citation_abstract_html_url" content="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2.abstract"/>
  <meta name="citation_full_html_url" content="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2.full"/>
  <meta name="citation_pdf_url" content="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505.full.pdf"/>
  <meta name="citation_doi" content="10.1101/2020.02.27.967505"/>
  <meta name="citation_num_pages" content="54"/>
  <meta name="citation_article_type" content="Article"/>
  <meta name="citation_section" content="New Results"/>
  <meta name="citation_firstpage" content="2020.02.27.967505"/>
  <meta name="citation_author" content="Fabian A. Soto"/>
  <meta name="citation_author_institution" content="Department of Psychology, Florida International University"/>
  <meta name="citation_author_email" content="fasoto@fiu.edu"/>
  <meta name="citation_author" content="Sanjay Narasiwodeyar"/>
  <meta name="citation_author_institution" content="Department of Psychology, Florida International University"/>
  <meta name="citation_reference" content="Allefeld C, Haynes JD. Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA. NeuroImage. 2014;89:345–357. doi:10.1016/j.neuroimage.2013.11.043."/>
  <meta name="citation_reference" content="Anzellotti S, Caramazza A. The neural mechanisms for the recognition of face identity in humans. Frontiers in Psychology. 2014;5:672. doi:10.3389/fpsyg.2014.00672."/>
  <meta name="citation_reference" content="Kaplan JT, Man K, Greening SG. Multivariate cross-classification: Applying machine learning techniques to characterize abstraction in neural representations. Frontiers in Human Neuroscience. 2015;9:151. doi:10.3389/fnhum.2015.00151."/>
  <meta name="citation_reference" content="Soto FA, Vucovich LE, Ashby FG. Linking signal detection theory and encoding models to reveal independent neural representations from neuroimaging data. PLoS Computational Biology. 2018;14(10):e1006470."/>
  <meta name="citation_reference" content="Anzellotti S, Fairhall SL, Caramazza A. Decoding representations of face identity that are tolerant to rotation. Cerebral Cortex. 2014;24(8):1988–1995. doi:10.1093/cercor/bht046."/>
  <meta name="citation_reference" content="Ramirez FM, Cichy RM, Allefeld C, Haynes JD. The neural code for face orientation in the human fusiform face area. The Journal of Neuroscience. 2014;34(36):12155–12167. doi:10.1523/JNEUROSCI.3156-13.2014."/>
  <meta name="citation_reference" content="Kaiser D, Azzalini DC, Peelen MV. Shape-independent object category responses revealed by MEG and fMRI decoding. Journal of Neurophysiology. 2016;115(4):2246–2250. doi:10.1152/jn.01074.2015."/>
  <meta name="citation_reference" content="Etzel JA, Gazzola V, Keysers C. Testing simulation theory with cross-modal multivariate classification of fMRI data. PLOS ONE. 2008;3(11):e3690. doi:10.1371/journal.pone.0003690."/>
  <meta name="citation_reference" content="Archila-Melendez ME, Valente G, Correia JM, Rouhl RPW, Kranen-Mastenbroek V, Jansma BM. Sensorimotor representation of speech perception: Cross-decoding of place of articulation features during selective attention to syllables in 7T fMRI. eNeuro. 2018;5(2):e0252–17.2018. doi:10.1523/ENEURO.0252-17.2018."/>
  <meta name="citation_reference" content="Man K, Kaplan JT, Damasio A, Meyer K. Sight and sound converge to form modality-invariant representations in temporoparietal cortex. Journal of Neuroscience. 2012;32(47):16629–16636. doi:10.1523/JNEUROSCI.2342-12.2012."/>
  <meta name="citation_reference" content="Anzellotti S, Caramazza A. Multimodal representations of person identity individuated with fMRI. Cortex. 2017;89:85–97."/>
  <meta name="citation_reference" content="Akama H, Murphy B, Na L, Shimizu Y, Poesio M. Decoding semantics across fMRI sessions with different stimulus modalities: a practical MVPA study. Frontiers in Neuroinformatics. 2012;6:24. doi:10.3389/fninf.2012.00024."/>
  <meta name="citation_reference" content="Soto FA, Waldschmidt JG, Helie S, Ashby FG. Brain activity across the development of automatic categorization: A comparison of categorization tasks using multi-voxel pattern analysis. Neuroimage. 2013;71:284–897. doi:10.1016/j.neuroimage.2013.01.008."/>
  <meta name="citation_reference" content="Buchweitz A, Shinkareva SV, Mason RA, Mitchell TM, Just MA. Identifying bilingual semantic neural representations across languages. Brain and Language. 2012;120(3):282–289. doi:10.1016/j.bandl.2011.09.003."/>
  <meta name="citation_reference" content="Guest O, Love BC. What the success of brain imaging implies about the neural code. Elife. 2017;6:e21397."/>
  <meta name="citation_reference" content="Issa NP, Rosenberg A, Husson TR. Models and measurements of functional maps in V1. Journal of Neurophysiology. 2008;99(6):2745–2754."/>
  <meta name="citation_reference" content="Ng J, Bharath AA, Zhaoping L. A survey of architecture and function of the primary visual cortex (V1). EURASIP J Appl Signal Process. 2007;2007(1):124–124."/>
  <meta name="citation_reference" content="Alink A, Krugliak A, Walther A, Kriegeskorte N. fMRI orientation decoding in V1 does not require global maps or globally coherent orientation stimuli. Frontiers in Psychology. 2013;4:493. doi:10.3389/fpsyg.2013.00493."/>
  <meta name="citation_reference" content="Pratte MS, Sy JL, Swisher JD, Tong F. Radial bias is not necessary for orientation decoding. NeuroImage. 2016;127:23–33. doi:10.1016/j.neuroimage.2015.11.066."/>
  <meta name="citation_reference" content="Maloney RT. The basis of orientation decoding in human primary visual cortex: fine- or coarse-scale biases? Journal of Neurophysiology. 2014;113(1):1–3. doi:10.1152/jn.00196.2014."/>
  <meta name="citation_reference" content="Gur M, Kagan I, Snodderly DM. Orientation and direction selectivity of neurons in V1 of alert monkeys: functional relationships and laminar distributions. Cerebral Cortex. 2005;15(8):1207–1221."/>
  <meta name="citation_reference" content="Brouwer GJ, Heeger DJ. Decoding and reconstructing color from responses in human visual cortex. Journal of Neuroscience. 2009;29(44):13992–14003. doi:10.1523/JNEUROSCI.3577-09.2009."/>
  <meta name="citation_reference" content="Ester EF, Sprague TC, Serences JT. Categorical biases in human occipitoparietal cortex. Journal of Neuroscience. 2020;40(4):917–931."/>
  <meta name="citation_reference" content="Garcia JO, Srinivasan R, Serences JT. Near-real-time feature-selective modulations in human cortex. Current Biology. 2013;23(6):515–522. doi:10.1016/j.cub.2013.02.013."/>
  <meta name="citation_reference" content="Liu T, Cable D, Gardner JL. Inverted encoding models of human population response conflate noise and neural tuning width. Journal of Neuroscience. 2018;38(2):398–408. doi:10.1523/JNEUROSCI.2453-17.2017."/>
  <meta name="citation_reference" content="Blasdel G, Campbell D. Functional retinotopy of monkey visual cortex. Journal of Neuroscience. 2001;21(20):8286–8301."/>
  <meta name="citation_reference" content="Freeman RD. Cortical columns: a multi-parameter examination. Cerebral Cortex. 2003;13(1):70–72."/>
  <meta name="citation_reference" content="Landisman CE, Ts’o DY. Color processing in macaque striate cortex: relationships to ocular dominance, cytochrome oxidase, and orientation. Journal of Neurophysiology. 2002;87(6):3126–3137."/>
  <meta name="citation_reference" content="Nauhaus I, Nielsen KJ, Disney AA, Callaway EM. Orthogonal micro-organization of orientation and spatial frequency in primate primary visual cortex. Nature Neuroscience. 2012;15(12):1683–1690."/>
  <meta name="citation_reference" content="Yacoub E, Harel N, Uğurbil K. High-field fMRI unveils orientation columns in humans. Proceedings of the National Academy of Sciences. 2008;105(30):10607–10612."/>
  <meta name="citation_reference" content="Ohki K, Chung S, Ch’ng YH, Kara P, Reid RC. Functional imaging with cellular resolution reveals precise micro-architecture in visual cortex. Nature. 2005;433(7026):597–603. doi:10.1038/nature03274."/>
  <meta name="citation_reference" content="Van Hooser SD, Heimel JAF, Chung S, Nelson SB, Toth LJ. Orientation selectivity without orientation maps in visual cortex of a highly visual mammal. Journal of Neuroscience. 2005;25(1):19–28."/>
  <meta name="citation_reference" content="Duyn JH. The future of ultra-high field MRI and fMRI for study of the human brain. Neuroimage. 2012;62(2):1241–1248."/>
  <meta name="citation_reference" content="Logothetis NK. What we can do and what we cannot do with fMRI. Nature. 2008;453(7197):869–878. doi:10.1038/nature06976."/>
  <meta name="citation_reference" content="Boynton GM. Imaging orientation selectivity: decoding conscious perception in V1. Nature Neuroscience. 2005;8(5):541–542."/>
  <meta name="citation_reference" content="Haynes JD, Rees G. Predicting the orientation of invisible stimuli from activity in human primary visual cortex. Nature Neuroscience. 2005;8(5):686–691."/>
  <meta name="citation_reference" content="Kamitani Y, Tong F. Decoding the visual and subjective contents of the human brain. Nature Neuroscience. 2005;8(5):679–685. doi:10.1038/nn1444."/>
  <meta name="citation_reference" content="Freeman J, Brouwer GJ, Heeger DJ, Merriam EP. Orientation decoding depends on maps, not columns. Journal of Neuroscience. 2011;31(13):4792–4804."/>
  <meta name="citation_reference" content="Wardle SG, Ritchie JB, Seymour K, Carlson TA. Edge-related activity is not necessary to explain orientation decoding in human visual cortex. Journal of Neuroscience. 2017;37(5):1187–1196."/>
  <meta name="citation_reference" content="Walther A, Nili H, Ejaz N, Alink A, Kriegeskorte N, Diedrichsen J. Reliability of dissimilarity measures for multi-voxel pattern analysis. NeuroImage. 2016;137:188–200. doi:10.1016/j.neuroimage.2015.12.012."/>
  <meta name="citation_reference" content="Van Bergen RS, Ma WJ, Pratte MS, Jehee JFM. Sensory uncertainty decoded from visual cortex predicts behavior. Nature Neuroscience. 2015;18(12):1728–1730."/>
  <meta name="citation_reference" content="Ritchie JB, Carlson TA. Neural decoding and “inner” psychophysics: A distance-to-bound approach for linking mind, brain, and behavior. Frontiers in Neuroscience. 2016;10. doi:10.3389/fnins.2016.00190."/>
  <meta name="citation_reference" content="Fortmann-Roe S, Starfield R, Getz WM. Contingent kernel density estimation. PLoS ONE. 2012;7(2):e30549. doi:10.1371/journal.pone.0030549."/>
  <meta name="citation_reference" content="Gardner JL, Liu T. Inverted encoding models reconstruct an arbitrary model response, not the stimulus. eNeuro. 2019;6(2):e0363–18.2019. doi:10.1523/ENEURO.0363-18.2019."/>
  <meta name="citation_reference" content="Peirce JW. PsychoPy: psychophysics software in Python. Journal of Neuroscience Methods. 2007;162(1-2):8–13."/>
  <meta name="citation_reference" content="Sengupta A, Yakupov R, Speck O, Pollmann S, Hanke M. The effect of acquisition resolution on orientation decoding from V1 BOLD fMRI at 7T. NeuroImage. 2017;148:64–76. doi:10.1016/j.neuroimage.2016.12.040."/>
  <meta name="citation_reference" content="Henriksson L, Nurminen L, Hyvärinen A, Vanni S. Spatial frequency tuning in human retinotopic visual areas. Journal of Vision. 2008;8(10):5. doi:10.1167/8.10.5."/>
  <meta name="citation_reference" content="Hinds OP, Rajendran N, Polimeni JR, Augustinack JC, Wiggins G, Wald LL, et al. Accurate prediction of V1 location from cortical folds in a surface coordinate system. Neuroimage. 2008;39(4):1585–1599."/>
  <meta name="citation_reference" content="Benson NC, Butt OH, Datta R, Radoeva PD, Brainard DH, Aguirre GK. The retinotopic organization of striate cortex is well predicted by surface topology. Current Biology. 2012;22(21):2081–2085."/>
  <meta name="citation_reference" content="Fischl B. FreeSurfer. Neuroimage. 2012;62(2):774–781."/>
  <meta name="citation_reference" content="Gorgolewski K, Burns CD, Madison C, Clark D, Halchenko YO, Waskom ML, et al. Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python. Frontiers in Neuroinformatics. 2011;5:13."/>
  <meta name="citation_reference" content="Jenkinson M, Beckmann CF, Behrens TE, Woolrich MW, Smith SM. Fsl. Neuroimage. 2012;62(2):782– 790."/>
  <meta name="citation_reference" content="Pedregosa F, Eickenberg M, Ciuciu P, Thirion B, Gramfort A. Data-driven HRF estimation for encoding and decoding models. Neuroimage. 2015;104:209–220."/>
  <meta name="citation_reference" content="Pedregosa F, Varoquaux G, Gramfort A, Michel V, Thirion B, Grisel O, et al. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research. 2011;12(Oct):2825–2830."/>
  <meta name="citation_reference" content="Knijnenburg TA, Wessels LFA, Reinders MJT, Shmulevich I. Fewer permutations, more accurate p-values. Bioinformatics. 2009;25(12):i161–i168. doi:10.1093/bioinformatics/btp211."/>
  <meta name="citation_reference" content="Soto FA, Ashby GF. Encoding models in neuroimaging. In: Ashby FG, Colonius H, Dzhafarov EN, editors. The new handbook of mathematical psychology. vol. 3. Cambridge University Press; 2022."/>
  <meta name="citation_reference" content="Alink A, Abdulrahman H, Henson RN. Forward models demonstrate that repetition suppression is best modelled by local neural scaling. Nature Communications. 2018;9(1):3854. doi:10.1038/s41467-018-05957-0."/>
  <meta name="citation_reference" content="Ester EF, Anderson DE, Serences JT, Awh E. A neural measure of precision in visual working memory. Journal of Cognitive Neuroscience. 2013;25(5):754–761."/>
  <meta name="twitter:title" content="Improving the validity of neuroimaging decoding tests of invariant and configural neural representation"/>
  <meta name="twitter:site" content="@biorxivpreprint"/>
  <meta name="twitter:card" content="summary"/>
  <meta name="twitter:image" content="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"/>
  <meta name="twitter:description" content="Many research questions in sensory neuroscience involve determining whether the neural representation of a stimulus property is invariant or specific to a particular stimulus context (e.g., Is object representation invariant to translation? Is the representation of a face feature specific to the context of other face features?). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging studies have used operational tests in which a target property is inferred from a significant test against the null hypothesis of the opposite property. For example, the popular cross-classification test concludes that representations are invariant or tolerant when the null hypothesis of specificity is rejected. A recently developed neurocomputational theory provides two insights regarding such tests. First, tests against the null of context-specificity, and for the alternative of context-invariance, are prone to false positives due to the way in which the underlying neural representations are transformed into indirect measurements in neuroimaging studies. Second, jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. Here, we provide empirical and computational evidence supporting both of these theoretical insights. In our empirical study, we use encoding of orientation and spatial position in primary visual cortex as a case study, as previous research has established that these properties are encoded in a context-sensitive way. Using fMRI decoding, we show that the cross-classification test produces false-positive conclusions of invariance, but that more valid conclusions can be reached by jointly performing tests against the null of invariance. The results of two simulations further support both of these conclusions. We conclude that more valid inferences about invariance or specificity of neural representations can be reached by jointly testing against both hypotheses, and using neurocomputational theory to guide the interpretation of results.

Author Summary Many research questions in sensory neuroscience involve determining whether the representation of a stimulus property is invariant or specific to a change in stimulus context (e.g., translation-invariant object representation; configural representation of face features). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging research has studied invariance using operational tests, among which the most widely used in recent years is cross-classification. We provide evidence from a functional MRI study, simulations, and theoretical results supporting two insights regarding such tests: (1) tests that seek to provide evidence for invariance (like cross-classification) have an inflated false positive rate, but (2) using complementary tests that seek evidence for context-specificity leads to more valid conclusions.

### Competing Interest Statement

The authors have declared no competing interest."/>
  <meta name="og-title" property="og:title" content="Improving the validity of neuroimaging decoding tests of invariant and configural neural representation"/>
  <meta name="og-url" property="og:url" content="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2"/>
  <meta name="og-site-name" property="og:site_name" content="bioRxiv"/>
  <meta name="og-description" property="og:description" content="Many research questions in sensory neuroscience involve determining whether the neural representation of a stimulus property is invariant or specific to a particular stimulus context (e.g., Is object representation invariant to translation? Is the representation of a face feature specific to the context of other face features?). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging studies have used operational tests in which a target property is inferred from a significant test against the null hypothesis of the opposite property. For example, the popular cross-classification test concludes that representations are invariant or tolerant when the null hypothesis of specificity is rejected. A recently developed neurocomputational theory provides two insights regarding such tests. First, tests against the null of context-specificity, and for the alternative of context-invariance, are prone to false positives due to the way in which the underlying neural representations are transformed into indirect measurements in neuroimaging studies. Second, jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. Here, we provide empirical and computational evidence supporting both of these theoretical insights. In our empirical study, we use encoding of orientation and spatial position in primary visual cortex as a case study, as previous research has established that these properties are encoded in a context-sensitive way. Using fMRI decoding, we show that the cross-classification test produces false-positive conclusions of invariance, but that more valid conclusions can be reached by jointly performing tests against the null of invariance. The results of two simulations further support both of these conclusions. We conclude that more valid inferences about invariance or specificity of neural representations can be reached by jointly testing against both hypotheses, and using neurocomputational theory to guide the interpretation of results.

Author Summary Many research questions in sensory neuroscience involve determining whether the representation of a stimulus property is invariant or specific to a change in stimulus context (e.g., translation-invariant object representation; configural representation of face features). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging research has studied invariance using operational tests, among which the most widely used in recent years is cross-classification. We provide evidence from a functional MRI study, simulations, and theoretical results supporting two insights regarding such tests: (1) tests that seek to provide evidence for invariance (like cross-classification) have an inflated false positive rate, but (2) using complementary tests that seek evidence for context-specificity leads to more valid conclusions.

### Competing Interest Statement

The authors have declared no competing interest."/>
  <meta name="og-type" property="og:type" content="article"/>
  <meta name="og-image" property="og:image" content="https://www.biorxiv.org/sites/default/files/images/biorxiv_logo_homepage7-5-small.png"/>
  <meta name="citation_date" content="2022-04-15"/>
  <meta name="description" content="bioRxiv - the preprint server for biology, operated by Cold Spring Harbor Laboratory, a research and educational institution"/>
  <meta name="generator" content="Drupal 7 (http://drupal.org)"/>
  <link rel="canonical" href="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2"/>
  <link rel="shortlink" href="https://www.biorxiv.org/node/2498488"/>
  <title>
   Improving the validity of neuroimaging decoding tests of invariant and configural neural representation | bioRxiv
  </title>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__7SC0i-kTgUlQGKuqbmyS18Sez8FDO-aG9FSHkGrLGl8__9Xf-fJpmF9h8tvWywQTaOzJzFLt4sEfx108Wh1gYmm0__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="//cdn.jsdelivr.net/qtip2/2.2.1/jquery.qtip.min.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__JbFqFjYGp4Zx8gvmj6v5YmfNmbiFphGHPblyC9bfG5Y__OScmsb_1nSVmm_Ax3cJ5Rq7p081PahYkvF_YWQd5GtE__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <style type="text/css" media="all">
   /* &lt;![CDATA[ */
.panels-flexible-new .panels-flexible-region{padding:0}.panels-flexible-new .panels-flexible-region-inside{padding-right:.5em;padding-left:.5em}.panels-flexible-new .panels-flexible-region-inside-first{padding-left:0}.panels-flexible-new .panels-flexible-region-inside-last{padding-right:0}.panels-flexible-new .panels-flexible-column{padding:0}.panels-flexible-new .panels-flexible-column-inside{padding-right:.5em;padding-left:.5em}.panels-flexible-new .panels-flexible-column-inside-first{padding-left:0}.panels-flexible-new .panels-flexible-column-inside-last{padding-right:0}.panels-flexible-new .panels-flexible-row{padding:0 0 .5em;margin:0}.panels-flexible-new .panels-flexible-row-last{padding-bottom:0}.panels-flexible-column-new-main{float:left;width:99.0000%}.panels-flexible-new-inside{padding-right:0}.panels-flexible-new{width:auto}.panels-flexible-region-new-center{float:left;width:99.0000%}.panels-flexible-row-new-main-row-inside{padding-right:0}
/* ]]&gt; */
  </style>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__PWuQ_RYRTJ4BLEKsbWQeHysPg0gOQ3571ruQa_rXvAo__cj81oxtSGUe-AIO3tlkSBJPNpKP5ZgLdB8f8awBQsWU__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <style type="text/css" media="all">
   /* &lt;![CDATA[ */
#sliding-popup.sliding-popup-bottom,#sliding-popup.sliding-popup-bottom .eu-cookie-withdraw-banner,.eu-cookie-withdraw-tab{background:gray}#sliding-popup.sliding-popup-bottom.eu-cookie-withdraw-wrapper{background:transparent}#sliding-popup .popup-content #popup-text h1,#sliding-popup .popup-content #popup-text h2,#sliding-popup .popup-content #popup-text h3,#sliding-popup .popup-content #popup-text p,.eu-cookie-compliance-secondary-button,.eu-cookie-withdraw-tab{color:#fff !important}.eu-cookie-withdraw-tab{border-color:#fff}.eu-cookie-compliance-more-button{color:#fff !important}
/* ]]&gt; */
  </style>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__Wnlyen9qEpwh_Qaf9okEu4QdVGM0BDothxeqA6Nbvo8__EJmw6SZD9bYoS8jocCpPYS3JFRURpdzmuvJoAUNiI-g__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__fse0T7HwKBxFeJ5ZSFW6P7GHsblWECJwe3f8Eo0Byb8__GnHmvNTOB0-xZRDC4PFtbOee_g-W6li7rpWRuc9O4B4__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__2WBMox6sOrN42ss5lCnH7WWVRdFdJCxtTKnQJYRwTE4__yqNvNYLvMpjy3ffuJrjjm9uW2i-Me1c23KLYuWHaqio__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="https://www.biorxiv.org/sites/default/files/advagg_css/css__g_BFrOIH2jRr6w2kKikVPe0XcLWrQStWL-Z3vs6TbJQ__5c1ZiN_pM9tjxvpyA9VpEacScF0S_W4R222pC-s_-Pk__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.css" media="all"/>
  <link type="text/css" rel="stylesheet" href="https://d33xdlntwy0kbs.cloudfront.net/cshl_custom.css" media="all"/>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__BKYqkKToQ7EjirB7eIdMEH5521EU3da9IpoOs8Ex2XI__aSjVoX8giBmLhN2EbCgIGQJNu89Mh5aVu1LvI_gkJ7Y__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript" src="//cdn.jsdelivr.net/qtip2/2.2.1/jquery.qtip.min.js">
  </script>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__4Cn2dxvNlsJ-sHe6QOTLREaQvcqb0Yh0Zm9tTOHtQow__JeZEUjzbaj_yX6UjCI8eBbXy_J64ZVuoWmc2fSpLZHo__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript" src="https://www.google.com/recaptcha/api.js?hl=en&render=explicit&onload=drupalRecaptchaOnload">
  </script>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__dGWpV57YWu3sX6UOe04RMH-iP9jSkEP7Ajt0caYXZZk__u2clNMaOO3LCM0tpFNpsQhnHrJ4_SUXG1gFb00eB1iU__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript" async="async" src="https://scholar.google.com/scholar_js/casa.js">
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
/*!
 * yepnope1.5.4
 * (c) WTFPL, GPLv2
 */
(function(a,b,c){function d(a){return"[object Function]"==o.call(a)}function e(a){return"string"==typeof a}function f(){}function g(a){return!a||"loaded"==a||"complete"==a||"uninitialized"==a}function h(){var a=p.shift();q=1,a?a.t?m(function(){("c"==a.t?B.injectCss:B.injectJs)(a.s,0,a.a,a.x,a.e,1)},0):(a(),h()):q=0}function i(a,c,d,e,f,i,j){function k(b){if(!o&amp;&amp;g(l.readyState)&amp;&amp;(u.r=o=1,!q&amp;&amp;h(),l.onload=l.onreadystatechange=null,b)){"img"!=a&amp;&amp;m(function(){t.removeChild(l)},50);for(var d in y[c])y[c].hasOwnProperty(d)&amp;&amp;y[c][d].onload()}}var j=j||B.errorTimeout,l=b.createElement(a),o=0,r=0,u={t:d,s:c,e:f,a:i,x:j};1===y[c]&amp;&amp;(r=1,y[c]=[]),"object"==a?l.data=c:(l.src=c,l.type=a),l.width=l.height="0",l.onerror=l.onload=l.onreadystatechange=function(){k.call(this,r)},p.splice(e,0,u),"img"!=a&amp;&amp;(r||2===y[c]?(t.insertBefore(l,s?null:n),m(k,j)):y[c].push(l))}function j(a,b,c,d,f){return q=0,b=b||"j",e(a)?i("c"==b?v:u,a,b,this.i++,c,d,f):(p.splice(this.i++,0,a),1==p.length&amp;&amp;h()),this}function k(){var a=B;return a.loader={load:j,i:0},a}var l=b.documentElement,m=a.setTimeout,n=b.getElementsByTagName("script")[0],o={}.toString,p=[],q=0,r="MozAppearance"in l.style,s=r&amp;&amp;!!b.createRange().compareNode,t=s?l:n.parentNode,l=a.opera&amp;&amp;"[object Opera]"==o.call(a.opera),l=!!b.attachEvent&amp;&amp;!l,u=r?"object":l?"script":"img",v=l?"script":u,w=Array.isArray||function(a){return"[object Array]"==o.call(a)},x=[],y={},z={timeout:function(a,b){return b.length&amp;&amp;(a.timeout=b[0]),a}},A,B;B=function(a){function b(a){var a=a.split("!"),b=x.length,c=a.pop(),d=a.length,c={url:c,origUrl:c,prefixes:a},e,f,g;for(f=0;f&lt;d;f++)g=a[f].split("="),(e=z[g.shift()])&amp;&amp;(c=e(c,g));for(f=0;f&lt;b;f++)c=x[f](c);return c}function g(a,e,f,g,h){var i=b(a),j=i.autoCallback;i.url.split(".").pop().split("?").shift(),i.bypass||(e&amp;&amp;(e=d(e)?e:e[a]||e[g]||e[a.split("/").pop().split("?")[0]]),i.instead?i.instead(a,e,f,g,h):(y[i.url]?i.noexec=!0:y[i.url]=1,f.load(i.url,i.forceCSS||!i.forceJS&amp;&amp;"css"==i.url.split(".").pop().split("?").shift()?"c":c,i.noexec,i.attrs,i.timeout),(d(e)||d(j))&amp;&amp;f.load(function(){k(),e&amp;&amp;e(i.origUrl,h,g),j&amp;&amp;j(i.origUrl,h,g),y[i.url]=2})))}function h(a,b){function c(a,c){if(a){if(e(a))c||(j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}),g(a,j,b,0,h);else if(Object(a)===a)for(n in m=function(){var b=0,c;for(c in a)a.hasOwnProperty(c)&amp;&amp;b++;return b}(),a)a.hasOwnProperty(n)&amp;&amp;(!c&amp;&amp;!--m&amp;&amp;(d(j)?j=function(){var a=[].slice.call(arguments);k.apply(this,a),l()}:j[n]=function(a){return function(){var b=[].slice.call(arguments);a&amp;&amp;a.apply(this,b),l()}}(k[n])),g(a[n],j,b,n,h))}else!c&amp;&amp;l()}var h=!!a.test,i=a.load||a.both,j=a.callback||f,k=j,l=a.complete||f,m,n;c(h?a.yep:a.nope,!!i),i&amp;&amp;c(i)}var i,j,l=this.yepnope.loader;if(e(a))g(a,0,l,0);else if(w(a))for(i=0;i&lt;a.length;i++)j=a[i],e(j)?g(j,0,l,0):w(j)?B(j):Object(j)===j&amp;&amp;h(j,l);else Object(a)===a&amp;&amp;h(a,l)},B.addPrefix=function(a,b){z[a]=b},B.addFilter=function(a){x.push(a)},B.errorTimeout=1e4,null==b.readyState&amp;&amp;b.addEventListener&amp;&amp;(b.readyState="loading",b.addEventListener("DOMContentLoaded",A=function(){b.removeEventListener("DOMContentLoaded",A,0),b.readyState="complete"},0)),a.yepnope=k(),a.yepnope.executeStack=h,a.yepnope.injectJs=function(a,c,d,e,i,j){var k=b.createElement("script"),l,o,e=e||B.errorTimeout;k.src=a;for(o in d)k.setAttribute(o,d[o]);c=j?h:c||f,k.onreadystatechange=k.onload=function(){!l&amp;&amp;g(k.readyState)&amp;&amp;(l=1,c(),k.onload=k.onreadystatechange=null)},m(function(){l||(l=1,c(1))},e),i?k.onload():n.parentNode.insertBefore(k,n)},a.yepnope.injectCss=function(a,c,d,e,g,i){var e=b.createElement("link"),j,c=i?h:c||f;e.href=a,e.rel="stylesheet",e.type="text/css";for(j in d)e.setAttribute(j,d[j]);g||(n.parentNode.insertBefore(e,n),m(c,0))}})(this,document);

//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
yepnope({
  test: Modernizr.matchmedia,
  nope: '/sites/all/libraries/media-match/media.match.min.js'
});
//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
var _prum=[['id', '612e3d94173350001100005d'], ['mark', 'firstbyte',
      (new Date()).getTime()]]; (function() {
      var s=document.getElementsByTagName('script')[0],
      p=document.createElement('script');
      p.async='async'; p.src='//rum-static.pingdom.net/prum.min.js';s.parentNode.insertBefore(p,s);})();
//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
if(typeof window.MathJax === "undefined") window.MathJax = { menuSettings: { zoom: "Click" } };
//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
(function(i,s,o,g,r,a,m){i["GoogleAnalyticsObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,"script","//www.google-analytics.com/analytics.js","ga");ga("create", "UA-45638026-1", {"cookieDomain":"auto"});ga("set", "page", location.pathname + location.search + location.hash);ga("send", "pageview");ga('create', 'UA-189672-38', 'auto', {'name': 'hwTracker'});
ga('set', 'anonymizeIp', true);
ga('hwTracker.send', 'pageview');
//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
jQuery.extend(Drupal.settings,{"basePath":"\/","pathPrefix":"","ajaxPageState":{"theme":"jcore_1","theme_token":"9zNjbAumyVzJVwdgHfz4JltrD2Kp4yGAIsQWCI5g9TI"},"colorbox":{"opacity":"0.85","current":"{current} of {total}","previous":"\u00ab Prev","next":"Next \u00bb","close":"Close","maxWidth":"98%","maxHeight":"98%","fixed":true,"mobiledetect":true,"mobiledevicewidth":"480px"},"highwire":{"nid":"2498488","apath":"\/biorxiv\/early\/2022\/04\/15\/2020.02.27.967505.atom","pisa":"biorxiv;2020.02.27.967505v2","processed":["highwire_math"],"markup":[{"requested":"full-text","variant":"full-text","view":"full","pisa":"biorxiv;2020.02.27.967505v2"}],"modal_window_width":"560","share_modal_width":"560","share_modal_title":"Share this Article"},"jcarousel":{"ajaxPath":"\/jcarousel\/ajax\/views"},"instances":"{\u0022highwire_abstract_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:20,\u0022height\u0022:20,\u0022border\u0022:1,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-abstract-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-abstract-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022right center\u0022,\u0022my\u0022:\u0022left center\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022shift\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter click \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}},\u0022highwire_author_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:15,\u0022height\u0022:15,\u0022border\u0022:1,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-author-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-author-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022top center\u0022,\u0022my\u0022:\u0022bottom center\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}},\u0022highwire_reflinks_tooltip\u0022:{\u0022content\u0022:{\u0022text\u0022:\u0022\u0022},\u0022style\u0022:{\u0022tip\u0022:{\u0022width\u0022:15,\u0022height\u0022:15,\u0022border\u0022:1,\u0022mimic\u0022:\u0022top center\u0022,\u0022offset\u0022:0,\u0022corner\u0022:true},\u0022classes\u0022:\u0022qtip-custom hw-tooltip hw-ref-link-tooltip qtip-shadow qtip-rounded\u0022,\u0022classes_custom\u0022:\u0022hw-tooltip hw-ref-link-tooltip\u0022},\u0022position\u0022:{\u0022at\u0022:\u0022bottom left\u0022,\u0022my\u0022:\u0022top left\u0022,\u0022viewport\u0022:true,\u0022adjust\u0022:{\u0022method\u0022:\u0022flip\u0022}},\u0022show\u0022:{\u0022event\u0022:\u0022mouseenter \u0022,\u0022solo\u0022:true},\u0022hide\u0022:{\u0022event\u0022:\u0022mouseleave \u0022,\u0022fixed\u0022:1,\u0022delay\u0022:\u0022100\u0022}}}","qtipDebug":"{\u0022leaveElement\u0022:0}","panel_ajax_tab":{"path":"sites\/all\/modules\/contrib\/panels_ajax_tab"},"disqus":{"domain":"biorxivstage","url":"https:\/\/www.biorxiv.org\/content\/10.1101\/2020.02.27.967505v2","title":"Improving the validity of neuroimaging decoding tests of invariant and configural neural representation","identifier":"node\/2498488"},"panels_ajax_pane":{"new-28877068-b9cb-4641-830b-b6b4638c98bb":"{\u0022encrypted\u0022:\u0022{\\\u0022encrypted\\\u0022:\\\u0022GQqUuDUkx7kl+hoY4xAcn\\\\\\\/3QlesG2KcSvStUO0S4wDZ47fW5EJMqwp\\\\\\\/qxERkpE58FkByqokc4zmtFFP7lStu9phCqrsjGQJkNb3a9qbjOxRQobSwMSitsh1lHnzz2R5ZVDpb\\\\\\\/OclAWFDx\\\\\\\/cNE3jwd7orfcBUkxlGJWJ6\\\\\\\/w5pjhvtL5RXukqw1eJQqayFxYhTB0pInnAZ8tOyA+sZtb6lG4E1YV6HOw6boW1zpVfIRx1ZPnAsxXJe85TZJMjSdB\\\\\\\/3tsXFi8PUjJ0vCzKHrqdsfksdlPKPzPEv0WThHFBtHtlAZBQItGymKIH9ZEZJTRZGV5K1mZcYiEhH2vllW7m6Y64JRlBpW0l60S7GiVEe5ZQ7lXYUJ3oJmYmZDMx1pnjyuCUTjg8f8Nvj6VCu\\\\\\\/Oub8LGiL6DEKvaeVMxf2W6As4hLqgtzs0JFzWCTeHVrWWhDsf8\\\\\\\/6zDman1nyS8XV+HGj\\\\\\\/BYmcj9PaQL1EpQBs9DlRAy9XsR6rS2UHYeRpGTz43jjF8XxvScy87uyXxVp2htdX5g7a6Dy3ra+D56m0G9vmS9gHgeLYq7BWlz+FGISbqEhgtPaAolQr\\\\\\\/8LIU\\\\\\\/AIxlkwbyhWa6u+KoASmVCjk3Ey8dz7Bx33oIXh5\\\\\\\/qIwQSo2tGSap+MDeteeAw\\\\\\\/+TNmL\\\\\\\/Rv+uuwZZAg1d7LwXo6ETMGS1GEeZe2Zlsi3igLQjIkx0jUp9C\\\\\\\/JX3gJMb2nA\\\\\\\/SJ+O0mVDSc59h0GM9+3NJ7sT2oKk7WaD\\\\\\\/WvEqUl+zkzgVk04ZTXPl1fkVDgP2bs7K2JeZ4Bcj3rJ5GJwwMK1rMpMoYHtza97T0zOpreJwtbZRwt76\\\\\\\/QoUXLxF8bpNHeog0LZkinZXTwXXXssfFjWc8hZMFnl2CzPfAWcoDHDhjomDKr\\\\\\\/VdfsAndDOFybsbPz4YyPYRfNwkzCzVkboyZVe8FWO365NsPtPlThztzfJLCZfDSCr9LwZxJOs6xaC4WyS6+XvxjZSlUr8Hv63+\\\\\\\/O6RELrETQVIALrMeYux13XRTO2Z7+5L+my2ejAa1Q3K6NqM3s4V6Nu04mq3R\\\\\\\/80+OaUAFDdCJ5hdYsBGvqUmqnY1HzrGGGzdS0LfFZIe9XOEGsbIRJlyEXNiU2f0n5ZCouqqi3S\\\\\\\/3sNAtRhd8\\\\\\\/WVzqz42wjIGtYyss8WeN8jYJDwcsLh+tUNiul\\\\\\\/2O2VFbi7i59D54U4Yk6DFdi5VT24nDAc9KpomYYaxEyJ86eo8lSQ8\\\\\\\/qwQ0wqWS7TiSz7H5WKkglxSi0Ob7eQfZk7ZPTssrKg2CLZDDUAlOZ5V5zXZueHMvLEesKHG2LQry0cHV5zM+Gfff7AF7EDW5IR6TmXceqBV3DBRynkeaU8OC+sjs\\\\\\\/dLGU3SXgh7Ya7P4qJGxAdNcQ5G94=\\\u0022,\\\u0022iv\\\u0022:\\\u0022Hs6qVxSet\\\\\\\/E98SNembrT6g==\\\u0022,\\\u0022salt\\\u0022:\\\u0022f9d8845712f72c9fee5db7d9ff111eab\\\u0022}\u0022,\u0022hmac\u0022:\u0022585ec67307ebf0567e62678967c43f609d850a287b09af337e9c72c34ccb4a81\u0022}"},"urlIsAjaxTrusted":{"\/content\/10.1101\/2020.02.27.967505v2.full":true},"ws_fl":{"width":100,"height":21},"ws_gpo":{"size":"","annotation":"","lang":"","callback":"","width":300},"color":{"logo":"https:\/\/www.biorxiv.org\/sites\/default\/files\/bioRxiv_article.jpg"},"highwire_list_expand":{"is_collapsed":"1"},"highwireResponsive":{"enquire_enabled":1,"breakpoints_configured":1,"breakpoints":{"zero":"all and (min-width: 0px)","xsmall":"all and (min-width: 380px)","narrow":"all and (min-width: 768px) and (min-device-width: 768px), (max-device-width: 800px) and (min-width: 768px) and (orientation:landscape)","normal":"all and (min-width: 980px) and (min-device-width: 980px), all and (max-device-width: 1024px) and (min-width: 1024px) and (orientation:landscape)","wide":"all and (min-width: 1220px)"}},"eu_cookie_compliance":{"popup_enabled":1,"popup_agreed_enabled":0,"popup_hide_agreed":0,"popup_clicking_confirmation":1,"popup_scrolling_confirmation":false,"popup_html_info":"\u003Cdiv\u003E\n  \u003Cdiv class =\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Cp\u003EWe use cookies on this site to enhance your user experience. By clicking any link on this page you are giving your consent for us to set cookies.\u003C\/p\u003E\n    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022agree-button eu-cookie-compliance-default-button\u0022\u003EContinue\u003C\/button\u003E\n                    \u003Cbutton type=\u0022button\u0022 class=\u0022find-more-button eu-cookie-compliance-more-button\u0022\u003EFind out more\u003C\/button\u003E\n          \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E","use_mobile_message":false,"mobile_popup_html_info":"\u003Cdiv\u003E\n  \u003Cdiv class =\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n          \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022agree-button eu-cookie-compliance-default-button\u0022\u003EContinue\u003C\/button\u003E\n                    \u003Cbutton type=\u0022button\u0022 class=\u0022find-more-button eu-cookie-compliance-more-button\u0022\u003EFind out more\u003C\/button\u003E\n          \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E\n","mobile_breakpoint":"768","popup_html_agreed":"\u003Cdiv\u003E\n  \u003Cdiv class=\u0022popup-content agreed\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Ch2\u003EThank you for accepting cookies\u003C\/h2\u003E\u003Cp\u003EYou can now hide this message or find out more about cookies.\u003C\/p\u003E    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022hide-popup-button eu-cookie-compliance-hide-button\u0022\u003EHide\u003C\/button\u003E\n              \u003Cbutton type=\u0022button\u0022 class=\u0022find-more-button eu-cookie-compliance-more-button-thank-you\u0022 \u003EMore info\u003C\/button\u003E\n          \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E","popup_use_bare_css":false,"popup_height":"auto","popup_width":"100%","popup_delay":1000,"popup_link":"\/help\/cookie-policy","popup_link_new_window":1,"popup_position":null,"popup_language":"en","store_consent":false,"better_support_for_screen_readers":0,"reload_page":0,"domain":"","popup_eu_only_js":0,"cookie_lifetime":"365","cookie_session":false,"disagree_do_not_show_popup":0,"method":"default","whitelisted_cookies":"","withdraw_markup":"\u003Cbutton type=\u0022button\u0022 class=\u0022eu-cookie-withdraw-tab\u0022\u003EPrivacy settings\u003C\/button\u003E\n\u003Cdiv class=\u0022eu-cookie-withdraw-banner\u0022\u003E\n  \u003Cdiv class=\u0022popup-content info\u0022\u003E\n    \u003Cdiv id=\u0022popup-text\u0022\u003E\n      \u003Cp\u003E\u0026lt;h2\u0026gt;We use cookies on this site to enhance your user experience\u0026lt;\/h2\u0026gt;\u0026lt;p\u0026gt;You have given your consent for us to set cookies.\u0026lt;\/p\u0026gt;\u003C\/p\u003E\n    \u003C\/div\u003E\n    \u003Cdiv id=\u0022popup-buttons\u0022\u003E\n      \u003Cbutton type=\u0022button\u0022 class=\u0022eu-cookie-withdraw-button\u0022\u003EWithdraw consent\u003C\/button\u003E\n    \u003C\/div\u003E\n  \u003C\/div\u003E\n\u003C\/div\u003E\n","withdraw_enabled":false},"googleanalytics":{"trackOutbound":1,"trackMailto":1,"trackDownload":1,"trackDownloadExtensions":"7z|aac|arc|arj|asf|asx|avi|bin|csv|doc(x|m)?|dot(x|m)?|exe|flv|gif|gz|gzip|hqx|jar|jpe?g|js|mp(2|3|4|e?g)|mov(ie)?|msi|msp|pdf|phps|png|ppt(x|m)?|pot(x|m)?|pps(x|m)?|ppam|sld(x|m)?|thmx|qtm?|ra(m|r)?|sea|sit|tar|tgz|torrent|txt|wav|wma|wmv|wpd|xls(x|m|b)?|xlt(x|m)|xlam|xml|z|zip","trackColorbox":1,"trackUrlFragments":1},"jnl_biorxiv_styles":{"defaultJCode":"biorxiv"},"omega":{"layouts":{"primary":"normal","order":["narrow","normal","wide"],"queries":{"narrow":"all and (min-width: 768px) and (min-device-width: 768px), (max-device-width: 800px) and (min-width: 768px) and (orientation:landscape)","normal":"all and (min-width: 980px) and (min-device-width: 980px), all and (max-device-width: 1024px) and (min-width: 1024px) and (orientation:landscape)","wide":"all and (min-width: 1220px)"}}}});
//--&gt;&lt;!]]&gt;
  </script>
 </head>
 <body class="html not-front not-logged-in page-node page-node- page-node-2498488 node-type-highwire-article context-content hw-default-jcode-biorxiv hw-article-type-article hw-article-category-new-results">
  <noscript>
   <iframe src="//www.googletagmanager.com/ns.html?id=GTM-M677548" height="0" width="0" style="display:none;visibility:hidden">
   </iframe>
  </noscript>
  <script type="text/javascript">
   (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0];var j=d.createElement(s);var dl=l!='dataLayer'?'&amp;l='+l:'';j.src='//www.googletagmanager.com/gtm.js?id='+i+dl;j.type='text/javascript';j.async=true;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-M677548');
  </script>
  <div id="skip-link">
   <a href="#main-content" class="element-invisible element-focusable">
    Skip to main content
   </a>
  </div>
  <div class="page clearfix page-box-shadows footer-borders panels-page panels-layout-jcore_2col" id="page">
   <header id="section-header" class="section section-header">
    <div id="zone-branding" class="zone zone-branding clearfix print-display-block container-30">
     <div class="grid-15 prefix-1 region region-branding print-display-block" id="region-branding">
      <div class="region-inner region-branding-inner">
       <div class="branding-data clearfix">
        <div class="logo-img">
         <a href="/" rel="home" class="" data-icon-position="" data-hide-link-title="0">
          <img alt="bioRxiv" src="https://www.biorxiv.org/sites/default/files/bioRxiv_article.jpg"/>
         </a>
        </div>
       </div>
      </div>
     </div>
     <div class="grid-11 suffix-1 region region-branding-second print-hidden" id="region-branding-second">
      <div class="region-inner region-branding-second-inner">
       <div class="block block-system block-menu block-main-menu block-system-main-menu odd block-without-title" id="block-system-main-menu">
        <div class="block-inner clearfix">
         <div class="content clearfix">
          <nav class="menubar-nav">
           <ul class="menu" role="menu">
            <li class="first leaf" role="menuitem">
             <a href="/" title="" class="" data-icon-position="" data-hide-link-title="0">
              Home
             </a>
            </li>
            <li class="leaf" role="menuitem">
             <a href="/about-biorxiv" class="" data-icon-position="" data-hide-link-title="0">
              About
             </a>
            </li>
            <li class="leaf" role="menuitem">
             <a href="/submit-a-manuscript" class="" data-icon-position="" data-hide-link-title="0">
              Submit
             </a>
            </li>
            <li class="last leaf" role="menuitem">
             <a href="/content/alertsrss" title="" class="" data-icon-position="" data-hide-link-title="0">
              ALERTS / RSS
             </a>
            </li>
           </ul>
          </nav>
         </div>
        </div>
       </div>
       <div class="block block-panels-mini block-biorxiv-search-box block-panels-mini-biorxiv-search-box even block-without-title" id="block-panels-mini-biorxiv-search-box">
        <div class="block-inner clearfix">
         <div class="content clearfix">
          <div class="panel-display panel-1col clearfix" id="mini-panel-biorxiv_search_box">
           <div class="panel-panel panel-col">
            <div>
             <div class="panel-pane pane-highwire-seach-quicksearch">
              <div class="pane-content">
               <form class="highwire-quicksearch button-style-mini button-style-mini" action="/content/10.1101/2020.02.27.967505v2.full" method="post" id="highwire-search-quicksearch-form-0" accept-charset="UTF-8">
                <div>
                 <div class="form-item form-item-label-invisible form-type-textfield form-item-keywords">
                  <label class="element-invisible" for="search_rightsidebar_keywords_846792413">
                   Search for this keyword
                  </label>
                  <input placeholder="Search" type="text" id="search_rightsidebar_keywords_846792413" name="keywords" value="" size="60" maxlength="128" class="form-text"/>
                 </div>
                 <div class="button-wrapper button-mini">
                  <span class="icon-search">
                  </span>
                  <input data-icon-only="1" data-font-icon="icon-search" data-icon-position="after" type="submit" id="search_rightsidebar_submit_1117977750" name="op" value="Search" class="form-submit"/>
                 </div>
                 <input type="hidden" name="form_build_id" value="form-fKIOFW7gImxDrk20UZZeol42s54uq3EPZ2v_u_4_DLs"/>
                 <input type="hidden" name="form_id" value="highwire_search_quicksearch_form_0"/>
                </div>
               </form>
              </div>
             </div>
             <div class="panel-separator">
             </div>
             <div class="panel-pane pane-custom pane-2 advanced-search-link">
              <div class="pane-content">
               <a href="/search">
                Advanced Search
               </a>
              </div>
             </div>
            </div>
           </div>
          </div>
         </div>
        </div>
       </div>
      </div>
     </div>
    </div>
    <div id="zone-header" class="zone zone-header clearfix container-30">
    </div>
   </header>
   <section id="section-content" class="section section-content">
    <div id="zone-content" class="zone zone-content clearfix container-30">
     <div class="grid-28 suffix-1 prefix-1 region region-content" id="region-content">
      <div class="region-inner region-content-inner">
       <a id="main-content">
       </a>
       <div class="block block-system block-main block-system-main odd block-without-title" id="block-system-main">
        <div class="block-inner clearfix">
         <div class="content clearfix">
          <div class="panel-display panels-960-layout jcore-2col-layout">
           <div class="panel-row-wrapper clearfix">
            <div class="main-content-wrapper grid-17 suffix-1 alpha">
             <div class="panel-panel panel-region-content">
              <div class="inside">
               <div class="panel-pane pane-highwire-article-citation">
                <div class="pane-content">
                 <div class="highwire-article-citation highwire-citation-type-highwire-article node2498488" data-node-nid="2498488" id="node-2498488--229655028" data-pisa="biorxiv;2020.02.27.967505v2" data-pisa-master="biorxiv;2020.02.27.967505" data-apath="/biorxiv/early/2022/04/15/2020.02.27.967505.atom" data-hw-author-tooltip-instance="highwire_author_tooltip">
                  <div class="highwire-cite highwire-cite-highwire-article highwire-citation-biorxiv-article-top clearfix has-author-tooltip">
                   <span class="biorxiv-article-type">
                    New Results
                   </span>
                   <h1 class="highwire-cite-title" id="page-title">
                    Improving the validity of neuroimaging decoding tests of invariant and configural neural representation
                   </h1>
                   <div class="highwire-cite-authors">
                    <span class="highwire-citation-authors">
                     <span class="highwire-citation-author first" data-delta="0">
                      <span class="nlm-given-names">
                       Fabian A.
                      </span>
                      <span class="nlm-surname">
                       Soto
                      </span>
                     </span>
                     ,
                     <span class="highwire-citation-author" data-delta="1">
                      <span class="nlm-given-names">
                       Sanjay
                      </span>
                      <span class="nlm-surname">
                       Narasiwodeyar
                      </span>
                     </span>
                    </span>
                   </div>
                   <div class="highwire-cite-metadata">
                    <span class="highwire-cite-metadata-doi highwire-cite-metadata">
                     <span class="label">
                      doi:
                     </span>
                     https://doi.org/10.1101/2020.02.27.967505
                    </span>
                   </div>
                  </div>
                  <div id="hw-article-author-popups-node-2498488--229655028" style="display: none;">
                   <div class="author-tooltip-0">
                    <div class="author-tooltip-name">
                     Fabian A. Soto
                    </div>
                    <div class="author-tooltip-affiliation">
                     <span class="author-tooltip-text">
                      <div class="author-affiliation">
                       <span class="nlm-institution">
                        Department of Psychology, Florida International University
                       </span>
                       , Modesto A. Maidique Campus, 11200 SW 8th St, Miami, FL 33199
                      </div>
                     </span>
                    </div>
                    <ul class="author-tooltip-find-more">
                     <li class="author-tooltip-gs-link first">
                      <a href="/lookup/google-scholar?link_type=googlescholar&gs_type=author&author%5B0%5D=Fabian%2BA.%2BSoto%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">
                       Find this author on Google Scholar
                      </a>
                     </li>
                     <li class="author-tooltip-pubmed-link">
                      <a href="/lookup/external-ref?access_num=Soto%20FA&link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">
                       Find this author on PubMed
                      </a>
                     </li>
                     <li class="author-site-search-link">
                      <a href="/search/author1%3AFabian%2BA.%2BSoto%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">
                       Search for this author on this site
                      </a>
                     </li>
                     <li class="author-corresp-email-link last">
                      <span>
                       For correspondence:
                       <a href="mailto:fasoto@fiu.edu" class="" data-icon-position="" data-hide-link-title="0">
                        fasoto@fiu.edu
                       </a>
                      </span>
                     </li>
                    </ul>
                   </div>
                   <div class="author-tooltip-1">
                    <div class="author-tooltip-name">
                     Sanjay Narasiwodeyar
                    </div>
                    <div class="author-tooltip-affiliation">
                     <span class="author-tooltip-text">
                      <div class="author-affiliation">
                       <span class="nlm-institution">
                        Department of Psychology, Florida International University
                       </span>
                       , Modesto A. Maidique Campus, 11200 SW 8th St, Miami, FL 33199
                      </div>
                     </span>
                    </div>
                    <ul class="author-tooltip-find-more">
                     <li class="author-tooltip-gs-link first">
                      <a href="/lookup/google-scholar?link_type=googlescholar&gs_type=author&author%5B0%5D=Sanjay%2BNarasiwodeyar%2B" target="_blank" class="" data-icon-position="" data-hide-link-title="0">
                       Find this author on Google Scholar
                      </a>
                     </li>
                     <li class="author-tooltip-pubmed-link">
                      <a href="/lookup/external-ref?access_num=Narasiwodeyar%20S&link_type=AUTHORSEARCH" target="_blank" class="" data-icon-position="" data-hide-link-title="0">
                       Find this author on PubMed
                      </a>
                     </li>
                     <li class="author-site-search-link last">
                      <a href="/search/author1%3ASanjay%2BNarasiwodeyar%2B" rel="nofollow" class="" data-icon-position="" data-hide-link-title="0">
                       Search for this author on this site
                      </a>
                     </li>
                    </ul>
                   </div>
                  </div>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-highwire-panel-tabs pane-panels-ajax-tab-tabs">
                <div class="pane-content">
                 <div class="item-list">
                  <ul class="tabs inline panels-ajax-tab">
                   <li class="first">
                    <a href="/content/10.1101/2020.02.27.967505v2" class="panels-ajax-tab-tab" data-panel-name="biorxiv_tab_art" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="" data-url-enabled="1">
                     Abstract
                    </a>
                    <a href="/panels_ajax_tab/biorxiv_tab_art/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                   <li>
                    <a href="/content/10.1101/2020.02.27.967505v2.full-text" class="panels-ajax-tab-tab" data-panel-name="article_tab_full_text" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="full-text" data-url-enabled="1">
                     Full Text
                    </a>
                    <a href="/panels_ajax_tab/article_tab_full_text/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                   <li>
                    <a href="/content/10.1101/2020.02.27.967505v2.article-info" class="panels-ajax-tab-tab" data-panel-name="biorxiv_tab_info" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="article-info" data-url-enabled="1">
                     Info/History
                    </a>
                    <a href="/panels_ajax_tab/biorxiv_tab_info/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                   <li>
                    <a href="/content/10.1101/2020.02.27.967505v2.article-metrics" class="panels-ajax-tab-tab" data-panel-name="article_tab_metrics" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="article-metrics" data-url-enabled="1">
                     Metrics
                    </a>
                    <a href="/panels_ajax_tab/article_tab_metrics/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                   <li>
                    <a href="/content/10.1101/2020.02.27.967505v2.supplementary-material" class="panels-ajax-tab-tab" data-panel-name="biorxiv_tab_data" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="supplementary-material" data-url-enabled="1">
                     Supplementary material
                    </a>
                    <a href="/panels_ajax_tab/biorxiv_tab_data/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                   <li class="last">
                    <a href="/content/10.1101/2020.02.27.967505v2.full.pdf+html" class="panels-ajax-tab-tab" data-panel-name="biorxiv_tab_pdf" data-target-id="highwire_article_tabs" data-entity-context="node:2498488" data-trigger="full.pdf+html" data-url-enabled="1">
                     <i class="icon-file-alt">
                     </i>
                     Preview PDF
                    </a>
                    <a href="/panels_ajax_tab/biorxiv_tab_pdf/node:2498488/1" rel="nofollow" style="display:none" class="js-crawler-link">
                    </a>
                   </li>
                  </ul>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-highwire-panel-tabs-container">
                <div class="pane-content">
                 <div data-panels-ajax-tab-preloaded="article_tab_full_text" id="panels-ajax-tab-container-highwire_article_tabs" class="panels-ajax-tab-container">
                  <div class="panels-ajax-tab-loading" style="display:none">
                   <img class="loading" src="https://www.biorxiv.org/sites/all/modules/contrib/panels_ajax_tab/images/loading.gif" alt="Loading" title="Loading"/>
                  </div>
                  <div class="panels-ajax-tab-wrap-article_tab_full_text">
                   <div class="panel-display panel-1col clearfix">
                    <div class="panel-panel panel-col">
                     <div>
                      <div class="panel-pane pane-highwire-markup">
                       <div class="pane-content">
                        <div class="highwire-markup">
                         <div xmlns="http://www.w3.org/1999/xhtml" data-highwire-cite-ref-tooltip-instance="highwire_reflinks_tooltip" class="content-block-markup" xmlns:xhtml="http://www.w3.org/1999/xhtml">
                          <div class="article fulltext-view">
                           <span class="highwire-journal-article-marker-start">
                           </span>
                           <div class="section abstract" id="abstract-1">
                            <h2 class="">
                             Abstract
                            </h2>
                            <p id="p-2">
                             Many research questions in sensory neuroscience involve determining whether the neural representation of a stimulus property is invariant or specific to a particular stimulus context (e.g., Is object representation invariant to translation? Is the representation of a face feature specific to the context of other face features?). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging studies have used operational tests in which a target property is inferred from a significant test against the null hypothesis of the opposite property. For example, the popular cross-classification test concludes that representations are invariant or tolerant when the null hypothesis of specificity is rejected. A recently developed neurocomputational theory provides two insights regarding such tests. First, tests against the null of context-specificity, and for the alternative of context-invariance, are prone to false positives due to the way in which the underlying neural representations are transformed into indirect measurements in neuroimaging studies. Second, jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. Here, we provide empirical and computational evidence supporting both of these theoretical insights. In our empirical study, we use encoding of orientation and spatial position in primary visual cortex as a case study, as previous research has established that these properties are encoded in a context-sensitive way. Using fMRI decoding, we show that the cross-classification test produces false-positive conclusions of invariance, but that more valid conclusions can be reached by jointly performing tests against the null of invariance. The results of two simulations further support both of these conclusions. We conclude that more valid inferences about invariance or specificity of neural representations can be reached by jointly testing against both hypotheses, and using neurocomputational theory to guide the interpretation of results.
                            </p>
                            <div id="sec-1" class="subsection">
                             <p id="p-3">
                              <strong>
                               Author Summary
                              </strong>
                              Many research questions in sensory neuroscience involve determining whether the representation of a stimulus property is invariant or specific to a change in stimulus context (e.g., translation-invariant object representation; configural representation of face features). Between these two extremes, representations may also be context-tolerant or context-sensitive. Most neuroimaging research has studied invariance using operational tests, among which the most widely used in recent years is cross-classification. We provide evidence from a functional MRI study, simulations, and theoretical results supporting two insights regarding such tests: (1) tests that seek to provide evidence for invariance (like cross-classification) have an inflated false positive rate, but (2) using complementary tests that seek evidence for context-specificity leads to more valid conclusions.
                             </p>
                            </div>
                           </div>
                           <div class="section" id="sec-2">
                            <h2 class="">
                             Introduction
                            </h2>
                            <p id="p-5">
                             A common question in sensory and cognitive neuroscience is to what extent the neural representation of a stimulus property changes as a function of changes in other aspects of stimulation–that is, the context in which it is presented–. As shown in
                             <a id="xref-fig-1-1" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             , one possibility is that the neural representation of the target property is invariant to changes in context. In that case, the neural activity representing the target property does not change at all with changes in context. Another possibility is that the neural representation of the target property is context-specific. In that case, the neural activity representing the target property completely changes with a change in context. Another way to describe context-specificity is by saying that the target property and its context are represented configurally; that is, as a configuration separate from its components. As shown in
                             <a id="xref-fig-1-2" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             , these two cases of complete invariance and specificity should be seen as extremes in a continuum. In this continuum, representations that are closer to invariance could be characterized as “tolerant” to changes in context, whereas representations that are closer to specificity could be characterized as “sensitive” to changes in context.
                            </p>
                            <div id="F1" class="fig pos-float type-figure odd">
                             <div class="highwire-figure">
                              <div class="fig-inline-img-wrapper">
                               <div class="fig-inline-img">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F1.large.jpg?width=800&height=600&carousel=1" title="Encoding of a target feature by a group of neurons can have varying degrees of change as a function of a change in context. With a change in context, context-invariant representations do not change at all, whereas context-specific representations change completely. There is a continuum between both extremes, which includes the more likely cases of context-tolerance and context-sensitivity. A significant test against the null hypothesis of context specificity, such as that provided by the cross-classification test, is usually interpreted as favoring invariance although the representation can be anywhere from sensitive to invariant. Similarly, a significant test against the null of context invariance can be obtained from representations ranging from tolerant to specific. We propose that jointly performing both types of test considerably increases the validity of our conclusions regarding the underlying representations." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Encoding of a target feature by a group of neurons can have varying degrees of change as a function of a change in context. With a change in context, context-invariant representations do not change at all, whereas context-specific representations change completely. There is a continuum between both extremes, which includes the more likely cases of context-tolerance and context-sensitivity. A significant test against the null hypothesis of context specificity, such as that provided by the cross-classification test, is usually interpreted as favoring invariance although the representation can be anywhere from sensitive to invariant. Similarly, a significant test against the null of context invariance can be obtained from representations ranging from tolerant to specific. We propose that jointly performing both types of test considerably increases the validity of our conclusions regarding the underlying representations.</div>' data-icon-position="" data-hide-link-title="0">
                                 <span class="hw-responsive-img">
                                  <img class="highwire-fragment fragment-image lazyload" alt="Figure 1:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F1.medium.gif" width="440" height="277"/>
                                  <noscript>
                                   <img class="highwire-fragment fragment-image" alt="Figure 1:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F1.medium.gif" width="440" height="277"/>
                                  </noscript>
                                 </span>
                                </a>
                               </div>
                              </div>
                              <ul class="highwire-figure-links inline">
                               <li class="download-fig first">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F1.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 1:" data-icon-position="" data-hide-link-title="0">
                                 Download figure
                                </a>
                               </li>
                               <li class="new-tab last">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F1.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                 Open in new tab
                                </a>
                               </li>
                              </ul>
                             </div>
                             <div class="fig-caption" xmlns:xhtml="http://www.w3.org/1999/xhtml">
                              <span class="fig-label">
                               Figure 1:
                              </span>
                              <p id="p-6" class="first-child">
                               Encoding of a target feature by a group of neurons can have varying degrees of change as a function of a change in context. With a change in context, context-invariant representations do not change at all, whereas context-specific representations change completely. There is a continuum between both extremes, which includes the more likely cases of context-tolerance and context-sensitivity. A significant test against the null hypothesis of context specificity, such as that provided by the cross-classification test, is usually interpreted as favoring invariance although the representation can be anywhere from sensitive to invariant. Similarly, a significant test against the null of context invariance can be obtained from representations ranging from tolerant to specific. We propose that jointly performing both types of test considerably increases the validity of our conclusions regarding the underlying representations.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-7">
                             Most human neuroimaging research has studied invariance and specificity using operational tests that provide evidence against the null hypotheses represented by the two extremes in
                             <a id="xref-fig-1-3" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             . This choice is paradoxical, as most neuroscientists are more interested in determining to what extent a representation is closer to one of the extremes in the continuum, being classified as either context-tolerant or context-sensitive.
                            </p>
                            <p id="p-8">
                             For example, probably the most widely used test in this area is cross-classification (or cross-decoding; 1, 2, 3; we have also called this test classification accuracy generalization: [
                             <a id="xref-ref-4-1" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ]), illustrated in
                             <a id="xref-fig-2-1" class="xref-fig" href="#F2">
                              Figure 2
                             </a>
                             . The first step in cross-classification is to train a classifier to decode a particular stimulus feature, such as whether a presented face is male or female, from patterns of fMRI activity observed across voxels. The second step is to test the trained classifier with new patterns of fMRI activity, this time obtained from presentation of the same stimuli, but changed in an irrelevant property, such as head orientation. Using our nomenclature, in this example the target stimulus property is face sex, and the context is face orientation. If accuracy with the test data is higher than chance, then researchers usually conclude that the neural representation of the target feature has a certain level of tolerance to changes in context (usually described as invariance), within the area from which the fMRI activity was obtained.
                            </p>
                            <div id="F2" class="fig pos-float type-figure odd">
                             <div class="highwire-figure">
                              <div class="fig-inline-img-wrapper">
                               <div class="fig-inline-img">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F2.large.jpg?width=800&height=600&carousel=1" title="Cross-classification test. (1) A classifier is trained to discriminate between levels of a target dimension (facial gender) in a given level of the context dimension (viewpoint). The axes represent activity in two exemplary voxels in response to stimuli. Each data point represents a single trial. (2) The same classifier is then used to classify data from a second level of the context dimension (different viewpoint). (3) If classification accuracy is above chance levels across viewpoints, then invariance is said to hold according to this test." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Cross-classification test. (1) A classifier is trained to discriminate between levels of a target dimension (facial gender) in a given level of the context dimension (viewpoint). The axes represent activity in two exemplary voxels in response to stimuli. Each data point represents a single trial. (2) The same classifier is then used to classify data from a second level of the context dimension (different viewpoint). (3) If classification accuracy is above chance levels across viewpoints, then invariance is said to hold according to this test.</div>' data-icon-position="" data-hide-link-title="0">
                                 <span class="hw-responsive-img">
                                  <img class="highwire-fragment fragment-image lazyload" alt="Figure 2:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F2.medium.gif" width="440" height="251"/>
                                  <noscript>
                                   <img class="highwire-fragment fragment-image" alt="Figure 2:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F2.medium.gif" width="440" height="251"/>
                                  </noscript>
                                 </span>
                                </a>
                               </div>
                              </div>
                              <ul class="highwire-figure-links inline">
                               <li class="download-fig first">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F2.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 2:" data-icon-position="" data-hide-link-title="0">
                                 Download figure
                                </a>
                               </li>
                               <li class="new-tab last">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F2.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                 Open in new tab
                                </a>
                               </li>
                              </ul>
                             </div>
                             <div class="fig-caption">
                              <span class="fig-label">
                               Figure 2:
                              </span>
                              <p id="p-9" class="first-child">
                               Cross-classification test. (1) A classifier is trained to discriminate between levels of a target dimension (facial gender) in a given level of the context dimension (viewpoint). The axes represent activity in two exemplary voxels in response to stimuli. Each data point represents a single trial. (2) The same classifier is then used to classify data from a second level of the context dimension (different viewpoint). (3) If classification accuracy is above chance levels across viewpoints, then invariance is said to hold according to this test.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-10">
                             The cross-classification test has been used to provide evidence for tolerant encoding of face identity across viewpoint [
                             <a id="xref-ref-5-1" class="xref-bibr" href="#ref-5">
                              5
                             </a>
                             ], object category and viewpoint across spatial position [
                             <a id="xref-ref-6-1" class="xref-bibr" href="#ref-6">
                              6
                             </a>
                             ], object category across shape [and vice-versa; 7], motor actions across modalities [
                             <a id="xref-ref-8-1" class="xref-bibr" href="#ref-8">
                              8
                             </a>
                             ], place of speech articulation features across manner of articulation [
                             <a id="xref-ref-9-1" class="xref-bibr" href="#ref-9">
                              9
                             </a>
                             ], object category [
                             <a id="xref-ref-10-1" class="xref-bibr" href="#ref-10">
                              10
                             </a>
                             ] or face identity [
                             <a id="xref-ref-11-1" class="xref-bibr" href="#ref-11">
                              11
                             </a>
                             ] across stimulus modality, word semantic category across stimulus modality [
                             <a id="xref-ref-12-1" class="xref-bibr" href="#ref-12">
                              12
                             </a>
                             ], learned category labels across categorization tasks [
                             <a id="xref-ref-13-1" class="xref-bibr" href="#ref-13">
                              13
                             </a>
                             ], and semantic word representation across languages [
                             <a id="xref-ref-14-1" class="xref-bibr" href="#ref-14">
                              14
                             </a>
                             ], among others [for a review, see 3].
                            </p>
                            <p id="p-11">
                             Cross classification is a test against the null hypothesis of no generalization of decoding accuracy from one context to another, a condition that would be met under context-specific encoding of the target property. As shown in
                             <a id="xref-fig-1-4" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             , evidence against the extreme of context-specificity means that the representation can fall anywhere in the continuum except the right extreme. Invariance and tolerance are only some of the possibilities, as representations may also be context-sensitive.
                            </p>
                            <p id="p-12">
                             An example of a test that provides evidence against the null hypothesis of invariance is the classification accuracy invariance test [
                             <a id="xref-ref-4-2" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ]. This test involves the same steps described for cross-classification in
                             <a id="xref-fig-2-2" class="xref-fig" href="#F2">
                              Figure 2
                             </a>
                             , but during the test phase the classifier is presented with data obtained at both the training and the testing context levels (i.e., levels 1 and 2 in
                             <a id="xref-fig-2-3" class="xref-fig" href="#F2">
                              Figure 2
                             </a>
                             ). The null hypothesis is that decoding accuracy is equivalent across all levels of context. When accuracy drops significantly from training to testing context, one can conclude that the underlying representation of the decoded property is not invariant to context. While the test was independently developed from theory [
                             <a id="xref-ref-4-3" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ], we are aware of at least one prior study using a version of this test to obtain evidence of position-dependent encoding of object category information in lateral occipital cortex, and of position-dependent encoding of face viewpoint information in right fusiform face area [
                             <a id="xref-ref-6-2" class="xref-bibr" href="#ref-6">
                              6
                             </a>
                             ].
                            </p>
                            <p id="p-13">
                             Again, evidence against the extreme of context-invariance means that the representation can fall anywhere else in the continuum shown in
                             <a id="xref-fig-1-5" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             . Context specificity is only one of the possibilities, as representations may also be context-sensitive or context-tolerant.
                            </p>
                            <p id="p-14">
                             In a previous theoretical paper [
                             <a id="xref-ref-4-4" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ], we explored to what extent the context tolerance or specificity of neural representations could be measured using a variety of neuroimaging analyses, with a focus on decoding tests like cross-classification and classification accuracy invariance. Because neuroimaging involves only indirect measures of neural activity, it cannot be used to get precise indicators of where a neural representation falls within the continuum shown in
                             <a id="xref-fig-1-6" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             . In general, the process by which neural representations are transformed from the neural space into a space of measurements (e.g., voxel activities) will distort the representations in such a way that makes such precise indicators impossible. However, the results of neuroimaging decoding tests like those just described do allow to make some inferences about the underlying neural representations. Besides clarifying what different tests measure (i.e., cross-classification provides evidence against context-specificity, rather than evidence for invariance), this theoretical work provides two important insights that have consequences for the way in which neuroimaging researchers should apply and interpret the results of decoding tests.
                            </p>
                            <p id="p-15">
                             The first theoretical insight is that jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations. When both types of tests are carried out, one can use
                             <a id="xref-table-wrap-1-1" class="xref-table" href="#T1">
                              Table 1
                             </a>
                             to reach valid conclusions about properties of the underlying neural code. For example, one may use the cross-classification test to obtain evidence against context-specificity, but usually researchers who use this test are interested in reaching a conclusion favoring invariance or tolerance [e.g., 5, 3]. For that, information from a test against invariance would be very useful. If a test against invariance is not significant, one can make a stronger case for tolerant representations. Because sample size and measurement noise are equivalent in this test and the significant cross-classification test, the best interpretation is that the underlying representation is likely to be farther away from specificity than from invariance, being tolerant/invariant rather than sensitive. On the other hand, if the test offers evidence against invariance, then the underlying representations could be anywhere in the continuum shown in
                             <a id="xref-fig-1-7" class="xref-fig" href="#F1">
                              Figure 1
                             </a>
                             , except at the two extremes, and it would be premature to make a conclusion of tolerance in the underlying representations, as they are equally likely to be context-sensitive. Because tests against invariance have been rarely used in the literature, one goal of the current study is to provide evidence of the validity of such tests.
                            </p>
                            <div id="T1" class="table pos-float">
                             <div class="table-inline table-callout-links">
                              <div class="callout">
                               <span>
                                View this table:
                               </span>
                               <ul class="callout-links">
                                <li class="view-inline first">
                                 <a href="##" class="table-expand-inline" data-table-url="/highwire/markup/2502800/expansion?postprocessors=highwire_tables%2Chighwire_reclass%2Chighwire_figures%2Chighwire_math%2Chighwire_inline_linked_media%2Chighwire_embed&table-expand-inline=1" data-icon-position="" data-hide-link-title="0">
                                  View inline
                                 </a>
                                </li>
                                <li class="view-popup">
                                 <a href="/highwire/markup/2502800/expansion?width=1000&height=500&iframe=true&postprocessors=highwire_tables%2Chighwire_reclass%2Chighwire_figures%2Chighwire_math%2Chighwire_inline_linked_media%2Chighwire_embed" class="colorbox colorbox-load table-expand-popup" rel="gallery-fragment-tables" data-icon-position="" data-hide-link-title="0">
                                  View popup
                                 </a>
                                </li>
                                <li class="download-ppt last">
                                 <a href="/highwire/powerpoint/2502800" class="highwire-figure-link highwire-figure-link-ppt" data-icon-position="" data-hide-link-title="0">
                                  Download powerpoint
                                 </a>
                                </li>
                               </ul>
                              </div>
                             </div>
                             <div class="table-caption">
                              <span class="table-label">
                               Table 1:
                              </span>
                              <p id="p-16" class="first-child">
                               Lookup table summarizing how joint tests against specificity and invariance should be interpreted. Note that significance of the popular cross-classification test does not guarantee a conclusion for tolerance or invariance. Only when such a test is accompanied by a nonsignificant test against invariance one can reach a positive conclusion.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-17">
                             The second theoretical insight is that there is an important asymmetry regarding the validity of tests of invariance and context-specificity. If the underlying neural representation is truly invariant, then a signal showing evidence against invariance will never be found from neuroimaging decoding tests. In this case, any finding of lack of invariance would result from measurement noise, and the probability of such finding would be equal to the false positive (type I) error rate of the statistical test, usually α = .05. On the other hand, if the underlying representation is truly context-specific, it is still possible to find a signal at the level of voxels showing evidence against context-sensitivity. In this case, such a signal will add to the probability of false positives, which would be higher than α.
                            </p>
                            <p id="p-18">
                             The reason lies in the contribution of the measurement model, which summarizes how representations are transformed from the space of neural representations into the space of measured variables.
                             <a id="xref-fig-3-1" class="xref-fig" href="#F3">
                              Figure 3
                             </a>
                             depicts a schematic example, where representations of the target stimuli in one context (e.g., faces with front orientation) are shown as red circles, and representations in a second context (e.g., faces with sideways orientation) are shown as green crosses. In panel (a), the original neural representations are fully context-invariant, meaning that the representation of a stimulus in either context is in the exact same point in neural space. Regardless of what transformation is induced by the measurement model, such representations will remain invariant in the measurement space, as the transformation will have the same effect on two identical representations (i.e., overlapping crosses and circles in
                             <a id="xref-fig-3-2" class="xref-fig" href="#F3">
                              Figure 3
                             </a>
                             ). In panel (b), the original representations are fully context-specific, meaning that the stimulus representations occupy completely different regions of space depending on context. In this case, there are transformations that would reduce differences in the representation of stimuli across contexts, making the representations less context-specific. In sum, the transformation from neural space to measurement space (i.e., the measurement model) cannot make a completely invariant representation appear as if it was sensitive to context, but it can make a completely context-specific representation appear as if it was tolerant to changes in context.
                            </p>
                            <div id="F3" class="fig pos-float type-figure odd">
                             <div class="highwire-figure">
                              <div class="fig-inline-img-wrapper">
                               <div class="fig-inline-img">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F3.large.jpg?width=800&height=600&carousel=1" title="A measurement model represents how representations are transformed from the space of neural activities to the space of voxel measurements. The outcome of this transformation has an asymmetrical effect on context-invariant and context-specific representations. Context-invariant representations (a) cannot be transformed in such a way to decrease their invariance and increase their specificity. On the other hand, context-specific representations (b) can be transformed to increase their invariance and decrease their specificity. The result is that there is an inflated risk to find false positive invariance in neuroimaging studies such as those using the cross-classification test." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">A measurement model represents how representations are transformed from the space of neural activities to the space of voxel measurements. The outcome of this transformation has an asymmetrical effect on context-invariant and context-specific representations. Context-invariant representations (a) cannot be transformed in such a way to decrease their invariance and increase their specificity. On the other hand, context-specific representations (b) can be transformed to increase their invariance and decrease their specificity. The result is that there is an inflated risk to find false positive invariance in neuroimaging studies such as those using the cross-classification test.</div>' data-icon-position="" data-hide-link-title="0">
                                 <span class="hw-responsive-img">
                                  <img class="highwire-fragment fragment-image lazyload" alt="Figure 3:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F3.medium.gif" width="440" height="269"/>
                                  <noscript>
                                   <img class="highwire-fragment fragment-image" alt="Figure 3:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F3.medium.gif" width="440" height="269"/>
                                  </noscript>
                                 </span>
                                </a>
                               </div>
                              </div>
                              <ul class="highwire-figure-links inline">
                               <li class="download-fig first">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F3.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 3:" data-icon-position="" data-hide-link-title="0">
                                 Download figure
                                </a>
                               </li>
                               <li class="new-tab last">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F3.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                 Open in new tab
                                </a>
                               </li>
                              </ul>
                             </div>
                             <div class="fig-caption">
                              <span class="fig-label">
                               Figure 3:
                              </span>
                              <p id="p-19" class="first-child">
                               A measurement model represents how representations are transformed from the space of neural activities to the space of voxel measurements. The outcome of this transformation has an asymmetrical effect on context-invariant and context-specific representations. Context-invariant representations (a) cannot be transformed in such a way to decrease their invariance and increase their specificity. On the other hand, context-specific representations (b) can be transformed to increase their invariance and decrease their specificity. The result is that there is an inflated risk to find false positive invariance in neuroimaging studies such as those using the cross-classification test.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-20">
                             This can happen in a number of ways, but the simplest example is one in which encoding of the target property is spatially smooth across voxels, while changes in context produce changes in the spatial distribution of activity that are fine-grained [
                             <a id="xref-ref-15-1" class="xref-bibr" href="#ref-15">
                              15
                             </a>
                             ]. Take the example shown in
                             <a id="xref-fig-4-1" class="xref-fig" href="#F4">
                              Figure 4
                             </a>
                             . Each column in the figure represents a different voxel, which itself contains a large number of neurons (or neural populations), represented by small circles, with selectivity for some target stimulus property. In this simplified example, the neurons can show preference for one of two values of the target property, represented by the colors red and yellow. Neurons can be inactive in a particular context, which is represented by the color gray. Different voxels have different proportions of the two types of neurons, so that despite of the spatial pooling of activity produced at each voxel, there is a distinctive pattern of activity produced across voxels by each stimulus property. This is a spatially smooth coding scheme.
                            </p>
                            <div id="F4" class="fig pos-float type-figure odd">
                             <div class="highwire-figure">
                              <div class="fig-inline-img-wrapper">
                               <div class="fig-inline-img">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F4.large.jpg?width=800&height=600&carousel=1" title="Example highlighting the differences between spatially smooth versus fine-grained encoding schemes, and a particular combination of the two schemes that produces false-positives in a voxelwise analysis. Each column in the figure represents a different voxel containing a large number of neurons represented by small circles, each with selectivity for one of two values of the target property, represented by the colors red and yellow. Different proportions of the two types of neurons are present across different voxels, so that despite of the spatial pooling of activity produced at each voxel, there is a distinctive pattern of activity produced across voxels by each stimulus property. This is a spatially smooth coding scheme. On the other hand, within a voxel widely different spatial distributions of activity may produce the same value of global activity at the voxel level, in a fine-grained coding scheme. Note how the multivoxel pattern of activity is the same for both levels of the context dimension, even though completely different populations of neurons encode each level. The combination of spatially smooth encoding of the target dimension and fine-grained encoding of the context dimension would produce false-positive invariance in a voxelwise analysis." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Example highlighting the differences between spatially smooth versus fine-grained encoding schemes, and a particular combination of the two schemes that produces false-positives in a voxelwise analysis. Each column in the figure represents a different voxel containing a large number of neurons represented by small circles, each with selectivity for one of two values of the target property, represented by the colors red and yellow. Different proportions of the two types of neurons are present across different voxels, so that despite of the spatial pooling of activity produced at each voxel, there is a distinctive pattern of activity produced across voxels by each stimulus property. This is a spatially smooth coding scheme. On the other hand, within a voxel widely different spatial distributions of activity may produce the same value of global activity at the voxel level, in a fine-grained coding scheme. Note how the multivoxel pattern of activity is the same for both levels of the context dimension, even though completely different populations of neurons encode each level. The combination of spatially smooth encoding of the target dimension and fine-grained encoding of the context dimension would produce false-positive invariance in a voxelwise analysis.</div>' data-icon-position="" data-hide-link-title="0">
                                 <span class="hw-responsive-img">
                                  <img class="highwire-fragment fragment-image lazyload" alt="Figure 4:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F4.medium.gif" width="440" height="415"/>
                                  <noscript>
                                   <img class="highwire-fragment fragment-image" alt="Figure 4:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F4.medium.gif" width="440" height="415"/>
                                  </noscript>
                                 </span>
                                </a>
                               </div>
                              </div>
                              <ul class="highwire-figure-links inline">
                               <li class="download-fig first">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F4.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 4:" data-icon-position="" data-hide-link-title="0">
                                 Download figure
                                </a>
                               </li>
                               <li class="new-tab last">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F4.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                 Open in new tab
                                </a>
                               </li>
                              </ul>
                             </div>
                             <div class="fig-caption">
                              <span class="fig-label">
                               Figure 4:
                              </span>
                              <p id="p-21" class="first-child">
                               Example highlighting the differences between spatially smooth versus fine-grained encoding schemes, and a particular combination of the two schemes that produces false-positives in a voxelwise analysis. Each column in the figure represents a different voxel containing a large number of neurons represented by small circles, each with selectivity for one of two values of the target property, represented by the colors red and yellow. Different proportions of the two types of neurons are present across different voxels, so that despite of the spatial pooling of activity produced at each voxel, there is a distinctive pattern of activity produced across voxels by each stimulus property. This is a spatially smooth coding scheme. On the other hand, within a voxel widely different spatial distributions of activity may produce the same value of global activity at the voxel level, in a fine-grained coding scheme. Note how the multivoxel pattern of activity is the same for both levels of the context dimension, even though completely different populations of neurons encode each level. The combination of spatially smooth encoding of the target dimension and fine-grained encoding of the context dimension would produce false-positive invariance in a voxelwise analysis.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-22">
                             On the other hand, note how within a voxel widely different spatial distributions of activity may produce the same value of global activity at the voxel level. For example, the same aggregate activity is obtained for voxel 1 in context 1 (top) and context 2 (bottom), despite the fact that the fine-grained distribution of activities is widely different. The same is true for all other voxels. Thus, within each voxel one can see a fine-grained coding scheme that distinguishes between contexts.
                            </p>
                            <p id="p-23">
                             More importantly for the issue of neural invariance, in
                             <a id="xref-fig-4-2" class="xref-fig" href="#F4">
                              Figure 4
                             </a>
                             the neurons encoding the target dimension in the first context (uneven columns of neurons) are completely different to those encoding the target dimension in the second context (even columns of neurons). However, the spatial distribution of neurons specific to each value of the context dimension is spatially homogeneous, with about the same number of neurons of each kind in the voxel regardless of context.
                            </p>
                            <p id="p-24">
                             The result of a spatially smooth encoding of the target dimension across voxels, together with a fine-grained spatial distribution of neurons specific to each value of the context dimension, produce as a result a case in which neural encoding of the target dimension is context-specific, but appears as perfectly invariant at the level of voxel activities.
                            </p>
                            <p id="p-25">
                             A good example of this type of encoding in the brain is encoding of spatial position and orientation in V1. Encoding of spatial position is spatially smooth in V1, with the scale of retinotopic maps being similar to the voxel sizes typically used in neuroimaging, whereas encoding of orientation is much more spatially fine-grained [see 16, 17]. Indeed, orientation maps are so fine-grained compared to the spatial scale of voxels in typical experiments that researchers have debated for years how it is that we are able to decode orientation from V1 using fMRI in the first place [e.g., 18, 19, 20].
                            </p>
                            <p id="p-26">
                             This example shows that the kind of encoding scheme exemplified by
                             <a id="xref-fig-4-3" class="xref-fig" href="#F4">
                              Figure 4
                             </a>
                             can be found in the brain. Because of the influence of the measurement model depicted in
                             <a id="xref-fig-3-3" class="xref-fig" href="#F3">
                              Figure 3b
                             </a>
                             , the need to jointly perform and interpret tests of invariance and specificity is even greater for researchers who aim to find evidence for tolerant/invariant representations. If a false positive is found in a test of context-specificity (e.g., cross-classification) due to issues in the measurement model, it is unlikely that a test of invariance (e.g., classification accuracy invariance) will also be significant. That is, while the cross-classification test has an inherent tendency to produce more false positives than expected (i.e., > α), this issue can be partially controlled by interpreting the results of that test together with results of tests against the null of invariance.
                            </p>
                            <p id="p-27">
                             Here, we show that the two theoretical insights described above have important consequences for neuroimaging research, through empirical evidence coming from an fMRI decoding study, and computational evidence coming from simulation work. In the empirical study, we perform decoding of orientation and spatial position from fMRI activity patterns recorded in V1, a case in which properties of the underlying neural code are known. The cross-classification test provides strong evidence for the incorrect conclusion that, in V1, encoding of spatial position is tolerant/invariant to changes in orientation, as well as some evidence for the incorrect conclusion that orientation is tolerant/invariant to changes in spatial position. We find that the use of theoretically-derived tests of invariance can lead to more valid conclusions regarding the underlying code. The results of two simulations further support all of these conclusions. Our results highlight the validity and value of using tests of invariance together with tests of context-specificity (e.g., cross-classification) when attempting to draw inferences about neural representations from neuroimaging decoding studies.
                            </p>
                           </div>
                           <div class="section" id="sec-3">
                            <h2 class="">
                             Results
                            </h2>
                            <div id="sec-4" class="subsection">
                             <h3>
                              Experimental Results
                             </h3>
                             <p id="p-28">
                              The goal of our study was to validate two insights provided by neurocomputational theory [
                              <a id="xref-ref-4-5" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ]. First, that tests aimed at testing against the null hypothesis of context-specificity, and to provide evidence for the alternative hypothesis of context-invariance, may be prone to false positives due to the way in which the underlying neural representations are transformed into measurements, as shown in
                              <a id="xref-fig-3-4" class="xref-fig" href="#F3">
                               Figures 3
                              </a>
                              and
                              <a id="xref-fig-4-4" class="xref-fig" href="#F4">
                               4
                              </a>
                              . Second, that jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations.
                             </p>
                             <p id="p-29">
                              To test these two hypotheses, we applied decoding tests of invariance and specificity to the study of orientation and spatial position in V1. Previous research has established that these properties are not encoded in an invariant way but, as explained in the introduction, the spatial scale of orientation and spatial position maps in V1 is likely to lead to the incorrect conclusion of invariance if tests of specificity, such as cross-classification, are applied on their own.
                             </p>
                             <p id="p-30">
                              Participants were presented with the stimuli in
                              <a id="xref-fig-13-1" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              while they performed a task involving a stimulus presented at the center of the screen. Functional MRI data was acquired at the same time, with separate runs providing data for training and testing of a support vector machine (SM) classifier. Training runs were composed of stimuli presented only in spatial positions top-right and bottom-left (highlighted through red and blue boxes in
                              <a id="xref-fig-13-2" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ). Testing runs included all sixteen stimulus combinations. We trained a linear SVM classifier to decode a target dimension (e.g., spatial position) while holding the context dimension (e.g., grating orientation) constant. We then tested the classifier with data obtained at the trained value of the context dimension (e.g., 0° orientation) as well as new values of the context dimension (e.g., 45°, 90°, and 135° orientation). The classifier provided decision variables and accuracy estimates used to perform a test of specificity (cross-classification) and two tests of invariance (classification accuracy invariance, decoding separability) presented below (for more details, see Materials and Methods).
                             </p>
                            </div>
                            <div id="sec-5" class="subsection">
                             <h3>
                              The Cross-Classification Test Produces False Positives
                             </h3>
                             <p id="p-31">
                              The popular cross-classification test ([e.g.,
                              <a id="xref-ref-1-1" class="xref-bibr" href="#ref-1">
                               1
                              </a>
                              ,
                              <a id="xref-ref-2-1" class="xref-bibr" href="#ref-2">
                               2
                              </a>
                              ,
                              <a id="xref-ref-3-1" class="xref-bibr" href="#ref-3">
                               3
                              </a>
                              ], see
                              <a id="xref-fig-2-4" class="xref-fig" href="#F2">
                               Figure 2
                              </a>
                              ) was specifically designed to provide evidence in favor of invariant encoding in a given brain region, by testing against the null of context-specific encoding (see
                              <a id="xref-fig-1-8" class="xref-fig" href="#F1">
                               Figure 1
                              </a>
                              ). As indicated earlier (see
                              <a id="xref-fig-3-5" class="xref-fig" href="#F3">
                               Figures 3
                              </a>
                              and
                              <a id="xref-fig-4-5" class="xref-fig" href="#F4">
                               4
                              </a>
                              ), theoretical considerations suggest that such a test would be biased to generate false positives, leading to evidence against context-specificity that is due to distortions in neural representations imposed by the measurement model, rather than to actual properties of neural encoding (see
                              <a id="xref-fig-3-6" class="xref-fig" href="#F3">
                               Figure 3b
                              </a>
                              ). We performed a set of analyses using the cross-classification test to validate our theoretical prediction that this method should produce findings of false-positive invariance; that is, cases in which invariance is concluded even though our knowledge of the underlying neural code indicates that such invariance does not exist. The cross-classification test was conducted by assessing whether a linear decoder trained to classify the target dimension at one level of the context dimension, could perform the same classification above chance across non-trained levels of the context dimension. A positive result in the cross-classification test is usually taken as evidence for the existence of invariant representations in the area of interest [
                              <a id="xref-ref-2-2" class="xref-bibr" href="#ref-2">
                               2
                              </a>
                              ,
                              <a id="xref-ref-3-2" class="xref-bibr" href="#ref-3">
                               3
                              </a>
                              ].
                             </p>
                             <p id="p-32">
                              We conducted two separate analyses using the cross-classification test in which we switched the identities of the target and context dimensions. In the first analysis, spatial position was treated as the target dimension to be decoded, while orientation remained as the context dimension. To obtain decoded stimulus values for spatial position, we used deconvolved single-trial estimates of activity in V1 voxels as input to the SVM linear decoder. We trained the decoder to classify trials based on spatial position labels (top-right vs bottom-left, see boxed stimuli in
                              <a id="xref-fig-13-3" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ) and holding constant the level of grating orientation (context dimension; for example, 0°) using leave-one-run-out cross-validation, and tested it with independent data sets across all levels of grating orientation (0°, 45°, 90°, and 135°). To test for cross-classification invariance, we performed a binomial test on the accuracy estimates from the testing data set, corrected for multiple comparisons using the Holm-Sidak method. (for more details, see fMRI Decoding Tests) If the accuracy score was significantly above chance, then the cross-classification test concludes that spatial position is encoded invariantly from orientation in V1, a conclusion known to be false.
                             </p>
                             <p id="p-33">
                              For each participant, we repeated the analysis four times, once for each level of grating orientation that was held fixed in the classifier’s training data. Based on theoretical considerations [
                              <a id="xref-ref-4-6" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ], we predicted that the cross-classification test would generate consistent false positives in the case where spatial position was used as the relevant dimension to be decoded. Since spatial position is encoded in a spatially smooth manner in V1, we expected strong performance of the classifier across all levels of orientation. In other words, we expected the accuracy scores of the classifier to remain above chance across different levels of the context dimension.
                             </p>
                             <p id="p-34">
                              <a id="xref-fig-5-1" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              shows accuracy estimates from such a decoding procedure for all five subjects. The SVM linear decoder achieves extremely high levels of classification accuracy in test sets across all 5 subjects. As predicted, the test incorrectly finds evidence for invariance of spatial position from orientation in all participants and all tests (all p<.001; for details see
                              <a id="xref-table-wrap-1-2" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              in the Supplementary Material). This result is unsurprising, in the sense that one would intuitively expect it given the properties of encoding in V1, where information about the spatial position of stimuli is spatially smooth, distributed at around the same scale as our voxel size, but information about orientation is fine-grained, distributed at a smaller scale than our voxel size. The important point, however, is that in most applications of the cross-classification test researchers do not know much about encoding in the area under study, and they could easily conclude in favor of invariance when the underlying code does not show such property.
                             </p>
                             <div id="F5" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F5.large.jpg?width=800&height=600&carousel=1" title="Classification accuracy results with test data for the decoding of spatial position. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate spatial positions while the oriented grating was held constant at 0°. The same decoder was then tested with independent testing data in which the oriented grating was held at all orientations (0°, 45°, 90°, and 135°). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As expected, the cross classification test consistently generates false positives and yields a conclusion that spatial position is encoded invariantly from orientation in V1." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Classification accuracy results with test data for the decoding of spatial position. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate spatial positions while the oriented grating was held constant at 0°. The same decoder was then tested with independent testing data in which the oriented grating was held at all orientations (0°, 45°, 90°, and 135°). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As expected, the cross classification test consistently generates false positives and yields a conclusion that spatial position is encoded invariantly from orientation in V1.</div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 5:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F5.medium.gif" width="440" height="390"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 5:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F5.medium.gif" width="440" height="390"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F5.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 5:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F5.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 5:
                               </span>
                               <p id="p-35" class="first-child">
                                Classification accuracy results with test data for the decoding of spatial position. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate spatial positions while the oriented grating was held constant at 0°. The same decoder was then tested with independent testing data in which the oriented grating was held at all orientations (0°, 45°, 90°, and 135°). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As expected, the cross classification test consistently generates false positives and yields a conclusion that spatial position is encoded invariantly from orientation in V1.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-36">
                              We performed a second analysis in which orientation was treated as the target dimension to be decoded, while spatial position was treated as the context dimension. We trained the decoder to classify trials based on grating orientation (0°, 45°, 90°, and 135°, see boxed stimuli in
                              <a id="xref-fig-13-4" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ) and holding constant the position of the spatial window (context dimension; for example, top-right or 20° in
                              <a id="xref-fig-13-5" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ) using leave-one-run-out cross-validation, and tested it with independent data sets across all levels of spatial position (top-right, bottom-right, bottom-left, and top-left; or 20°, 80°, 200°, and 260° in
                              <a id="xref-fig-13-6" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ). All other procedures remained the same as in the first analysis. Figure (6) shows decoding accuracy results for the orientation analysis. The SVM classifier was able to successfully decode orientation information at the original training position in all subjects, but for subjects 1 and 4 this was restricted to a single training window (200° window). In contrast to spatial position classification, the classifier’s accuracy scores drop significantly in untrained testing windows.
                             </p>
                             <p id="p-37">
                              The classifier accuracy at the training window provides a ceiling of performance for the cross-classification accuracy (see 2, 3). That is, we are not interested in the analyses with non-significant accuracies at the training window (sub#1 and sub#4 at training window 1; see
                              <a id="xref-fig-6-1" class="xref-fig" href="#F6">
                               Figure 6
                              </a>
                              ), as in those cases we would not expect a significant cross-classification accuracy. Out of the eight analyses showing significant accuracy at the training window, two generated significant cross-classification results, which would lead to an invalid conclusion of invariance. This number was higher than the 5% expected false positive rate for these tests, but a binomial test did not reach significance with p =.051, probably due to the low power of a test involving only eight analyses.
                             </p>
                             <div id="F6" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F6.large.jpg?width=800&height=600&carousel=1" title="Classification accuracy results with test data for the decoding of orientation. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate grating orientations, while holding the spatial position of the window constant at 20° of rotation. The same decoder was then tested with independent testing data in which the window was held at all spatial positions (20°, 80°, 260°, and 200° of rotation). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As predicted, the cross classification test is susceptible to generating false positives, concluding that orientation is encoded invariantly from spatial position in the V1 of subjects 2 and 3. A blue asterisk represents that accuracy values significantly drop from the value observed at the trained window, leading to the conclusion of no invariance from the classification accuracy invariance test. The test is successful in finding evidence against invariance in the data of each participant." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Classification accuracy results with test data for the decoding of orientation. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate grating orientations, while holding the spatial position of the window constant at 20° of rotation. The same decoder was then tested with independent testing data in which the window was held at all spatial positions (20°, 80°, 260°, and 200° of rotation). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As predicted, the cross classification test is susceptible to generating false positives, concluding that orientation is encoded invariantly from spatial position in the V1 of subjects 2 and 3. A blue asterisk represents that accuracy values significantly drop from the value observed at the trained window, leading to the conclusion of no invariance from the classification accuracy invariance test. The test is successful in finding evidence against invariance in the data of each participant.</div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 6:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F6.medium.gif" width="257" height="440"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 6:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F6.medium.gif" width="257" height="440"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F6.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 6:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F6.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 6:
                               </span>
                               <p id="p-38" class="first-child">
                                Classification accuracy results with test data for the decoding of orientation. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) held fixed during training. For example, the leftmost cell for subject 1 displays accuracy results from a decoder that was trained to discriminate grating orientations, while holding the spatial position of the window constant at 20° of rotation. The same decoder was then tested with independent testing data in which the window was held at all spatial positions (20°, 80°, 260°, and 200° of rotation). A green asterisk represents accuracy values significantly above chance (dotted line), leading to the conclusion of invariance from the cross-classification test. As predicted, the cross classification test is susceptible to generating false positives, concluding that orientation is encoded invariantly from spatial position in the V1 of subjects 2 and 3. A blue asterisk represents that accuracy values significantly drop from the value observed at the trained window, leading to the conclusion of no invariance from the classification accuracy invariance test. The test is successful in finding evidence against invariance in the data of each participant.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                            </div>
                            <div id="sec-6" class="subsection">
                             <h3>
                              Jointly Testing Against Specificity and Invariance Leads To Valid Conclusions
                             </h3>
                             <p id="p-39">
                              The results from the previous section showed that the cross-classification test, which tests against the null hypothesis of context-specificity, can lead to erroneous conclusions about invariance of representations. We next aimed to show that the addition of tests of invariance developed from neurocomputational theory [
                              <a id="xref-ref-4-7" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ] could solve such issues and lead to more valid conclusions about the underlying code. Here, we apply two of these tests on our data set: the classification accuracy invariance test and the decoding separability test. In contrast to the cross-classification test, both of these theoretically-driven tests try to detect failures of invariance as opposed to providing evidence for invariance.
                             </p>
                             <p id="p-40">
                              The classification accuracy invariance test defines invariance as the case where the probability of correct classification is exactly the same across all contexts. With invariance being the null hypothesis, the test is sensitive to any drop in the classifier’s performance across different levels of the context dimension. We implemented the classification accuracy invariance test by applying an omnibus Chi-Square test on the accuracy estimates from the linear decoder (i.e., testing whether all proportions are the same or some of them are different). Then, we performed pairwise comparisons between accuracy at the training level and each non-training level of the context dimension.
                             </p>
                             <p id="p-41">
                              The decoding separability test, unlike the previous two tests, does not make use of classification accuracy estimates. Instead, it directly relies on certain properties of the decoding probability distributions for individual stimuli. That is, linear classifiers like the one used here perform classification of a new data point by computing a decision variable z, representing the distance of the data point from the classifier’s hyperplane separating two classes. When the decision variable is larger than some criterion value (usually zero), the output is one class, whereas when the decision variable is smaller than the criterion the output is the other class. Instead of comparing simple accuracy estimates, the decoding separability test compares the full distributions of such decision variables, or decoding distributions.
                             </p>
                             <p id="p-42">
                              This test followed the same steps and rationale as the classification accuracy invariance test presented earlier, but instead of computing accuracies and testing their differences, we obtained decision variables from the trained classifier, and used those to estimate decoding distributions using kernel density estimation. For each pair of stimuli differing in the context dimension (e.g., 0° and 45° grating orientation, when the decoded variable was spatial position) we computed the distance between decoding distributions using a discretized L1 metric, which corresponds to the area highlighted in yellow in
                              <a id="xref-fig-15-1" class="xref-fig" href="#F15">
                               Figure 15
                              </a>
                              . Then, we summed a number of such L1 metrics across values of the decoded dimension (e.g., the two spatial windows, when the decoded variable was spatial position), which produced an
                              <span class="inline-formula" id="inline-formula-1">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-1.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-1.gif"/>
                                </noscript>
                               </span>
                              </span>
                              statistic (see
                              <a id="xref-disp-formula-5-1" class="xref-disp-formula" href="#disp-formula-5">
                               Equation 3
                              </a>
                              ). Simply put, while a single L1 metric is analogous to the accuracy of the classifier for a single decoded label, the
                              <span class="inline-formula" id="inline-formula-2">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-2.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-2.gif"/>
                                </noscript>
                               </span>
                              </span>
                              statistic is analogous to the overall decoding accuracy across all labels. The only difference is that
                              <span class="inline-formula" id="inline-formula-3">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-3.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-3.gif"/>
                                </noscript>
                               </span>
                              </span>
                              measures distances between decoding distributions, rather than accuracies. We performed a permutation test to determine whether the observed
                              <span class="inline-formula" id="inline-formula-4">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-4.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-4.gif"/>
                                </noscript>
                               </span>
                              </span>
                              statistic was higher than expected by chance under the null hypothesis of invariance; a positive result on this test gives evidence against neural invariance for the given comparison. Also, we must note that, in theory, the decoding separability test should provide more information about (and be more sensitive to) such violations than the decoding accuracy invariance test (see 4).
                             </p>
                             <p id="p-43">
                              As before, we first applied the invariance tests to decoding results from the spatial position classification. Results from the classification accuracy invariance are shown in
                              <a id="xref-fig-5-2" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              , and results from the decoding separability test are shown in
                              <a id="xref-fig-7-1" class="xref-fig" href="#F7">
                               Figure 7
                              </a>
                              . The specific values obtained from the two tests are reported in Tables 2 and 3 of the Supplementary Material. The classification accuracy invariance test (
                              <a id="xref-fig-5-3" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              ) did not find evidence against invariance in any of the subjects. However, in line with theoretical predictions, the decoding separability test (
                              <a id="xref-fig-5-4" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              ) was much more sensitive to evidence against invariance present in the data. The test found failures of invariance in many cases where accuracy-based tests either found false positives (i.e., cross-classification) or failed to detect failures of invariance (i.e., classification accuracy invariance; see
                              <a id="xref-fig-5-5" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              ). Overall, we found that the decoding separability test detected failures of invariance in the data of all five participants (17 out of 20 analyses).
                             </p>
                             <div id="F7" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F7.large.jpg?width=800&height=600&carousel=1" title="Decoding separability test results with spatial position as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) during training. The y-axis shows the  statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the  statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the  statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 18 out of 20 analyses." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml">Decoding separability test results with spatial position as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) during training. The <em>y</em>-axis shows the  statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the  statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the  statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 18 out of 20 analyses.</div></div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 7:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F7.medium.gif" width="440" height="353"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 7:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F7.medium.gif" width="440" height="353"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F7.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 7:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F7.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 7:
                               </span>
                               <p id="p-44" class="first-child">
                                Decoding separability test results with spatial position as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (orientation) during training. The y-axis shows the
                                <span class="inline-formula" id="inline-formula-5">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-5.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-5.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the
                                <span class="inline-formula" id="inline-formula-6">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-6.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-6.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the
                                <span class="inline-formula" id="inline-formula-7">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-7.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F7/embed/inline-graphic-7.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 18 out of 20 analyses.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-45">
                              From these results, it is apparent that the decoding separability test is sensitive to failures of invariance known to exist in the underlying neural code, even when decoding accuracy seems to suggest perfect invariance (see
                              <a id="xref-fig-5-6" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              ). These results serve as an empirical validation of the decoding separability test, which was developed directly from theory [
                              <a id="xref-ref-4-8" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ]. In addition, these results show the value of testing against invariance, in addition to testing against specificity, to reach valid conclusions about the invariance or specificity of underlying neural representations. Performing both tests and following the guidelines in
                              <a id="xref-table-wrap-1-3" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              , results are inconclusive about whether encoding of spatial position in V1 is invariant or specific to orientation. This conservative conclusion is far better than the invalid conclusion that one would reach by performing the cross-classification test by itself; namely, that encoding of spatial position in V1 is invariant to orientation.
                             </p>
                             <p id="p-46">
                              Next, we applied the invariance test to decoding results from the orientation classification. Results from the classification accuracy invariance test are shown in
                              <a id="xref-fig-6-2" class="xref-fig" href="#F6">
                               Figure 6
                              </a>
                              , and results from the decoding separability test are shown in
                              <a id="xref-fig-8-1" class="xref-fig" href="#F8">
                               Figure 8
                              </a>
                              . The specific values obtained from the two tests are reported in Tables 2 and 3 of the Supplementary Material. The classification accuracy invariance test (
                              <a id="xref-fig-6-3" class="xref-fig" href="#F6">
                               Figure 6
                              </a>
                              ) was much more sensitive to failures of invariance in this analysis. Failures of invariance were detected in every case where the classifier successfully decoded orientations above chance levels in the training window. Interestingly, failures of invariance were also detected in cases where the classifier did not successfully decode orientation above chance. This is counterintuitive, but expected from a theoretical point of view [see 4], which suggests that a decoder does not have to perform accurately or be optimal in any way to be able to detect failures of invariance. Contrary to our expectations, in this analysis the decoding separability test detected failures of invariance less frequently than the classification accuracy invariance test (see
                              <a id="xref-fig-8-2" class="xref-fig" href="#F8">
                               Figure 8
                              </a>
                              ). The decoding separability test detected failures of invariance in the data of four out of five participants (eight out of ten analyses).
                             </p>
                             <div id="F8" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F8.large.jpg?width=800&height=600&carousel=1" title="Decoding separability test results with orientation as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) during training. The y-axis shows the  statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the  statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the  statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 8 out of 10 analyses." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml">Decoding separability test results with orientation as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) during training. The <em>y</em>-axis shows the  statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the  statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the  statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 8 out of 10 analyses.</div></div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 8:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F8.medium.gif" width="281" height="440"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 8:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F8.medium.gif" width="281" height="440"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F8.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 8:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F8.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 8:
                               </span>
                               <p id="p-47" class="first-child">
                                Decoding separability test results with orientation as the target dimension. Each row represents a complete analysis for a single subject. Columns represent different levels of the context dimension (spatial position) during training. The y-axis shows the
                                <span class="inline-formula" id="inline-formula-8">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-8.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-8.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic, which quantifies the magnitude of violations of decoding separability. Bars represent 90% bootstrap confidence intervals on the
                                <span class="inline-formula" id="inline-formula-9">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-9.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-9.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic. The dotted line and surrounded gray area represent the expected value and 90% bootstrap confidence interval for the
                                <span class="inline-formula" id="inline-formula-10">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-10.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/F8/embed/inline-graphic-10.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic when no differences exist between two distributions. Teal asterisks represent significant failures of invariance according to a permutation test. The test successfully found evidence for the absence of invariance in 8 out of 10 analyses.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-48">
                              In comparison to the classification accuracy invariance test, the decoding separability test appears to be more sensitive to detecting failures of invariance in cases where the decoder’s performance reaches ceiling levels (
                              <a id="xref-fig-7-2" class="xref-fig" href="#F7">
                               Figure 7
                              </a>
                              ). However, when classification accuracy is well below ceiling levels, as in decoding of orientation, the test seems less sensitive than classification accuracy invariance, perhaps due to a lower statistical power of the permutation test involved.
                             </p>
                             <p id="p-49">
                              As was the case with decoding of spatial position, in this second analysis we also see the value of testing against invariance. While the results of the cross-classification test suggested invariant representations in subjects #2 and #3 (see
                              <a id="xref-fig-6-4" class="xref-fig" href="#F6">
                               Figure 6
                              </a>
                              ), such results are inconclusive when interpreted in the context of tests of invariance, which suggest context-specific representations.
                             </p>
                            </div>
                            <div id="sec-7" class="subsection">
                             <h3>
                              Simulation and Theoretical Results
                             </h3>
                             <p id="p-50">
                              The empirical results described in the preceding section clearly support the hypotheses that tests aimed at providing evidence for invariance, such as cross-classification, are prone to false positives, and that jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations.
                             </p>
                             <p id="p-51">
                              However, there are issues with experimental work that motivated us to further evaluate our hypotheses through simulation work. In particular, experimental work does not allow full control of the underlying neural representations. In our study, we assumed that encoding of spatial position was specific to orientation, and vice-versa, but it is unlikely that the true encoding of these variables in V1 is completely context-specific. For example, there is evidence that a minority of neurons in V1 are invariant to orientation [
                              <a id="xref-ref-21-1" class="xref-bibr" href="#ref-21">
                               21
                              </a>
                              ]. This means that encoding of spatial position is best characterized as context-sensitive, but a critical reader could interpret this as evidence for tolerance. Simulation work provides complete control over the representations under study, which can be made to be fully context-specific, without any degree of tolerance to changes in context. The relevant question is: Does cross-classification lead to conclusions of false-positive invariance under such circumstances? If yes: Can tests against invariance lead to more valid conclusions?
                             </p>
                             <p id="p-52">
                              Another issue with experimental results is that they can be difficult to generalize. A critical reader could argue that issues with tests of context-specificity like cross-classification are restricted to special cases, and not general as suggested by theory. Again, simulation and theoretical work allows one to provide results that are more general.
                             </p>
                            </div>
                            <div id="sec-8" class="subsection">
                             <h3>
                              Simulation 1: False Positive Invariance Resulting From Features Of The Measurement Model
                             </h3>
                             <p id="p-53">
                              The empirical results presented in the previous section clearly show that the cross-classification test can generate false positives. Representations of orientation and spatial position in V1 can be categorized as context-sensitive at most (see
                              <a id="xref-fig-1-9" class="xref-fig" href="#F1">
                               Figure 1
                              </a>
                              ), but cross-classification can lead to conclusions of tolerance or invariance. Yet, some researchers might argue that they use the cross-classification test to detect any level of context-tolerance; that is, whether representations fall anywhere to the left of context-specificity in the continuum shown in
                              <a id="xref-fig-1-10" class="xref-fig" href="#F1">
                               Figure 1
                              </a>
                              . In other words, some researchers might classify context-sensitivity as a form of tolerance, or partial invariance.
                             </p>
                             <p id="p-54">
                              In theory, even a completely context-specific code could produce false conclusions of invariance in neuroimaging decoding studies, due to the transformation and mixing of neural responses from different populations that occurs at each voxel (see
                              <a id="xref-fig-3-7" class="xref-fig" href="#F3">
                               Figure 3
                              </a>
                              ). To provide evidence for such a general claim, we resort to simulation and theoretical work (for details on the models and procedures used in the simulations, see Simulations in the Materials and Methods section). We study a case of complete context-specificity in which it cannot be claimed that any amount of tolerance exists in the neural representations.
                             </p>
                             <p id="p-55">
                              To create such a model, we started by defining two sets of encoding models, corresponding to two levels of the context dimension. In context 1, the target dimension was encoded through neural channels with homogeneous features (i.e., evenly spaced position, same maximum activity, same width), as shown at the top of
                              <a id="xref-fig-18-1" class="xref-fig" href="#F18">
                               Figure 18
                              </a>
                              . In context 2, the target dimension was encoded through neural channels with completely randomized features, which is exemplified at the bottom of
                              <a id="xref-fig-18-2" class="xref-fig" href="#F18">
                               Figure 18
                              </a>
                              . Then, we produced false positive invariance by optimizing the weights of the measurement model such that the voxel-wise activity values were similar across the two levels of the context dimension (
                              <a id="xref-fig-18-3" class="xref-fig" href="#F18">
                               Figure 18
                              </a>
                              ). Finally, we sampled data from both models and used them as input to a linear SVM classifier. As in the preceding empirical analyses, the decoder was trained on data from the first level model and tested on independent data from both the first and second level models (
                              <a id="xref-fig-19-1" class="xref-fig" href="#F19">
                               Figure 19
                              </a>
                              ). This entire procedure was repeated 200 times per simulation run, and we present the average results across simulations. We performed twenty simulation runs, where we gradually increased the measurement noise in each voxel (standard deviation going from 1 to 20, in steps of 1).
                             </p>
                             <p id="p-56">
                              <a id="xref-fig-9-1" class="xref-fig" href="#F9">
                               Figure 9a
                              </a>
                              shows the decoding accuracy results from this simulation. The most important values are represented by the blue curves, which represent performance of the classifier in the non-trained level of the context dimension. Whenever accuracy is above chance, represented by the dotted line, the cross-classification test leads to a conclusion of invariance in a situation where no invariance exists (i.e., false positive invariance). The cross-classification accuracy score was much higher than chance across all levels of noise, even as measurement noise was drastically increased. The red line in
                              <a id="xref-fig-9-2" class="xref-fig" href="#F9">
                               Figure 9b
                              </a>
                              shows the proportion of false positives for the cross-classification test, which consistently remained above the nominal α = .05, represented by the dotted line, across all levels of noise that produced above-chance decoding. Only when decoding accuracy drops to chance levels (a case where the test would not be applied in an empirical setting) the cross-classification test stops producing false positives.
                             </p>
                             <div id="F9" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F9.large.jpg?width=800&height=600&carousel=1" title="Decoding results from simulation 1. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The y-axis represents accuracy scores, while the x-axis represents level of measurement noise (in units of standard deviation). (b) Proportion of positive tests of each type. The y - axis represents proportion of positives, and x-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains higher that the accepted 5% threshold (dotted line). (c-d) Proportion of each type of conclusion in Table 1 (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml">Decoding results from simulation 1. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The <em>y</em>-axis represents accuracy scores, while the <em>x</em>-axis represents level of measurement noise (in units of standard deviation). (b) Proportion of positive tests of each type. The <em>y</em> - axis represents proportion of positives, and <em>x</em>-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains higher that the accepted 5% threshold (dotted line). (c-d) Proportion of each type of conclusion in Table 1 (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity.</div></div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 9:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F9.medium.gif" width="440" height="397"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 9:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F9.medium.gif" width="440" height="397"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F9.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 9:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F9.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 9:
                               </span>
                               <p id="p-57" class="first-child">
                                Decoding results from simulation 1. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The y-axis represents accuracy scores, while the x-axis represents level of measurement noise (in units of standard deviation). (b) Proportion of positive tests of each type. The y - axis represents proportion of positives, and x-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains higher that the accepted 5% threshold (dotted line). (c-d) Proportion of each type of conclusion in
                                <a id="xref-table-wrap-1-4" class="xref-table" href="#T1">
                                 Table 1
                                </a>
                                (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-58">
                              These results suggest that a suitable selection of measurement model is sufficient for inducing false positives in the cross-classification test, even when the underlying encoding distributions themselves show absolutely no tolerance. The next question is whether using additional tests against the null of invariance can lead to more valid conclusions.
                             </p>
                             <p id="p-59">
                              The blue line in 9b shows the proportion of tests correctly rejecting the null of invariance for the classification accuracy invariance test. The test is very sensitive to measurement noise, having good power (about 80%) only at the smallest levels of measurement noise.
                              <a id="xref-fig-9-3" class="xref-fig" href="#F9">
                               Figure 9c
                              </a>
                              shows the proportion of each type of conclusion in
                              <a id="xref-table-wrap-1-5" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance, by using the cross-classification and classification accuracy invariance tests, respectively. This strategy does lead to more valid conclusions at either low or high levels of noise, but at intermediate levels the strategy fails and produces a high proportion of conclusions for tolerance. Note that these intermediate levels of noise produce decoding accuracy around 40%-60%, which are realistic values for a four-alternative classification task.
                             </p>
                             <p id="p-60">
                              The green line in
                              <a id="xref-fig-9-4" class="xref-fig" href="#F9">
                               Figure 9b
                              </a>
                              shows the proportion of tests correctly rejecting the null of invariance for the decoding separability test. The first notable result is the high sensitivity of the decoding separability test to violations of invariance. At all levels of noise, the test detected such violations in almost all simulation runs. Note that the test is sensitive even when decoding accuracy has dropped to chance. All these features of the test are expected from the theory used to develop it [
                              <a id="xref-ref-4-9" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ]. Higher sensitivity than accuracy-based tests is expected because the test uses information from the full distribution of decision variables from the decoder. Robustness in the face of measurement noise is expected because although noise reduces high-frequency differences between distributions, it preserves differences at lower frequencies (see [
                              <a id="xref-ref-4-10" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ]). We must note that this simulation probably over-estimates the test’s sensitivity, as our experimental results showed that the test often misses significance in real data.
                             </p>
                             <p id="p-61">
                              <a id="xref-fig-9-5" class="xref-fig" href="#F9">
                               Figure 9d
                              </a>
                              shows the proportion of each type of conclusion in
                              <a id="xref-table-wrap-1-6" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance, by using the cross-classification and decoding separability tests, respectively. In this case, invalid conclusions of tolerance are never reached. Counterintuitively, valid conclusions of sensitivity increase over inconclusive results as noise increases. The reason is that cross-classification is more sensitive to noise than decoding separability.
                             </p>
                             <p id="p-62">
                              Overall, the results from this simulation provide further evidence favoring our hypotheses, showing that cross-classification can lead to false positive conclusions of tolerance when absolutely no tolerance exists in the underlying neural code, and that the addition of tests against invariance leads to more valid conclusions. The results suggest that decoding separability should be preferred over classification accuracy invariance to test against invariance, as was expected from theory [
                              <a id="xref-ref-4-11" class="xref-bibr" href="#ref-4">
                               4
                              </a>
                              ].
                             </p>
                            </div>
                            <div id="sec-9" class="subsection">
                             <h3>
                              Evaluating the Pervasiveness of the False Positive Invariance Problem
                             </h3>
                             <p id="p-63">
                              A critical reader might argue that the conditions leading to false positive invariance in the first simulation, namely the explicit selection of the measurement weights that produce similar voxel-wise activity patterns across levels of the context dimension, are unlikely to occur in real fMRI experiments. The true measurement process is not trained to make activity values similar across different levels of irrelevant dimensions. How pervasive is the false positive invariance problem uncovered in the first simulation? Here we show that, against intuition, the problem is quite pervasive.
                             </p>
                             <p id="p-64">
                              In the standard encoding model used in our simulations, the mean response of neural channel c to stimulus s
                              <sub>
                               i
                              </sub>
                              , presented in context j, is given by a tuning function f
                              <sub>
                               jc
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ) (see subsection in Materials and Methods). We can collect the mean response of N
                              <sub>
                               c
                              </sub>
                              channels in a population response vector
                              <strong>
                               f
                              </strong>
                              <sub>
                               j
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ) = [f
                              <sub>
                               j
                              </sub>
                              <sub>
                               1
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ), f
                              <sub>
                               j
                              </sub>
                              <sub>
                               2
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ), …f
                              <sub>
                               jNc
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              )]. A number of stimulus values for the target dimension are presented in any experiment, indexed by i = 1, 2, …, N
                              <sub>
                               s
                              </sub>
                              . Without loss of generality, we can focus on an experiment with two stimulus contexts indexed by j = 1, 2, as in our simulation. The measured activity in voxel k to stimulus s
                              <sub>
                               i
                              </sub>
                              in the first context is equal to
                              <strong>
                               f
                              </strong>
                              <sub>
                               1
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              )
                              <sup>
                               T
                              </sup>
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               1
                              </sub>
                              , and in the second context is equal to
                              <strong>
                               f
                              </strong>
                              <sub>
                               2
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              )
                              <sup>
                               T
                              </sup>
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               2
                              </sub>
                              . The measurement vectors
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               1
                              </sub>
                              and
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               2
                              </sub>
                              produce invariance in voxel k when they produce the same mean activity value:
                              <span class="disp-formula" id="disp-formula-1">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-11.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-11.gif"/>
                                </noscript>
                               </span>
                              </span>
                              where
                              <strong>
                               f
                              </strong>
                              <sub>
                               +
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ) is a row vector of concatenated mean population responses, and
                              <strong>
                               w
                              </strong>
                              <sub>
                               +
                              </sub>
                              is a column vector of concatenated weights.
                             </p>
                             <p id="p-65">
                              If we collect the vectors
                              <strong>
                               f
                              </strong>
                              <sub>
                               +
                              </sub>
                              (s
                              <sub>
                               i
                              </sub>
                              ) in response to the experimental stimuli in a matrix:
                              <span class="disp-formula" id="disp-formula-2">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-12.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-12.gif"/>
                                </noscript>
                               </span>
                              </span>
                              we get a set of homogeneous equations that can be solved for
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               +
                              </sub>
                              > 0:
                              <span class="disp-formula" id="disp-formula-3">
                               <span class="highwire-responsive-lazyload">
                                <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-13.gif"/>
                                <noscript>
                                 <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-13.gif"/>
                                </noscript>
                               </span>
                              </span>
                             </p>
                             <p id="p-66">
                              A measurement model produces false positive invariance when
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               +
                              </sub>
                              ≠
                              <strong>
                               0
                              </strong>
                              is a solution of this equation for all voxels k. Another way to see this equation is that
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               +
                              </sub>
                              corresponds to the nullspace of matrix
                              <strong>
                               F
                              </strong>
                              <sub>
                               +
                              </sub>
                              . The nullity-rank theorem tells us that the dimensionality of this nullspace, or nullity, equals the number of columns in
                              <strong>
                               F
                              </strong>
                              <sub>
                               +
                              </sub>
                              (i.e., the total number of channels in the model) minus its rank. The nullity gives us information about the size of the subspace of measurement models
                              <strong>
                               w
                              </strong>
                              <sub>
                               k
                              </sub>
                              <sub>
                               +
                              </sub>
                              that produce false positive invariance. When the only solution for
                              <a id="xref-disp-formula-3-1" class="xref-disp-formula" href="#disp-formula-3">
                               Equation 1
                              </a>
                              is the trivial solution
                              <strong>
                               w
                              </strong>
                              <sub>
                               kc
                              </sub>
                              =
                              <strong>
                               0
                              </strong>
                              , the nullity of
                              <strong>
                               F
                              </strong>
                              <sub>
                               +
                              </sub>
                              is zero. In this case, constraints in the encoding model and experimental design, summarized in
                              <strong>
                               F
                              </strong>
                              <sub>
                               +
                              </sub>
                              , are such that there is no measurement model that can produce false positive invariance. This is the only case in which we would not have to worry about false positive invariance, but it has been the default assumption of researchers applying the cross-classification test in the literature. Note also that this analysis is only concerned with strict invariance and not with tolerance; even when false positive invariance cannot be produced by a measurement model, false positive tolerance may still be possible.
                             </p>
                             <p id="p-67">
                              We are now in a good position to evaluate the pervasiveness of false positive invariance in the encoding scenario posed by our first simulation. We created encoding models just as indicated for simulation 1 (see
                              <a id="xref-fig-18-4" class="xref-fig" href="#F18">
                               Figure 18
                              </a>
                              ), each time with a different number of stimuli and neural channels. The number of neural channels was varied from 5 to 30 in steps of 5, and the number of stimuli was varied from 2 to 20 in steps of 2. For each combination of neural channels and stimuli, we created 200 different encoding models, and computed the nullity of the mean population response matrix
                              <strong>
                               F
                              </strong>
                              <sub>
                               +
                              </sub>
                              . As indicated earlier, the nullity represents the dimensionality of the subspace of measurement models that would produce false positive invariance. To ease comparison,
                              <a id="xref-fig-10-1" class="xref-fig" href="#F10">
                               Figure 10
                              </a>
                              shows the nullity divided by the dimensionality of the measurement model, or proportion nullity. This represents the proportion of the measurement space (in terms of dimensionality) that would produce false positive invariance. We found that there was no variability of results across the 200 sampled models, so
                              <a id="xref-fig-10-2" class="xref-fig" href="#F10">
                               Figure 10
                              </a>
                              shows the unique value of proportion nullity found in each case.
                             </p>
                             <div id="F10" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F10.large.jpg?width=800&height=600&carousel=1" title="Pervasiveness of the problem of false positive invariance for the extreme case of context-specificity studied in simulation 1. Proportion nullity represents the proportion of all dimensions in the measurement space that would produce false positive invariance, and therefore the size of the false positive invariance problem. The values reported were always the same for a given combination of number of neural channels and number of stimuli, across 200 randomly sampled encoding models." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Pervasiveness of the problem of false positive invariance for the extreme case of context-specificity studied in simulation 1. Proportion nullity represents the proportion of all dimensions in the measurement space that would produce false positive invariance, and therefore the size of the false positive invariance problem. The values reported were always the same for a given combination of number of neural channels and number of stimuli, across 200 randomly sampled encoding models.</div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 10:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F10.medium.gif" width="440" height="255"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 10:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F10.medium.gif" width="440" height="255"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F10.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 10:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F10.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 10:
                               </span>
                               <p id="p-68" class="first-child">
                                Pervasiveness of the problem of false positive invariance for the extreme case of context-specificity studied in simulation 1. Proportion nullity represents the proportion of all dimensions in the measurement space that would produce false positive invariance, and therefore the size of the false positive invariance problem. The values reported were always the same for a given combination of number of neural channels and number of stimuli, across 200 randomly sampled encoding models.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-69">
                              One can easily see from
                              <a id="xref-fig-10-3" class="xref-fig" href="#F10">
                               Figure 10
                              </a>
                              that the scenario posed in our first simulation is far from rare. On the contrary, with ten channels and four stimuli, as we used in that simulation, the proportion nullity is 0.8, meaning that the large majority of the possible measurement models will lead to false positive invariance. This result was not idiosyncratic to the parameters chosen for our simulation, with proportion nullity in general being quite high. The exception was a combination of a high number of stimuli and low number of channels, which is rare in experiments reported in the literature. Most neuroimaging studies using cross-classification to study invariance have presented 2-4 stimuli, a case in which the proportion nullity is at least 0.6, and in most cases above 0.8.
                             </p>
                             <p id="p-70">
                              We must remind the reader that we are studying here an extreme case of context-specificity, under the assumption of no measurement noise, and an extreme case of false positive invariance, rather than tolerance. For these reasons, we can consider our results a lower bound on the size of the false positive invariance problem. More realistic scenarios involving context-sensitivity, high measurement noise, or evaluation of tolerance rather than strict invariance can all be expected to worsen the problem beyond what is shown in our results.
                             </p>
                             <p id="p-71">
                              We see two clear trends in
                              <a id="xref-fig-10-4" class="xref-fig" href="#F10">
                               Figure 10
                              </a>
                              . First, proportion nullity –and therefore, the problem of false positive invariance– drops linearly with number of stimuli included in the study. Experimenters can reduce the risk of false positive invariance by increasing the number of stimulus levels for the target dimension. Second, proportion nullity increases in a negatively accelerated fashion with increments in the number of neural channels. The number of neural channels represents our assumption of how many unique neural tuning functions underlie the data or, in other words, how well-covered is the stimulus dimension by the encoding neural population. In realistic scenarios, this value will be much higher than any of those shown in
                              <a id="xref-fig-10-5" class="xref-fig" href="#F10">
                               Figure 10
                              </a>
                              . However, it is common to find applications of the standard encoding model in computational neuroimaging that assume 6-15 channels [e.g.,
                              <a id="xref-ref-22-1" class="xref-bibr" href="#ref-22">
                               22
                              </a>
                              ,
                              <a id="xref-ref-23-1" class="xref-bibr" href="#ref-23">
                               23
                              </a>
                              ,
                              <a id="xref-ref-24-1" class="xref-bibr" href="#ref-24">
                               24
                              </a>
                              ,
                              <a id="xref-ref-25-1" class="xref-bibr" href="#ref-25">
                               25
                              </a>
                              ].
                             </p>
                            </div>
                            <div id="sec-10" class="subsection">
                             <h3>
                              Simulation 2: False Positive Invariance Resulting From Similarly Tuned Neural Subpopulations Across Contexts
                             </h3>
                             <p id="p-72">
                              A critical reader may again argue against the results just presented, indicating that although the space of possible measurement models leading to false positive invariance is large in most published studies, most of those models would never be observed in nature. Only a small proportion of all possible measurement models might be truly at play in neuroimaging studies, and those could be contained within the space of models for which false positive invariance is not an issue. Although this is an extremely optimistic position, and we think that it would be unwise for scientists to take it, we would like to strengthen our conclusions by studying a realistic encoding scenario, likely to be implemented in the brain.
                             </p>
                             <p id="p-73">
                              There are many known cases in which neurons that are sensitive to a particular stimulus feature are spatially clustered at sub-millimeter scales. In those cases, while there is spatially distributed information about stimulus features, this information is not immediately visible at the typical resolution of an fMRI study. For example, V1 neurons that are sensitive to the same spatial frequency, color, ocular dominance, and orientation all cluster at the sub-millimeter scale [
                              <a id="xref-ref-26-1" class="xref-bibr" href="#ref-26">
                               26
                              </a>
                              ,
                              <a id="xref-ref-27-1" class="xref-bibr" href="#ref-27">
                               27
                              </a>
                              ,
                              <a id="xref-ref-28-1" class="xref-bibr" href="#ref-28">
                               28
                              </a>
                              ,
                              <a id="xref-ref-29-1" class="xref-bibr" href="#ref-29">
                               29
                              </a>
                              ]. Although advances in high-field fMRI can in some cases uncover such sub-millimeter organization [e.g.,
                              <a id="xref-ref-30-1" class="xref-bibr" href="#ref-30">
                               30
                              </a>
                              ], information can also be spatially distributed without any clustering (e.g., “salt-and-pepper” codes; see [
                              <a id="xref-ref-31-1" class="xref-bibr" href="#ref-31">
                               31
                              </a>
                              ,
                              <a id="xref-ref-32-1" class="xref-bibr" href="#ref-32">
                               32
                              </a>
                              ]), at scales that are unlikely to be reached with fMRI at even higher field strengths than those currently available [
                              <a id="xref-ref-33-1" class="xref-bibr" href="#ref-33">
                               33
                              </a>
                              ,
                              <a id="xref-ref-34-1" class="xref-bibr" href="#ref-34">
                               34
                              </a>
                              ].
                             </p>
                             <p id="p-74">
                              In cases such as these, across voxels we would expect to find relatively homogeneous distributions of selectivities. Our ability to use voxel-level decoding to detect whether and how features are encoded depends critically on small random variations in mixing; that is, in the proportion of each type of neuron present within each voxel. Indeed, small differences in mixing across voxels is a mechanism proposed to underlie decoding of orientation information from V1 [
                              <a id="xref-ref-35-1" class="xref-bibr" href="#ref-35">
                               35
                              </a>
                              ,
                              <a id="xref-ref-36-1" class="xref-bibr" href="#ref-36">
                               36
                              </a>
                              ,
                              <a id="xref-ref-37-1" class="xref-bibr" href="#ref-37">
                               37
                              </a>
                              ,
                              <a id="xref-ref-38-1" class="xref-bibr" href="#ref-38">
                               38
                              </a>
                              ,
                              <a id="xref-ref-39-1" class="xref-bibr" href="#ref-39">
                               39
                              </a>
                              ], like that shown in our experimental study.
                             </p>
                             <p id="p-75">
                              This sub-voxel distribution of information, which may underlie the success of many fMRI decoding studies, can also easily lead to false-positive invariance when the cross-classification test (or other tests of the null of specificity) is used in isolation. Small differences in mixing might be enough to promote above-chance decoding of a stimulus feature, because decoding algorithms are specifically trained to detect differences in the target feature. On the other hand, decoding algorithms are not trained to detect changes in context. Any small differences in mixing that might provide information about context-specificity would be lost, and the decoding algorithm would be very likely to generalize performance across changes in stimulus context. We find an example of this in our own experiment. There, classification of spatial position generalized perfectly across changes in grating orientation, as shown in
                              <a id="xref-fig-5-7" class="xref-fig" href="#F5">
                               Figure 5
                              </a>
                              , despite the fact that the voxels contained information about differences in orientation, as determined by above-chance decoding of that dimension (see
                              <a id="xref-fig-6-5" class="xref-fig" href="#F6">
                               Figure 6
                              </a>
                              ).
                             </p>
                             <p id="p-76">
                              In the present simulation, we wanted to study the sensitivity of different fMRI decoding tests to changes in mixing carrying information about context-sensitivity. With this goal in mind, we created a model in which a target dimension is encoded in a completely context-specific manner, with one subpopulation of neurons responding whenever the context dimension is at level 1, and a different subpopulation of neurons responding whenever the context dimension is at level 2. Both subpopulations were modeled using a standard homogeneous encoding model (see above), but note that this similarity in tuning functions is not equivalent to invariance, as each channel responded only at one of the levels of the context dimension. In other words, our simulation assumes that populations encoding the target dimension are completely separated across levels of the context dimension, but they encode the target dimension in a similar way (just as neurons in
                              <a id="xref-fig-4-6" class="xref-fig" href="#F4">
                               Figure 4
                              </a>
                              have two selectivity types across levels of the context dimension). As before, we report the averaged results from 200 simulations in each run. Measurement noise was set to a fixed level across simulations (s.d.=5, which in our previous simulation produced accuracies around 40%-50%, see
                              <a id="xref-fig-9-6" class="xref-fig" href="#F9">
                               Figure 9
                              </a>
                              ). In each simulation run, we increased the difference in the measurement models for the two levels of the context dimension, by adding random noise to weights of the measurement model as illustrated in
                              <a id="xref-fig-20-1" class="xref-fig" href="#F20">
                               Figure 20
                              </a>
                              . The standard deviation of the weight noise was gradually increased from 0.05 to 0.5 (i.e., from 0.5 to 5 times the average weight value), in steps of 0.05. That is, in the final models the contribution of each neuron type (e.g., neurons selective to a value of 0 in the target dimension) was widely different across levels of the context dimension.
                             </p>
                             <p id="p-77">
                              The results from this simulation are shown in
                              <a id="xref-fig-11-1" class="xref-fig" href="#F11">
                               Figure 11
                              </a>
                              . Panel a shows the accuracy of the classifier tested in the original training context (red line) and in the changed context (i.e., cross-classification performance; blue line). It can be seen that the cross-classification test is sensitive to mixing variations, as accuracy drops with increments in weight changes with context. However, accuracy remains well above chance even for the largest weight changes.
                              <a id="xref-fig-20-2" class="xref-fig" href="#F20">
                               Figure 20b
                              </a>
                              shows the proportion of positive tests as a function of the magnitude of random weight changes (in standard deviations). The cross-classification test consistently showed false positives at a rate much higher than the nominal 5%. High levels of false-positive invariance were present even when the weight noise standard deviation was five times as large as the average weight values. These results suggest that, when two completely separate neural populations use similar codes to represent a target dimension across levels of an context dimension, false positive invariance is likely to be found not only with the small variations in mixing that one would usually expect from fMRI studies, but from very large variations in mixing.
                             </p>
                             <div id="F11" class="fig pos-float type-figure odd">
                              <div class="highwire-figure">
                               <div class="fig-inline-img-wrapper">
                                <div class="fig-inline-img">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F11.large.jpg?width=800&height=600&carousel=1" title="Decoding results from simulation 2. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The y-axis represents accuracy scores, while the x-axis represents magnitude of noise added to measurement weights for the second level model. Note that classifier accuracy never dips below chance levels (dotted line) for either model. (b) Proportion of positive tests of each type. The y-axis represents proportion of positives, and x-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains well above the accepted 5% threshold (dotted line) at noise levels with a standard deviation five times the average value of the original weights. (c-d) Proportion of each type of conclusion in Table 1 (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml">Decoding results from simulation 2. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The <em>y</em>-axis represents accuracy scores, while the <em>x</em>-axis represents magnitude of noise added to measurement weights for the second level model. Note that classifier accuracy never dips below chance levels (dotted line) for either model. (b) Proportion of positive tests of each type. The <em>y</em>-axis represents proportion of positives, and <em>x</em>-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains well above the accepted 5% threshold (dotted line) at noise levels with a standard deviation five times the average value of the original weights. (c-d) Proportion of each type of conclusion in Table 1 (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity.</div></div>' data-icon-position="" data-hide-link-title="0">
                                  <span class="hw-responsive-img">
                                   <img class="highwire-fragment fragment-image lazyload" alt="Figure 11:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F11.medium.gif" width="440" height="392"/>
                                   <noscript>
                                    <img class="highwire-fragment fragment-image" alt="Figure 11:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F11.medium.gif" width="440" height="392"/>
                                   </noscript>
                                  </span>
                                 </a>
                                </div>
                               </div>
                               <ul class="highwire-figure-links inline">
                                <li class="download-fig first">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F11.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 11:" data-icon-position="" data-hide-link-title="0">
                                  Download figure
                                 </a>
                                </li>
                                <li class="new-tab last">
                                 <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F11.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                  Open in new tab
                                 </a>
                                </li>
                               </ul>
                              </div>
                              <div class="fig-caption">
                               <span class="fig-label">
                                Figure 11:
                               </span>
                               <p id="p-78" class="first-child">
                                Decoding results from simulation 2. (a) Classifier accuracy scores for model-generated data from both levels of the context dimension. The y-axis represents accuracy scores, while the x-axis represents magnitude of noise added to measurement weights for the second level model. Note that classifier accuracy never dips below chance levels (dotted line) for either model. (b) Proportion of positive tests of each type. The y-axis represents proportion of positives, and x-axis represents measurement noise. At all levels of measurement noise producing classifier accuracies above chance, the proportion of false positive cross-classification tests remains well above the accepted 5% threshold (dotted line) at noise levels with a standard deviation five times the average value of the original weights. (c-d) Proportion of each type of conclusion in
                                <a id="xref-table-wrap-1-7" class="xref-table" href="#T1">
                                 Table 1
                                </a>
                                (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance. The left panel (c) shows conclusions reached by using the classification accuracy invariance test against invariance, and the right panel (d) shows conclusions reached by using the decoding separability test against invariance. In both cases, the cross-classification test is used against specificity.
                               </p>
                               <div class="sb-div caption-clear">
                               </div>
                              </div>
                             </div>
                             <p id="p-79">
                              As before, the question now is whether this issue of false-positive invariance can be ameliorated by adding tests against the null of invariance. Using classification accuracy invariance, the results are not very promising. The blue line in
                              <a id="xref-fig-20-3" class="xref-fig" href="#F20">
                               Figure 20b
                              </a>
                              shows the power of this test to reject the null of invariance, which starts near zero with very small variations in weights (or mixing) and is quite low (∼60% power) even at the largest weight variations.
                              <a id="xref-fig-20-4" class="xref-fig" href="#F20">
                               Figure 20c
                              </a>
                              shows the proportion of each type of conclusion in
                              <a id="xref-table-wrap-1-8" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance, by using the cross-classification and classification accuracy invariance tests, respectively. First, the addition of classification accuracy invariance does improve the validity of conclusions. Comparing the red curve in
                              <a id="xref-fig-20-5" class="xref-fig" href="#F20">
                               Figure 20b
                              </a>
                              against the blue curve in
                              <a id="xref-fig-20-6" class="xref-fig" href="#F20">
                               Figure 20c
                              </a>
                              shows that the latter drops more steeply with size of weight changes. On the other hand, using cross-classification and classification accuracy invariance together still leads to a false positive rate above 5% across all the values of weight change simulated.
                             </p>
                             <p id="p-80">
                              On the other hand, using decoding separability the results are much better. The green line in
                              <a id="xref-fig-20-7" class="xref-fig" href="#F20">
                               Figure 20b
                              </a>
                              shows that the power of this test to reject the null of invariance is near 100% across all levels of weight change. That is, the test is sensitive to even small changes in mixing resulting from changes in context. As explained before, this high power is a consequence of the test using the whole distribution of decision variables from the decoder, rather than only binary classification decisions.
                              <a id="xref-fig-20-8" class="xref-fig" href="#F20">
                               Figure 20d
                              </a>
                              shows the proportion of each type of conclusion in
                              <a id="xref-table-wrap-1-9" class="xref-table" href="#T1">
                               Table 1
                              </a>
                              (specificity/sensitivity in red, invariance/tolerance in blue, and no conclusion in green) reached from jointly testing against specificity and invariance, by using the cross-classification and decoding separability tests, respectively. First, the test has a higher power than classification accuracy invariance to reach the correct conclusion of context-sensitivity. More importantly, at low values of mixing, the test leads to inconclusive results rather than to the incorrect conclusion of invariance.
                             </p>
                             <p id="p-81">
                              Overall, this simulation confirms our previous conclusion and theoretical expectation that supplementing the cross-classification test with a test against the null of invariance increases the validity of conclusions about the underlying codes, and that decoding separability is superior to classification accuracy invariance for that goal. We have shown that this is the case in the realistic scenario in which two different populations encode the target dimension in a similar manner, and the fact that both populations are separated can be inferred only from small differences in their relative contribution to voxel activities. With such small differences in mixing (i.e., the smallest values of weight change in
                              <a id="xref-fig-20-9" class="xref-fig" href="#F20">
                               Figure 20
                              </a>
                              ), using cross-classification alone leads to a conclusion of false positive invariance almost 100% of the time, the addition of the classification accuracy invariance test slightly reduces the issue, and the addition of the decoding separability test eliminates it, at least in our simulation. The results were similar at very large differences in mixing (i.e., the largest values of weight change in
                              <a id="xref-fig-20-10" class="xref-fig" href="#F20">
                               Figure 20
                              </a>
                              ), where using cross-classification alone leads to a conclusion of false positive invariance about 30% of the time, the addition of the classification accuracy invariance test slightly reduces the issue, and the addition of the decoding separability test eliminates it, with the most likely conclusion being the ground truth of context-sensitive encoding. We must warn again, however, that the sensitivity of the decoding separability test is expected to be lower with experimental data, as it was in our own study. The main reason why decoding separability is so extremely powerful in our simulations is that they assumed the extreme case of completely context-specific codes.
                             </p>
                            </div>
                           </div>
                           <div class="section" id="sec-11">
                            <h2 class="">
                             Discussion
                            </h2>
                            <p id="p-82">
                             Here, we have provided empirical and computational evidence supporting two insights about decoding tests of invariance reached with the help of neurocomputational theory [
                             <a id="xref-ref-4-12" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ]. First, that tests aimed at evaluating evidence against the null of context-specificity, and for the alternative of context-invariance, may be prone to false positives due to the way in which the underlying neural representations are transformed into measurements. Second, that jointly performing tests against the nulls of invariance and specificity allows one to reach more precise and valid conclusions about the underlying representations.
                            </p>
                            <p id="p-83">
                             In the empirical study, we performed decoding of orientation and spatial position from fMRI activity patterns recorded in V1, a case in which properties of the underlying neural code are known. The cross-classification test gave strong evidence for the incorrect conclusion that, in V1, encoding of spatial position is tolerant/invariant to changes in orientation, as well as some evidence for the incorrect conclusion that orientation is tolerant/invariant to changes in spatial position. We found that the addition of theoretically-derived tests of invariance leads to more valid conclusions regarding the underlying code.
                            </p>
                            <p id="p-84">
                             The results of two simulations strengthened the conclusions from the empirical study, by showing that they hold even in the extreme case of completely context-specific encoding. In the first simulation, we showed that cross-classification can lead to false positive conclusions of tolerance when absolutely no tolerance exists in the underlying neural code, and that the addition of tests against invariance leads to more valid conclusions. We also showed, through theoretical analysis and further simulations, that this problem is likely to be pervasive, rather than resulting from a hand-picked proof of concept. In our second simulation, we showed that the same results are found in simulations of realistic encoding scenarios.
                            </p>
                            <p id="p-85">
                             Based on our empirical and computational results, we conclude that the cross-classification test can lead to invalid conclusions about the invariance of neural representations. Applying the test by itself should be avoided, and previous research using the test should be re-evaluated in light of our results. Instead, we propose to routinely test against the null of invariance whenever the cross-classification test is applied. Even if a researcher is unconvinced by the pervasiveness of the problem highlighted in our study and simulations, the cost of running these additional tests is extremely low.
                            </p>
                            <p id="p-86">
                             As expected from theory, we found that the decoding separability test is sensitive to violations of invariance that cannot be captured by the classification accuracy invariance test. In particular, when decoding accuracy is near ceiling or floor values, only the decoding separability test can detect violations of invariance by relying on the more fine-grained information available in the full decoding probability distributions, rather than on the coarse information available in accuracy estimates. The reason behind this superiority is simple: the decoding separability test uses information from the full distribution of decoder decision variables, and much of this information is lost once that distribution is binarized for classification. A similar conclusion was reached by Walther et al. [
                             <a id="xref-ref-40-1" class="xref-bibr" href="#ref-40">
                              40
                             </a>
                             ], who found that the reliability of continuous neural dissimilarity measures was higher than that of classification accuracies, and concluded that this was due to the loss of information inherent to the latter. We believe that focusing on full decoding distributions can help us to move from using decoding to test whether information is encoded in a particular area, to using decoding to test how information is encoded. Additional examples of this approach have linked uncertainty in decoding distributions to behavior [
                             <a id="xref-ref-41-1" class="xref-bibr" href="#ref-41">
                              41
                             </a>
                             ], and have correlated the variability in decoding distributions to behavioral responses [
                             <a id="xref-ref-42-1" class="xref-bibr" href="#ref-42">
                              42
                             </a>
                             ].
                            </p>
                            <p id="p-87">
                             A drawback of the decoding separability test is that its application requires a large number of trials per participant. Precise kernel density estimates (and more generally, precise estimation of differences between two distributions), which are essential for accurate results from the decoding separability test, require large longitudinal datasets like the one used in this study [
                             <a id="xref-ref-43-1" class="xref-bibr" href="#ref-43">
                              43
                             </a>
                             ]. With a small number of trials per stimulus, the classification accuracy invariance test might be a better choice.
                            </p>
                            <p id="p-88">
                             Relatedly, the study of invariance could benefit from the development of a test against context-specificity to replace the cross-classification test, which is relatively insensitive due to its reliance on decoding accuracy. This new test should aim to evaluate the null hypothesis that the neural representation of a target stimulus property is completely different in two different contexts, showing non-overlapping distributions of neural activity. The development and validation of such a measure is not trivial, and we must leave it to future research. We at least know that a sensitive measure would rely on something different from the decoding distribution of the target variable, and therefore it would follow a different logic than the decoding separability test developed in previous work [
                             <a id="xref-ref-4-13" class="xref-bibr" href="#ref-4">
                              4
                             </a>
                             ].
                             <a id="xref-fig-12-1" class="xref-fig" href="#F12">
                              Figure 12
                             </a>
                             shows why this is the case. The two main axes represent measurements in two different voxels, and each ellipse represents the distribution of voxel activity patterns for a target stimulus property presented in two different contexts. It can be seen that the two distributions are completely non-overlapping in the multivariate space of voxel patterns. However, when the two distributions are projected onto the decoded variable they show a non-zero overlap, represented by the yellow rectangular area. Note how changing the direction of the decoded variable does not necessarily result in no overlap. Also, simply measuring the overlap at the voxel level does not solve the issue, because the measurement model may also artificially introduce overlap in the distributions that does not exist in the underlying neural representations. This is simply a case of the more general issue with measurement models inducing invariance in context-specific representations, presented in
                             <a id="xref-fig-3-8" class="xref-fig" href="#F3">
                              Figure 3b
                             </a>
                             .
                            </p>
                            <div id="F12" class="fig pos-float type-figure odd">
                             <div class="highwire-figure">
                              <div class="fig-inline-img-wrapper">
                               <div class="fig-inline-img">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F12.large.jpg?width=800&height=600&carousel=1" title="The decoding distributions along the decoded variable cannot be used to obtain a valid test of no overlap between neural representations across two contexts. The main axes represent measurements at the voxel level, and each ellipse represents the distribution of neural activity (after transformation by the measurement model) for a target stimulus property presented in two different contexts. The two distributions are completely non-overlapping at the level of the multivariate voxel patterns. However, when the two distributions are projected onto the decoded variable, they show a non-zero overlap represented by the yellow area." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">The decoding distributions along the decoded variable cannot be used to obtain a valid test of no overlap between neural representations across two contexts. The main axes represent measurements at the voxel level, and each ellipse represents the distribution of neural activity (after transformation by the measurement model) for a target stimulus property presented in two different contexts. The two distributions are completely non-overlapping at the level of the multivariate voxel patterns. However, when the two distributions are projected onto the decoded variable, they show a non-zero overlap represented by the yellow area.</div>' data-icon-position="" data-hide-link-title="0">
                                 <span class="hw-responsive-img">
                                  <img class="highwire-fragment fragment-image lazyload" alt="Figure 12:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F12.medium.gif" width="440" height="395"/>
                                  <noscript>
                                   <img class="highwire-fragment fragment-image" alt="Figure 12:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F12.medium.gif" width="440" height="395"/>
                                  </noscript>
                                 </span>
                                </a>
                               </div>
                              </div>
                              <ul class="highwire-figure-links inline">
                               <li class="download-fig first">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F12.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 12:" data-icon-position="" data-hide-link-title="0">
                                 Download figure
                                </a>
                               </li>
                               <li class="new-tab last">
                                <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F12.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                 Open in new tab
                                </a>
                               </li>
                              </ul>
                             </div>
                             <div class="fig-caption">
                              <span class="fig-label">
                               Figure 12:
                              </span>
                              <p id="p-89" class="first-child">
                               The decoding distributions along the decoded variable cannot be used to obtain a valid test of no overlap between neural representations across two contexts. The main axes represent measurements at the voxel level, and each ellipse represents the distribution of neural activity (after transformation by the measurement model) for a target stimulus property presented in two different contexts. The two distributions are completely non-overlapping at the level of the multivariate voxel patterns. However, when the two distributions are projected onto the decoded variable, they show a non-zero overlap represented by the yellow area.
                              </p>
                              <div class="sb-div caption-clear">
                              </div>
                             </div>
                            </div>
                            <p id="p-90">
                             Beyond the specific case of decoding tests of invariance, the present study shows the dangers of over-reliance on operational tests that have only face validity, particularly in the study of neural representation through indirect measures obtained through neuroimaging. Our study joins other recent reports in the literature [
                             <a id="xref-ref-25-2" class="xref-bibr" href="#ref-25">
                              25
                             </a>
                             ,
                             <a id="xref-ref-44-1" class="xref-bibr" href="#ref-44">
                              44
                             </a>
                             ] in showing that the application of sophisticated data analysis tools can lead to the wrong conclusions when problems of identifiability (e.g., between neural and measurement factors) inherent to neuroimaging are not taken into account. We believe that theoretical and simulation work will play an important part in the future of neuroimaging, both to point out areas in which our methods might run into issues, as well as showing us potential solutions.
                            </p>
                           </div>
                           <div class="section" id="sec-12">
                            <h2 class="">
                             Materials and Methods
                            </h2>
                            <div id="sec-13" class="subsection">
                             <h3>
                              Participants
                             </h3>
                             <p id="p-91">
                              Five healthy volunteers (ages 19–27, three female) from Florida International University participated in the experiment; all had normal or corrected-to-normal vision. The study protocol was approved by Florida International University’s Institutional Review Board and by the Center for Imaging Science Steering Committee. All subjects gave written consent to experimental procedures before participating in the experiment.
                             </p>
                            </div>
                            <div id="sec-14" class="subsection">
                             <h3>
                              Stimuli
                             </h3>
                             <p id="p-92">
                              All stimuli were generated using Psychopy v.1.85.0 [
                              <a id="xref-ref-45-1" class="xref-bibr" href="#ref-45">
                               45
                              </a>
                              ]. Images were displayed on a 40″ Nordic Neurolab LCD InroomViewing Device, placed at the rear entrance of the scanner bore. Subjects viewed the screen via an angled mirror attached to the head coil. Visual stimuli were full-contrast square-wave gratings with a spatial frequency of 1.5 cycles per degree of visual angle [similar to
                              <a id="xref-ref-18-1" class="xref-bibr" href="#ref-18">
                               18
                              </a>
                              ,
                              <a id="xref-ref-19-1" class="xref-bibr" href="#ref-19">
                               19
                              </a>
                              ,
                              <a id="xref-ref-46-1" class="xref-bibr" href="#ref-46">
                               46
                              </a>
                              ], a frequency known to drive V1 responses strongly [
                              <a id="xref-ref-47-1" class="xref-bibr" href="#ref-47">
                               47
                              </a>
                              ], shown through a wedge-shaped aperture window that spanned from 1.5° to 10° of eccentricity and 100° of polar angle (
                              <a id="xref-fig-13-7" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ). The aperture window had four possible locations, starting at 20°, 80°, 200°, and 260° of rotation. The square-wave gratings were oriented in one of four angles for each trial: 0°, 45°, 90°, 135°. The phase of the gratings was randomly changed every 250ms, to reduce retinal adaptation and afterimages.
                             </p>
                            </div>
                            <div id="sec-15" class="subsection">
                             <h3>
                              Task and Procedures
                             </h3>
                             <p id="p-93">
                              To ensure that the data used to train a classifier in decoding analyses (see below) was independent from the data used to test the classifier and compute measures of performance, training trials and testing trials were presented on separate acquisition runs. Training and testing runs were identical in all aspects except one: the positions of the aperture window were restricted to 20° and 200° of rotation for the training runs, while testing runs included all four positions (
                              <a id="xref-fig-13-8" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ). During stimulus presentation, the phase of the grating was randomly shifted every 250 ms. The orientation of each grating was randomly chosen on each trial, while the spatial position of the window changed sequentially in a pre-determined manner. In training runs, the aperture window switched between 20° and 200° on every trial. In testing runs, the aperture window cycled through 20°, 200°, 80°, 260°, in that order. For both training and testing runs, each combination of spatial position (two or four levels) and orientation (four levels) was presented 35 times in a single acquisition session. Each subject went through 4 identical acquisition sessions to yield a total of 135 presentations of a given combination of orientation and spatial position (see all combinations in
                              <a id="xref-fig-13-9" class="xref-fig" href="#F13">
                               Figure 13
                              </a>
                              ) for both training and testing trials types. This large longitudinal sample size (3,240 trials total per participant) was chosen to focus our analyses on data at the level of individual participants (see Statistical Analyses below).
                             </p>
                             <p id="p-94">
                              On each trial, a single grating was presented for 3s, followed by a 3s inter-trial interval. All runs began with a 10s fixation period and ended with a 1 min rest period. The training runs lasted for 5 mins and 43 secs, and the test runs lasted for 10 mins and 13s. Due to experimenter error during data acquisition, a portion of training trials were lost for participants 1 and 2. To compensate for the reduced number of training trials, we collected an additional session of data from subject 2, resulting in about 123 training trials and 112 testing trials per stimulus. For subject 1, we simply set aside half of the testing trials for training purposes and used the other half for testing; the number of testing trials for non-trained values of the context dimension remained the same as for all other participants.
                             </p>
                             <p id="p-95">
                              The participants’ task was to look at a small black ring presented in the center of the screen [similar to
                              <a id="xref-ref-18-2" class="xref-bibr" href="#ref-18">
                               18
                              </a>
                              ]. The black ring had a small gap that randomly switched position throughout the trial. Participants were asked to continuously report the side of the gap (left or right) by pressing the corresponding button. The task had the purpose of forcing participants to fixate at the center of the screen, and to draw attention away from the stimuli.
                             </p>
                            </div>
                            <div id="sec-16" class="subsection">
                             <h3>
                              Functional Imaging
                             </h3>
                             <p id="p-96">
                              Imaging was performed with a Siemens Magnetom Prisma 3T whole-body MRI system located at the Center for Imaging Science, Florida International University. A volume RF coil (transmit) and a 32-channel receive array were used to acquire both functional and anatomical images. Each subject participated in four identical MRI sessions. During each session, a high-resolution 3D anatomical T1-weighted volume (MPRAGE; TR 2.4s; TI 1.1s; TE 2.9 ms; flip angle 7°; voxel size 1×1×1 mm; FOV 256 mm; 176 sagittal slices) was obtained, which served as the reference volume to align all functional images. During the main experiment, functional images were collected using a T2*-weighted EPI sequence (TR 1.5 s; TE 30 ms; flip angle 52°; sensitivity encoding with acceleration factor of 4). We collected 60 transversal slices, with resolution of 2.4×2.4×2.4 mm, and FOV of 219mm. The first six volumes in each run were discarded to allow T1 magnetization to reach steady state.
                             </p>
                            </div>
                            <div id="sec-17" class="subsection">
                             <h3>
                              Statistical Analyses
                             </h3>
                             <p id="p-97">
                              All data analyses, including multi-voxel decoding and tests of invariance, were performed on the individual data of each participant. In designing our experiment, we favored collection of a large amount of data per participant (3,240 trials, about 8 hours of scanning) rather than a large number of participants. Each separate analysis can be considered a replication of a single-subject experiment. With our sample sizes (n=135 per stimulus), our tests can detect a 6% difference from chance in classifier performance with 85% power, an 8% drop in classifier performance with >80% power, and kernel density estimate error is maximally reduced, according to simulation studies [
                              <a id="xref-ref-43-2" class="xref-bibr" href="#ref-43">
                               43
                              </a>
                              ].
                             </p>
                             <div id="sec-18" class="subsection">
                              <h4>
                               Region of Interest
                              </h4>
                              <p id="p-98">
                               The boundaries of V1 are commonly found using a functional localizer procedure. However, previous work has shown such boundaries can be accurately estimated from cortical folds, without the need for a functional localizer [
                               <a id="xref-ref-48-1" class="xref-bibr" href="#ref-48">
                                48
                               </a>
                               ]. Additionally, evidence shows that the definition of V1 boundaries using the algorithm proposed by
                               <strong>
                                (author?)
                               </strong>
                               [
                               <a id="xref-ref-48-2" class="xref-bibr" href="#ref-48">
                                48
                               </a>
                               ] has a precision that is equivalent to 10-25 minutes of functional mapping [
                               <a id="xref-ref-49-1" class="xref-bibr" href="#ref-49">
                                49
                               </a>
                               ]. Therefore, we applied the
                               <strong>
                                (author?)
                               </strong>
                               [
                               <a id="xref-ref-48-3" class="xref-bibr" href="#ref-48">
                                48
                               </a>
                               ] algorithm, implemented in Freesurfer 6.0 [
                               <a id="xref-ref-50-1" class="xref-bibr" href="#ref-50">
                                50
                               </a>
                               ], to the anatomical T1-weighted images, to define the boundaries of V1 in each participant and obtain an ROI mask. The obtained V1 mask was then converted into a binary mask, and transformed to the individual’s functional scan space (the averaged volume of the first functional run was used as a target) using linear registration with FLIRT. An example mask, obtained from one participant in the study, is displayed in
                               <a id="xref-fig-14-1" class="xref-fig" href="#F14">
                                Figure 14
                               </a>
                               .
                              </p>
                              <div id="F13" class="fig pos-float type-figure odd">
                               <div class="highwire-figure">
                                <div class="fig-inline-img-wrapper">
                                 <div class="fig-inline-img">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F13.large.jpg?width=800&height=600&carousel=1" title="Stimuli were composed of oriented gratings (dimension 1) presented in a windowed spatial position (dimension 2). Each trial consisted of a single combination of orientated gratings and spatial position. Training runs were composed of stimuli presented only in spatial positions 20° and 200° (highlighted through red and blue boxes). Testing runs included all sixteen stimulus combinations." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Stimuli were composed of oriented gratings (dimension 1) presented in a windowed spatial position (dimension 2). Each trial consisted of a single combination of orientated gratings and spatial position. Training runs were composed of stimuli presented only in spatial positions 20° and 200° (highlighted through red and blue boxes). Testing runs included all sixteen stimulus combinations.</div>' data-icon-position="" data-hide-link-title="0">
                                   <span class="hw-responsive-img">
                                    <img class="highwire-fragment fragment-image lazyload" alt="Figure 13:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F13.medium.gif" width="440" height="286"/>
                                    <noscript>
                                     <img class="highwire-fragment fragment-image" alt="Figure 13:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F13.medium.gif" width="440" height="286"/>
                                    </noscript>
                                   </span>
                                  </a>
                                 </div>
                                </div>
                                <ul class="highwire-figure-links inline">
                                 <li class="download-fig first">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F13.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 13:" data-icon-position="" data-hide-link-title="0">
                                   Download figure
                                  </a>
                                 </li>
                                 <li class="new-tab last">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F13.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                   Open in new tab
                                  </a>
                                 </li>
                                </ul>
                               </div>
                               <div class="fig-caption">
                                <span class="fig-label">
                                 Figure 13:
                                </span>
                                <p id="p-99" class="first-child">
                                 Stimuli were composed of oriented gratings (dimension 1) presented in a windowed spatial position (dimension 2). Each trial consisted of a single combination of orientated gratings and spatial position. Training runs were composed of stimuli presented only in spatial positions 20° and 200° (highlighted through red and blue boxes). Testing runs included all sixteen stimulus combinations.
                                </p>
                                <div class="sb-div caption-clear">
                                </div>
                               </div>
                              </div>
                              <div id="F14" class="fig pos-float type-figure odd">
                               <div class="highwire-figure">
                                <div class="fig-inline-img-wrapper">
                                 <div class="fig-inline-img">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F14.large.jpg?width=800&height=600&carousel=1" title="Example V1 mask obtained from one participant in this study." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Example V1 mask obtained from one participant in this study.</div>' data-icon-position="" data-hide-link-title="0">
                                   <span class="hw-responsive-img">
                                    <img class="highwire-fragment fragment-image lazyload" alt="Figure 14:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F14.medium.gif" width="440" height="328"/>
                                    <noscript>
                                     <img class="highwire-fragment fragment-image" alt="Figure 14:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F14.medium.gif" width="440" height="328"/>
                                    </noscript>
                                   </span>
                                  </a>
                                 </div>
                                </div>
                                <ul class="highwire-figure-links inline">
                                 <li class="download-fig first">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F14.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 14:" data-icon-position="" data-hide-link-title="0">
                                   Download figure
                                  </a>
                                 </li>
                                 <li class="new-tab last">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F14.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                   Open in new tab
                                  </a>
                                 </li>
                                </ul>
                               </div>
                               <div class="fig-caption">
                                <span class="fig-label">
                                 Figure 14:
                                </span>
                                <p id="p-100" class="first-child">
                                 Example V1 mask obtained from one participant in this study.
                                </p>
                                <div class="sb-div caption-clear">
                                </div>
                               </div>
                              </div>
                             </div>
                             <div id="sec-19" class="subsection">
                              <h4>
                               BOLD Data Preprocessing
                              </h4>
                              <p id="p-101">
                               Data were processed and analyzed using nipype Python wrappers for FSL [
                               <a id="xref-ref-51-1" class="xref-bibr" href="#ref-51">
                                51
                               </a>
                               ,
                               <a id="xref-ref-52-1" class="xref-bibr" href="#ref-52">
                                52
                               </a>
                               ]. Basic preprocessing of functional data included skull stripping, slice time correction, and head motion correction using MCFLIRT. All functional runs for a given subject were then aligned to an averaged volume of the first functional run for the same subject. This step ensured that the entire time-series for each subject lay in the same co-ordinate space. The aligned time-series was then concatenated into a single time-series file for further processing. The concatenated series for each subject was de-trended using a Savitzky-Golay filter with a polynomial order of 3 and a window length of 81 secs [
                               <a id="xref-ref-53-1" class="xref-bibr" href="#ref-53">
                                53
                               </a>
                               ].
                              </p>
                             </div>
                             <div id="sec-20" class="subsection">
                              <h4>
                               Deconvolution
                              </h4>
                              <p id="p-102">
                               Using the obtained V1 mask, time-series from V1 voxels were extracted for further analysis. Single-trial activity estimates were obtained via a data-driven deconvolution technique in which deconvolved neural activation values and a model of the hemodynamic response function (HRF) are estimated together [
                               <a id="xref-ref-53-2" class="xref-bibr" href="#ref-53">
                                53
                               </a>
                               ]. Unlike other methods that hold the shape of the HRF constant across voxels, this technique allows the shape of the HRF to be different in each voxel, resulting in more accurate activity estimates. The model is implemented via the hrf_estimation Python package v. 1.1 (
                               <a href="https://pypi.org/project/hrf_estimation/">
                                https://pypi.org/project/hrf_estimation/
                               </a>
                               ). The hrf_estimation package presents 10 different options for HRF modeling, with varying options for the HRF basis function and for the General Linear Model estimation technique. To select the optimal combination of HRF and estimation method, we performed a cross-validated decoding analysis using data from the training runs of a single participant (data from the testing runs was not used in this pre-analysis). First, we generated activity estimates from all possible model combinations (estimation method and HRF). Then, for each model, we trained and tested an SVM classifier to decode orientations from a portion of the training set, and tested the classifier with the remaining data. We chose the Rank-1 General Linear Model with a 3-basis-functions HRF model, based on the fact that it yielded the highest testing accuracy score.
                              </p>
                             </div>
                             <div id="sec-21" class="subsection">
                              <h4>
                               Decoding Analysis
                              </h4>
                              <p id="p-103">
                               To decode stimulus types based on voxel-wise activity patterns, we used a Nu-support vector machine (NuSVC) classifier with a linear basis function implemented via the Python package scikit-learn v. 0.19.1 [
                               <a id="xref-ref-54-1" class="xref-bibr" href="#ref-54">
                                54
                               </a>
                               ]. We used the de-convolved activity patterns from V1 voxels as inputs to the classifier, while trial-specific stimulus values (either orientation or spatial position) were provided as labels.
                              </p>
                              <p id="p-104">
                               To decode orientation, we employed two separate classifiers, corresponding to the two different spatial positions (context dimension) at which the oriented gratings were presented during the training runs of the experiment (see
                               <a id="xref-fig-13-10" class="xref-fig" href="#F13">
                                Figure 13
                               </a>
                               ). Each classifier was trained to decode grating orientation (0°, 45°, 90°, and 135°) using only trials in which a specific spatial position was presented. However, the classifier was then tested with data collected from independent test runs at all four spatial positions. This resulted in an accuracy estimate at the training position, as well as at the other three spatial positions. For example, to train the first classifier, we gathered all trials that were presented at spatial position 20°. After normalizing the data, the classifier was trained using leave-one-run-out cross-validation with data from the training runs. Cross-validation was used to optimized the Nu parameter of the classifier, to obtain the highest accuracies within the training set. A new classifier was then trained on all the training data using the chosen Nu parameter. This classifier was then tested with data from testing runs.
                              </p>
                              <p id="p-105">
                               To decode spatial position, we employed four separate classifiers corresponding to the four levels of grating orientation (context dimension) that were presented during the training runs of the experiment. Each classifier was trained to decode spatial position (top-right vs bottom-left, see boxed stimuli in
                               <a id="xref-fig-13-11" class="xref-fig" href="#F13">
                                Figure 13
                               </a>
                               ) using only trials in which a specific grating orientation was presented. However, the classifier was then tested with data collected from independent test runs across all levels of grating orientation. This resulted in an accuracy estimate for the training grating orientation, as well as the other three levels of grating orientation. As in the orientation decoding procedure, we divided the data into independent training and test sets, performed normalization, and optimized the classifier’s Nu parameter via leave-one-run-out cross-validation. One important difference is that spatial position decoding involved a two-class classification problem, where the classifiers had to discriminate between 20° and 200° spatial position of the stimulus window (the only two positions presented during training trials, see boxed stimuli in
                               <a id="xref-fig-13-12" class="xref-fig" href="#F13">
                                Figure 13
                               </a>
                               ). As the classifier was not trained to classify the 80° or 260° spatial positions, we dropped those trials from the testing data set in this analysis. This ensured that the model fitting and testing procedures remained consistent across both decoding analyses.
                              </p>
                             </div>
                             <div id="sec-22" class="subsection">
                              <h4>
                               fMRI Decoding Tests
                              </h4>
                              <p id="p-106">
                               Many possible operational tests of invariance can be proposed based on the results of a decoding study, but we applied three of them to our data: the cross-classification test, the classification accuracy invariance test, and the decoding separability test. All tests where applied to the results of the two decoding analyses above: decoding of orientation and spatial position. In the descriptions below, the target dimension refers to the decoded stimulus values, and the context dimension refers to the stimulus values irrelevant for decoding that only changed from training to testing.
                              </p>
                              <p id="p-107">
                               All the tests described below were implemented in Python expanded with SciPy v. 1.1.0 (
                               <a href="https://www.scipy.org/">
                                https://www.scipy.org/
                               </a>
                               ) and Statsmodels v. 0.9.0 (
                               <a href="https://www.statsmodels.org/">
                                https://www.statsmodels.org/
                               </a>
                               ). Plots were created using the Matplotlib library v. 2.2.2 (
                               <a href="https://matplotlib.org/">
                                https://matplotlib.org/
                               </a>
                               )
                              </p>
                              <div id="sec-23" class="subsection">
                               <h5>
                                Cross-classification Test
                               </h5>
                               <p id="p-108">
                                The cross-classification invariance test is a well-known test in the literature that is meant to provide evidence for invariant representations directly from voxel-level activity estimates [e.g., 1, 2, 3]. As shown in
                                <a id="xref-fig-2-5" class="xref-fig" href="#F2">
                                 Figure 2
                                </a>
                                , the first step in this test is to train a classifier or another procedure to decode a particular stimulus feature from patterns of fMRI activity observed across voxels. In the figure, the feature that is being decoded is whether a face presented from a frontal viewpoint is male or female. The second step is to test the same classifier with new patterns of fMRI activity, this time obtained from presentation of the same stimuli changed in a context dimension, such as head orientation. If accuracy with this test data is higher than chance, then the conclusion is that that an invariant neural representation of the target feature is stored in the area from which the fMRI activity was obtained.
                               </p>
                               <p id="p-109">
                                We implement the cross-classification invariance test by training a linear SVM, as described above, to classify levels of the target dimension (grating orientation or spatial position) while holding the level of the context dimension constant. For example, to decode orientation we start by training the SVM classifier to predict orientation in a given spatial position. Then, we test the accuracy of the classifier with data from independent test sets at the training position, as well as three other spatial positions (i.e., different levels of the context dimension). We tested whether each of these accuracies was above the chance level of 25% correct using a binomial test, and corrected the resulting p-values for multiple comparisons using the Holm-Sidak method. If classification accuracy was above chance at any of the testing levels of the context dimension, then the cross-classification invariance test concludes that there is evidence for invariance of the target dimension from the context dimension.
                               </p>
                              </div>
                              <div id="sec-24" class="subsection">
                               <h5>
                                Classification Accuracy Invariance Test
                               </h5>
                               <p id="p-110">
                                Classification accuracy invariance is defined as the case where the probability of correct classification is exactly the same across all levels of the context dimension. This test is theory-driven, as it was suggested by neurocomputational theory as a valid way to obtain information about invariance [
                                <a id="xref-ref-4-14" class="xref-bibr" href="#ref-4">
                                 4
                                </a>
                                ]. Still, we are aware of at least one prior study using a version of this test to obtain evidence of position-dependent encoding of object category information in lateral occipital cortex, and of position-dependent encoding of face viewpoint information in right fusiform face area [
                                <a id="xref-ref-6-3" class="xref-bibr" href="#ref-6">
                                 6
                                </a>
                                ].
                               </p>
                               <p id="p-111">
                                This test uses the same estimates of classification accuracy described for the cross-classification test, but uses them to check whether there is a significant drop in performance from the training to the testing context values. We first performed an omnibus Chi-Square test of the null hypothesis that accuracy does not depend on level of the context dimension. In addition, we tested accuracy at each testing context value against the training context value using a pairwise z test for proportions, and corrected the resulting p-values for multiple comparisons using the Holm-Sidak method.
                               </p>
                              </div>
                              <div id="sec-25" class="subsection">
                               <h5>
                                Decoding Separability Test
                               </h5>
                               <p id="p-112">
                                Linear classifiers–like the linear SVM used here–perform classification of a new data point by computing a decision variable z, representing the distance of the data point from the classifier’s hyperplane separating two classes. When the decision variable is larger than some criterion value (usually zero), the output is one class, whereas when the decision variable is smaller than the criterion the output is the other class.
                               </p>
                               <p id="p-113">
                                This suggests that a better test of invariance should use not only classification accuracy scores, but rather the full distribution of such decision variables, or decoding distribution. Decoding separability is defined as the case where the decoding distribution of a stimulus does not change across different levels of the context dimension (
                                <a id="xref-fig-15-2" class="xref-fig" href="#F15">
                                 Figure 15
                                </a>
                                ). In
                                <a id="xref-fig-15-3" class="xref-fig" href="#F15">
                                 Figure 15
                                </a>
                                , the decoding distribution for a female face is shown for different viewpoints (context dimension). In this case, decoding separability is said to fail when the estimated decoding distribution for a target stimulus feature (e.g., maleness) is significantly different across any two levels of the context dimension (viewpoint). The distance between the two distributions of interest provides a numerical estimate of deviations from decoding separability. One way to measure this distance is through the L1 norm:
                                <span class="disp-formula" id="disp-formula-4">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-19.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-19.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                where p
                                <sub>
                                 1
                                </sub>
                                and p
                                <sub>
                                 2
                                </sub>
                                represent the distributions of decoded values at levels 1 and 2 of the context dimension, respectively. The L1 distance between two distributions is represented in
                                <a id="xref-fig-15-4" class="xref-fig" href="#F15">
                                 Figure 15
                                </a>
                                by the area highlighted in light yellow.
                               </p>
                               <div id="F15" class="fig pos-float type-figure odd">
                                <div class="highwire-figure">
                                 <div class="fig-inline-img-wrapper">
                                  <div class="fig-inline-img">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F15.large.jpg?width=800&height=600&carousel=1" title="The decoding separability test. This is a theoretically-driven test of invariance that relies directly on the decoded stimulus distributions. Neural noise and random error in the decoding of stimulus values gives rise to decoding probability distributions. In this example, decoding distributions are shown for some facial identity whose viewpoint changes. If the two decoding distributions corresponding to different viewpoints are the same (left), then decoding separability is said to hold. If the decoding distributions are shifted for two levels of viewpoint (right), then decoding separability is said to fail." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">The decoding separability test. This is a theoretically-driven test of invariance that relies directly on the decoded stimulus distributions. Neural noise and random error in the decoding of stimulus values gives rise to decoding probability distributions. In this example, decoding distributions are shown for some facial identity whose viewpoint changes. If the two decoding distributions corresponding to different viewpoints are the same (left), then decoding separability is said to hold. If the decoding distributions are shifted for two levels of viewpoint (right), then decoding separability is said to fail.</div>' data-icon-position="" data-hide-link-title="0">
                                    <span class="hw-responsive-img">
                                     <img class="highwire-fragment fragment-image lazyload" alt="Figure 15:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F15.medium.gif" width="440" height="262"/>
                                     <noscript>
                                      <img class="highwire-fragment fragment-image" alt="Figure 15:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F15.medium.gif" width="440" height="262"/>
                                     </noscript>
                                    </span>
                                   </a>
                                  </div>
                                 </div>
                                 <ul class="highwire-figure-links inline">
                                  <li class="download-fig first">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F15.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 15:" data-icon-position="" data-hide-link-title="0">
                                    Download figure
                                   </a>
                                  </li>
                                  <li class="new-tab last">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F15.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                    Open in new tab
                                   </a>
                                  </li>
                                 </ul>
                                </div>
                                <div class="fig-caption">
                                 <span class="fig-label">
                                  Figure 15:
                                 </span>
                                 <p id="p-114" class="first-child">
                                  The decoding separability test. This is a theoretically-driven test of invariance that relies directly on the decoded stimulus distributions. Neural noise and random error in the decoding of stimulus values gives rise to decoding probability distributions. In this example, decoding distributions are shown for some facial identity whose viewpoint changes. If the two decoding distributions corresponding to different viewpoints are the same (left), then decoding separability is said to hold. If the decoding distributions are shifted for two levels of viewpoint (right), then decoding separability is said to fail.
                                 </p>
                                 <div class="sb-div caption-clear">
                                 </div>
                                </div>
                               </div>
                               <p id="p-115">
                                For each combination of values of the relevant and context dimensions, we obtained decision variables from the trained SVM linear classifier. These decision variables were used to estimate the decoding distribution using kernel density estimates (KDEs). A gaussian kernel and automatic bandwidth determination were used as implemented in the SciPy function gaussian_kde. Let p̂
                                <sub>
                                 ij
                                </sub>
                                (z) represent the KDE for a stimulus with value i on the target dimension and value j on the context dimension, evaluated at point z. Each p̂
                                <sub>
                                 ij
                                </sub>
                                (z) was evaluated at values of z going from -3 to 6, in 0.01 steps, indexed by k, which were confirmed to cover the range of observed decision variable values. Then an estimate of the summed L1 distances indicating deviations from decoding separability was computed from all four KDEs obtained, according to the following equation:
                                <span class="disp-formula" id="disp-formula-5">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-21.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-21.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                , where j = 1 is the training level of the context dimension. The
                                <span class="inline-formula" id="inline-formula-11">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-11.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-11.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                (with G standing for global) simply takes an estimate of the L1 distance (obtained by discretizing the continuous decision variable z) defined in
                                <a id="xref-disp-formula-4-1" class="xref-disp-formula" href="#disp-formula-4">
                                 Equation 2
                                </a>
                                for each value of the relevant dimension, and then sums them together. We computed
                                <span class="inline-formula" id="inline-formula-12">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-12.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-12.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                separately for each value of the context dimension, or j ≠ 1.
                               </p>
                               <p id="p-116">
                                We used a permutation test to test whether each
                                <span class="inline-formula" id="inline-formula-13">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-13.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-13.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                statistic was significantly larger than expected by chance. In this test, the level of the context dimension j was randomly re-assigned to all data points, KDEs were estimated, and the
                                <span class="inline-formula" id="inline-formula-14">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-14.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-14.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                was computed according to
                                <a id="xref-disp-formula-5-2" class="xref-disp-formula" href="#disp-formula-5">
                                 Equation 3
                                </a>
                                . This process was repeated 5,000 times, to obtain an empirical distribution for the statistic, from which accurate p-values were computed using the procedure proposed by [
                                <a id="xref-ref-55-1" class="xref-bibr" href="#ref-55">
                                 55
                                </a>
                                ]. The resulting p-values were corrected for multiple comparisons using the Holm-Sidak method.
                               </p>
                              </div>
                             </div>
                            </div>
                            <div id="sec-26" class="subsection">
                             <h3>
                              Simulations
                             </h3>
                             <p id="p-117">
                              The simulations described below were implemented in Python 2.6 extended with Numpy v. 1.16.2 (
                              <a href="https://numpy.org/">
                               https://numpy.org/
                              </a>
                              ). The decoding analysis of simulated data was performed exactly as described for fMRI data in the sections Decoding Analysis and fMRI Decoding Tests above, with the exception that the Nu parameter of the SVM was set to the default value of 0.5 rather than optimized based on cross-validation.
                             </p>
                             <div id="sec-27" class="subsection">
                              <h4>
                               Model
                              </h4>
                              <p id="p-118">
                               In our simulations, we used a standard population encoding model and a linear measurement model. Both are common choices in the computational neuroimaging literature (for a review, see [
                               <a id="xref-ref-56-1" class="xref-bibr" href="#ref-56">
                                56
                               </a>
                               ]), both in recent simulation work [e.g.,
                               <a id="xref-ref-57-1" class="xref-bibr" href="#ref-57">
                                57
                               </a>
                               ,
                               <a id="xref-ref-44-2" class="xref-bibr" href="#ref-44">
                                44
                               </a>
                               ,
                               <a id="xref-ref-25-3" class="xref-bibr" href="#ref-25">
                                25
                               </a>
                               ], as well as in model-based data analysis [e.g.,
                               <a id="xref-ref-22-2" class="xref-bibr" href="#ref-22">
                                22
                               </a>
                               ,
                               <a id="xref-ref-58-1" class="xref-bibr" href="#ref-58">
                                58
                               </a>
                               ,
                               <a id="xref-ref-24-2" class="xref-bibr" href="#ref-24">
                                24
                               </a>
                               ,
                               <a id="xref-ref-41-2" class="xref-bibr" href="#ref-41">
                                41
                               </a>
                               ]. We assumed a circular dimension with values ranging from -90 to 90, as is the case of grating orientation, but our conclusions apply to non-circular dimensions as well.
                              </p>
                              <div id="sec-28" class="subsection">
                               <h5>
                                Encoding Model
                               </h5>
                               <p id="p-119">
                                We used standard encoding models to represent the activity patterns of populations of neurons within a given voxel. Our encoding model was composed of several independent channels, representing any number of neurons that have similar stimulus preferences. Each channel is highly tuned to a specific value along the target stimulus dimension, such that the channel’s response becomes attenuated as we move away from the preferred value. The tuning function of a single channel is represented by a Gaussian function:
                                <span class="disp-formula" id="disp-formula-6">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-22.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-22.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                , where r
                                <sup>
                                 max
                                </sup>
                                represents the maximum neural activity for channel c, the mean s
                                <sub>
                                 c
                                </sub>
                                represents the channel’s preferred stimulus, and the standard deviation ω
                                <sub>
                                 c
                                </sub>
                                represents the width of the tuning function. The height of the tuning functions at any value along the stimulus dimension (i.e., f
                                <sub>
                                 c
                                </sub>
                                (s)) represents the average response of the channels to that particular stimuli.
                               </p>
                               <p id="p-120">
                                We assume that the response of each channel r
                                <sub>
                                 c
                                </sub>
                                is a random variable with Poisson distribution:
                                <span class="disp-formula" id="disp-formula-7">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-23.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-23.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                The full encoding model was composed of ten channels with activity described by
                                <a id="xref-disp-formula-6-1" class="xref-disp-formula" href="#disp-formula-6">
                                 Equations 4
                                </a>
                                and
                                <a id="xref-disp-formula-7-1" class="xref-disp-formula" href="#disp-formula-7">
                                 5
                                </a>
                                . Unless indicated otherwise below, we used a homogeneous population model, in which the parameters s
                                <sub>
                                 c
                                </sub>
                                were evenly distributed across all possible values of the dimension (i.e., from -90 to 90 degrees), and other parameters were fixed to the same values for all channels:
                                <span class="inline-formula" id="inline-formula-15">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-15.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/inline-graphic-15.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                .
                               </p>
                               <p id="p-121">
                                <a id="xref-fig-16-1" class="xref-fig" href="#F16">
                                 Figure 16
                                </a>
                                shows an example of the encoding process. When a face with a value of 75% maleness is presented to the model, the channel encoding distribution produces a vector of responses. Each element in this vector corresponds to the response of a particular channel. The channels with the strongest preference for the value 75% show the highest response in this vector. Since the response of neural populations are known to be noisy, channel noise is added to each element of the response vector. The final output is a noisy vector of channel responses that change slightly for repeated presentations of the same stimulus.
                               </p>
                               <div id="F16" class="fig pos-float type-figure odd">
                                <div class="highwire-figure">
                                 <div class="fig-inline-img-wrapper">
                                  <div class="fig-inline-img">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F16.large.jpg?width=800&height=600&carousel=1" title="Population encoding model. This figures illustrates how stimulus information can be encoded by a set of neurons in the brain. The encoding model consists of a set of channels that are tuned to specific stimulus values along a given dimension (e.g., maleness). When a stimulus with a particular value on the maleness dimension is presented, the channels respond according to their stimulus preferences. The channel responses are then perturbed by random channel noise. The final output represents a vector of noisy firing rates in response to a particular stimulus." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Population encoding model. This figures illustrates how stimulus information can be encoded by a set of neurons in the brain. The encoding model consists of a set of channels that are tuned to specific stimulus values along a given dimension (e.g., maleness). When a stimulus with a particular value on the maleness dimension is presented, the channels respond according to their stimulus preferences. The channel responses are then perturbed by random channel noise. The final output represents a vector of noisy firing rates in response to a particular stimulus.</div>' data-icon-position="" data-hide-link-title="0">
                                    <span class="hw-responsive-img">
                                     <img class="highwire-fragment fragment-image lazyload" alt="Figure 16:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F16.medium.gif" width="440" height="117"/>
                                     <noscript>
                                      <img class="highwire-fragment fragment-image" alt="Figure 16:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F16.medium.gif" width="440" height="117"/>
                                     </noscript>
                                    </span>
                                   </a>
                                  </div>
                                 </div>
                                 <ul class="highwire-figure-links inline">
                                  <li class="download-fig first">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F16.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 16:" data-icon-position="" data-hide-link-title="0">
                                    Download figure
                                   </a>
                                  </li>
                                  <li class="new-tab last">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F16.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                    Open in new tab
                                   </a>
                                  </li>
                                 </ul>
                                </div>
                                <div class="fig-caption">
                                 <span class="fig-label">
                                  Figure 16:
                                 </span>
                                 <p id="p-122" class="first-child">
                                  Population encoding model. This figures illustrates how stimulus information can be encoded by a set of neurons in the brain. The encoding model consists of a set of channels that are tuned to specific stimulus values along a given dimension (e.g., maleness). When a stimulus with a particular value on the maleness dimension is presented, the channels respond according to their stimulus preferences. The channel responses are then perturbed by random channel noise. The final output represents a vector of noisy firing rates in response to a particular stimulus.
                                 </p>
                                 <div class="sb-div caption-clear">
                                 </div>
                                </div>
                               </div>
                              </div>
                              <div id="sec-29" class="subsection">
                               <h5>
                                Measurement Model
                               </h5>
                               <p id="p-123">
                                Because neuroimaging studies produce only indirect measures of neural activity, a measurement model is required to link the neural responses of the encoding model with voxel-wise activity values. The measurement model is described by the following equation:
                                <span class="disp-formula" id="disp-formula-8">
                                 <span class="highwire-responsive-lazyload">
                                  <img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" class="highwire-embed lazyload" alt="Embedded Image" data-src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-25.gif"/>
                                  <noscript>
                                   <img class="highwire-embed" alt="Embedded Image" src="https://www.biorxiv.org/sites/default/files/highwire/biorxiv/early/2022/04/15/2020.02.27.967505/embed/graphic-25.gif"/>
                                  </noscript>
                                 </span>
                                </span>
                                where
                                <strong>
                                 a
                                </strong>
                                is a row vector of voxel activity values,
                                <strong>
                                 r
                                </strong>
                                is a row vector of neural responses sampled from the encoding model (i.e., from
                                <a id="xref-disp-formula-7-2" class="xref-disp-formula" href="#disp-formula-7">
                                 Equation 5
                                </a>
                                ),
                                <strong>
                                 W
                                </strong>
                                is a weight matrix were each column
                                <strong>
                                 w
                                </strong>
                                <sub>
                                 v
                                </sub>
                                represents the linear measurement model for a different voxel a
                                <sub>
                                 v
                                </sub>
                                , and E is a random normal row vector with mean
                                <strong>
                                 0
                                </strong>
                                and covariance matrix with σ in the diagonal and zeros elsewhere. The value of σ was varied in Simulation 1 and was fixed to 5 in Simulation 2 (see below).
                               </p>
                               <p id="p-124">
                                <a id="xref-disp-formula-8-1" class="xref-disp-formula" href="#disp-formula-8">
                                 Equation 6
                                </a>
                                indicates that the activity in each voxel is a linear combination of neural channel responses, plus some random measurement noise. As shown in
                                <a id="xref-fig-17-1" class="xref-fig" href="#F17">
                                 Figure 17
                                </a>
                                , the model for each voxel was composed of a finite number of encoding channels that independently contributed to the aggregate signal of the voxel according to a set of weights. The values of the weights were randomly and uniformly sampled from 0 to 1, and then normalized by column, so that weights in
                                <strong>
                                 w
                                </strong>
                                <sub>
                                 v
                                </sub>
                                would add up to one. This way, the weights can be interpreted as the relative contribution of each channel to a voxel’s activity.
                               </p>
                               <div id="F17" class="fig pos-float type-figure odd">
                                <div class="highwire-figure">
                                 <div class="fig-inline-img-wrapper">
                                  <div class="fig-inline-img">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F17.large.jpg?width=800&height=600&carousel=1" title="Linear measurement model. The measurement model provides a link between neural encoding channels and voxel-wise activity measures. Activity in each voxel (represented by cubes) is a linear combination of neural channel responses (r = [r1, r2, r3, … rK]), plus independent random measurement noise (represented by the dice next to each cube)" class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup"><div xmlns="http://www.w3.org/1999/xhtml">Linear measurement model. The measurement model provides a link between neural encoding channels and voxel-wise activity measures. Activity in each voxel (represented by cubes) is a linear combination of neural channel responses (<strong>r</strong> = [<em>r</em><sub>1</sub><em>, r</em><sub>2</sub><em>, r</em><sub>3</sub><em>, … r<sub>K</sub></em>]), plus independent random measurement noise (represented by the dice next to each cube)</div></div>' data-icon-position="" data-hide-link-title="0">
                                    <span class="hw-responsive-img">
                                     <img class="highwire-fragment fragment-image lazyload" alt="Figure 17:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F17.medium.gif" width="405" height="440"/>
                                     <noscript>
                                      <img class="highwire-fragment fragment-image" alt="Figure 17:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F17.medium.gif" width="405" height="440"/>
                                     </noscript>
                                    </span>
                                   </a>
                                  </div>
                                 </div>
                                 <ul class="highwire-figure-links inline">
                                  <li class="download-fig first">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F17.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 17:" data-icon-position="" data-hide-link-title="0">
                                    Download figure
                                   </a>
                                  </li>
                                  <li class="new-tab last">
                                   <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F17.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                    Open in new tab
                                   </a>
                                  </li>
                                 </ul>
                                </div>
                                <div class="fig-caption">
                                 <span class="fig-label">
                                  Figure 17:
                                 </span>
                                 <p id="p-125" class="first-child">
                                  Linear measurement model. The measurement model provides a link between neural encoding channels and voxel-wise activity measures. Activity in each voxel (represented by cubes) is a linear combination of neural channel responses (
                                  <strong>
                                   r
                                  </strong>
                                  = [r
                                  <sub>
                                   1
                                  </sub>
                                  , r
                                  <sub>
                                   2
                                  </sub>
                                  , r
                                  <sub>
                                   3
                                  </sub>
                                  , … r
                                  <sub>
                                   K
                                  </sub>
                                  ]), plus independent random measurement noise (represented by the dice next to each cube)
                                 </p>
                                 <div class="sb-div caption-clear">
                                 </div>
                                </div>
                               </div>
                               <p id="p-126">
                                We simulated a total of 100 voxels. In each simulated trial, the encoding model was presented with a given stimulus and produced a random vector of neural responses
                                <strong>
                                 r
                                </strong>
                                as explained in the previous section, which were then used as input to the measurement model to obtain a random vector of voxel activities
                                <strong>
                                 a
                                </strong>
                                .
                               </p>
                              </div>
                             </div>
                             <div id="sec-30" class="subsection">
                              <h4>
                               Simulation 1: False Positive Invariance Resulting From Features Of The Measurement Model
                              </h4>
                              <p id="p-127">
                               In theory, even a completely context-specific code could produce false conclusions of invariance in neuroimaging decoding studies, due to the transformation and mixing of neural responses from different populations that occurs at each voxel (see
                               <a id="xref-fig-3-9" class="xref-fig" href="#F3">
                                Figure 3
                               </a>
                               ). To provide evidence for such a general claim, we study a case of complete context-specificity in which it cannot be claimed that any amount of tolerance exists in the neural representations. The goal of the first simulation was to show that the cross-classification test can lead to a conclusion of invariance when neural representations do not satisfy any sensible definition of invariance or tolerance. As shown in
                               <a id="xref-fig-18-5" class="xref-fig" href="#F18">
                                Figure 18
                               </a>
                               , the model underlying the simulation was created so that the encoding of the target dimension (e.g., orientation) was completely different across levels of the context dimension (e.g., spatial position). That is, two separate encoding models were created to represents the levels of the context dimension. The first level model consisted of a homogeneous population encoding model. To make sure that there was no invariance across levels of the context dimension, the encoding model for the second level of the context dimension was composed of channels whose tuning parameters were completely randomized. For each channel, the position parameter s
                               <sub>
                                c
                               </sub>
                               was randomly sampled from a uniform distribution covering all values in the dimension, r
                               <sup>
                                max
                               </sup>
                               was similarly sampled from values between 5 and 20, and ω
                               <sub>
                                c
                               </sub>
                               from values between 5 and 25. The result was a completely randomized encoding model for the second level of the context dimension, which was extremely unlikely to share any properties with the encoding model for the first level of the context dimension (compare the top and bottom encoding models in
                               <a id="xref-fig-19-2" class="xref-fig" href="#F19">
                                Figure 19
                               </a>
                               ).
                              </p>
                              <div id="F18" class="fig pos-float type-figure odd">
                               <div class="highwire-figure">
                                <div class="fig-inline-img-wrapper">
                                 <div class="fig-inline-img">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F18.large.jpg?width=800&height=600&carousel=1" title="Encoding models for simulation 1. Two separate encoding models were created to represent two levels of the context dimension. The first level model (top row) consisted of homogeneously tuned encoding channels. The measurement weights for this level were selected randomly. The second level model (bottom row) consisted of randomly tuned encoding channels, ensuring a complete lack of invariance between the first and second level models. The measurement weights for this level were then chosen via lasso regression to produce similar activity patterns to that of the first level model." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Encoding models for simulation 1. Two separate encoding models were created to represent two levels of the context dimension. The first level model (top row) consisted of homogeneously tuned encoding channels. The measurement weights for this level were selected randomly. The second level model (bottom row) consisted of randomly tuned encoding channels, ensuring a complete lack of invariance between the first and second level models. The measurement weights for this level were then chosen via lasso regression to produce similar activity patterns to that of the first level model.</div>' data-icon-position="" data-hide-link-title="0">
                                   <span class="hw-responsive-img">
                                    <img class="highwire-fragment fragment-image lazyload" alt="Figure 18:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F18.medium.gif" width="440" height="290"/>
                                    <noscript>
                                     <img class="highwire-fragment fragment-image" alt="Figure 18:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F18.medium.gif" width="440" height="290"/>
                                    </noscript>
                                   </span>
                                  </a>
                                 </div>
                                </div>
                                <ul class="highwire-figure-links inline">
                                 <li class="download-fig first">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F18.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 18:" data-icon-position="" data-hide-link-title="0">
                                   Download figure
                                  </a>
                                 </li>
                                 <li class="new-tab last">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F18.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                   Open in new tab
                                  </a>
                                 </li>
                                </ul>
                               </div>
                               <div class="fig-caption">
                                <span class="fig-label">
                                 Figure 18:
                                </span>
                                <p id="p-128" class="first-child">
                                 Encoding models for simulation 1. Two separate encoding models were created to represent two levels of the context dimension. The first level model (top row) consisted of homogeneously tuned encoding channels. The measurement weights for this level were selected randomly. The second level model (bottom row) consisted of randomly tuned encoding channels, ensuring a complete lack of invariance between the first and second level models. The measurement weights for this level were then chosen via lasso regression to produce similar activity patterns to that of the first level model.
                                </p>
                                <div class="sb-div caption-clear">
                                </div>
                               </div>
                              </div>
                              <p id="p-129">
                               As shown in the middle part of
                               <a id="xref-fig-18-6" class="xref-fig" href="#F18">
                                Figure 18
                               </a>
                               , the measurement weights of the first level model,
                               <strong>
                                W
                               </strong>
                               <sub>
                                1
                               </sub>
                               , were randomly sampled to generate activity patterns in each voxel (as explained above). On the other hand, the measurement weights for the second level model,
                               <strong>
                                W
                               </strong>
                               <sub>
                                2
                               </sub>
                               , were chosen so that the activity patterns generated by any stimulus presented to this second level model would be as similar as possible as those presented to the first level model. To do this, we presented the level 1 model with the preferred stimulus of each channel s
                               <sub>
                                c
                               </sub>
                               20 times, and each time sampled data from 100 voxels. We then presented the level 2 model with the same stimuli a single time, and recorded a vector of average responses from the encoding model using
                               <a id="xref-disp-formula-6-2" class="xref-disp-formula" href="#disp-formula-6">
                                Equation 4
                               </a>
                               (i.e., neural channel responses without any noise). Finally, for each voxel, the vectors of weights in
                               <strong>
                                W
                               </strong>
                               <sub>
                                2
                               </sub>
                               were obtained via Lasso regression, where voxel-wise activity patterns produced by the first level model were used as outputs to be predicted from the average neural activities obtained from the second level encoding model. Using Lasso regression, as implemented in sklearn, allowed us to constrain the weights to be positive. The regularization parameter of the regression model was not optimized, but fixed to a value of 0.01.
                              </p>
                              <p id="p-130">
                               This procedure should result in a model in which no sensible definition of invariance or tolerance holds at the level of neural responses, but that nonetheless should show some level of tolerance at the level of indirect voxel activity measures. As shown in
                               <a id="xref-fig-19-3" class="xref-fig" href="#F19">
                                Figure 19
                               </a>
                               , each simulation started by creating such a model (step 1), and continued by sampling data from it (step 2). To get that data, we presented the model with four stimuli, with values of -45°, 0°, 45°, and 90°, and sampled voxel activity patterns from it. Each stimulus presentation was repeated 20 times. We sampled data this way both from the first and second level models constructed as indicated above. Data was sampled twice from the first level model, to obtain training and testing data sets, and only once from the second level model, to obtain a testing data set only. We then performed a cross-classification test on the resulting data (steps 3 and 4 in
                               <a id="xref-fig-19-4" class="xref-fig" href="#F19">
                                Figure 19
                               </a>
                               ), following the same procedures as with the experimental data explained above, with the exception that the Nu parameter of the SVM was fixed to the default value of 0.5. Each simulation was repeated 200 times. The results presented represent average statistics across all simulations, obtained from the testing data sets.
                              </p>
                              <div id="F19" class="fig pos-float type-figure odd">
                               <div class="highwire-figure">
                                <div class="fig-inline-img-wrapper">
                                 <div class="fig-inline-img">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F19.large.jpg?width=800&height=600&carousel=1" title="Steps taken in each repetition of simulation 1. Data was sampled from both the first and second level models. A linear SVM classifier was fit to training data from the level 1 model. Then, the fitted model was tested with independent testing data from both the first and second level models." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Steps taken in each repetition of simulation 1. Data was sampled from both the first and second level models. A linear SVM classifier was fit to training data from the level 1 model. Then, the fitted model was tested with independent testing data from both the first and second level models.</div>' data-icon-position="" data-hide-link-title="0">
                                   <span class="hw-responsive-img">
                                    <img class="highwire-fragment fragment-image lazyload" alt="Figure 19:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F19.medium.gif" width="440" height="120"/>
                                    <noscript>
                                     <img class="highwire-fragment fragment-image" alt="Figure 19:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F19.medium.gif" width="440" height="120"/>
                                    </noscript>
                                   </span>
                                  </a>
                                 </div>
                                </div>
                                <ul class="highwire-figure-links inline">
                                 <li class="download-fig first">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F19.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 19:" data-icon-position="" data-hide-link-title="0">
                                   Download figure
                                  </a>
                                 </li>
                                 <li class="new-tab last">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F19.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                   Open in new tab
                                  </a>
                                 </li>
                                </ul>
                               </div>
                               <div class="fig-caption">
                                <span class="fig-label">
                                 Figure 19:
                                </span>
                                <p id="p-131" class="first-child">
                                 Steps taken in each repetition of simulation 1. Data was sampled from both the first and second level models. A linear SVM classifier was fit to training data from the level 1 model. Then, the fitted model was tested with independent testing data from both the first and second level models.
                                </p>
                                <div class="sb-div caption-clear">
                                </div>
                               </div>
                              </div>
                              <p id="p-132">
                               Finally, we repeated the group of simulations a total of 20 times, each time with a different value for the level of voxel measurement noise σ, going from 1 to 20.
                              </p>
                             </div>
                             <div id="sec-31" class="subsection">
                              <h4>
                               Simulation 2: False Positive Invariance Resulting From Similarly Tuned Neural Subpopulations Across Contexts
                              </h4>
                              <p id="p-133">
                               Only a small proportion of all possible measurement models might be truly at play in neuroimaging studies, and those could be contained within the space of models for which false positive invariance is not an issue. Thus, we would like to strengthen our conclusions by studying a realistic encoding scenario, likely to be implemented in the brain.
                              </p>
                              <p id="p-134">
                               There are many known cases in which neurons that are sensitive to a particular stimulus feature are spatially clustered at sub-millimeter scales. In those cases, while there is spatially distributed information about stimulus features, this information is not immediately visible at the typical resolution of an fMRI study. In cases such as these, across voxels we would expect to find relatively homogeneous distributions of selectivities. Our ability to use voxel-level decoding to detect whether and how features are encoded depends critically on small random variations in mixing; that is, in the proportion of each type of neuron present within each voxel. This sub-voxel distribution of information, which may underlie the success of many fMRI decoding studies, can also easily lead to false-positive invariance when the cross-classification test (or other tests of the null of specificity) is used in isolation. Small differences in mixing might be enough to promote above-chance decoding of a stimulus feature, because decoding algorithms are specifically trained to detect differences in the target feature. On the other hand, decoding algorithms are not trained to detect changes in context. Any small differences in mixing that might provide information about context-specificity would be lost, and the decoding algorithm would be very likely to generalize performance across changes in stimulus context.
                              </p>
                              <p id="p-135">
                               In the present simulation, we wanted to study the sensitivity of different fMRI decoding tests to changes in mixing indicative of context-sensitivity. With this goal in mind, we created a model in which a target dimension is encoded in a completely context-specific manner, with one subpopulation of neurons responding whenever the context dimension is at level 1, and a different subpopulation of neurons responding whenever the context dimension is at level 2. However, both subpopulations encoded the target dimension in a similar way. To do this, the measurement model of each voxel was obtained as shown in
                               <a id="xref-fig-20-11" class="xref-fig" href="#F20">
                                Figure 20
                               </a>
                               . The weights
                               <strong>
                                w
                               </strong>
                               <sub>
                                v
                               </sub>
                               for level 1 of the context dimension were randomly generated, as explained above (step 1 in
                               <a id="xref-fig-20-12" class="xref-fig" href="#F20">
                                Figure 20
                               </a>
                               ). To create the measurement model for level 2 of the context dimension, we first obtained a vector
                               <strong>
                                e
                               </strong>
                               of random values sampled from a normal distribution with mean zero and standard deviation equal to σ
                               <strong>
                                <sub>
                                 e
                                </sub>
                               </strong>
                               . This random vector was added to
                               <strong>
                                w
                               </strong>
                               <sub>
                                v
                               </sub>
                               (step 2), and then the values were made positive through rectification and normalized to add up to one (step 3), producing the final set of weights for level 2 of the context dimension. Once the model was generated, the simulation was carried out following the same other steps as in Simulation 1, numbered 2 to 4 in
                               <a id="xref-fig-19-5" class="xref-fig" href="#F19">
                                Figure 19
                               </a>
                               . The only difference was that σ = 5 in the measurement model, whereas the value of σ
                               <strong>
                                <sub>
                                 e
                                </sub>
                               </strong>
                               was varied from 0 to 0.5. Note that this implies that, at the highest values of σ
                               <strong>
                                <sub>
                                 e
                                </sub>
                               </strong>
                               , the standard deviation of the changes in weights in the measurement model was 500% the average value of those weights (0.1). This ensured that in the final models the contribution of each neuron type (e.g., neurons selective to a value of 0 in the target dimension) was widely different across levels of the context dimension.
                              </p>
                              <div id="F20" class="fig pos-float type-figure odd">
                               <div class="highwire-figure">
                                <div class="fig-inline-img-wrapper">
                                 <div class="fig-inline-img">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F20.large.jpg?width=800&height=600&carousel=1" title="Encoding model for simulation 2. The encoding model for the first level was generated in the same manner as in simulation 1 (see Figure 18). For the second level model, the channels weights within each voxel were perturbed by a vector of random values sampled from a normal distribution, and were then rectified and normalized to make sure that they were positive and added up to one for each voxel." class="highwire-fragment fragment-images colorbox-load" rel="gallery-fragment-images-102507825" data-figure-caption='<div class="highwire-markup">Encoding model for simulation 2. The encoding model for the first level was generated in the same manner as in simulation 1 (see Figure 18). For the second level model, the channels weights within each voxel were perturbed by a vector of random values sampled from a normal distribution, and were then rectified and normalized to make sure that they were positive and added up to one for each voxel.</div>' data-icon-position="" data-hide-link-title="0">
                                   <span class="hw-responsive-img">
                                    <img class="highwire-fragment fragment-image lazyload" alt="Figure 20:" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F20.medium.gif" width="440" height="98"/>
                                    <noscript>
                                     <img class="highwire-fragment fragment-image" alt="Figure 20:" src="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F20.medium.gif" width="440" height="98"/>
                                    </noscript>
                                   </span>
                                  </a>
                                 </div>
                                </div>
                                <ul class="highwire-figure-links inline">
                                 <li class="download-fig first">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F20.large.jpg?download=true" class="highwire-figure-link highwire-figure-link-download" title="Download Figure 20:" data-icon-position="" data-hide-link-title="0">
                                   Download figure
                                  </a>
                                 </li>
                                 <li class="new-tab last">
                                  <a href="https://www.biorxiv.org/content/biorxiv/early/2022/04/15/2020.02.27.967505/F20.large.jpg" class="highwire-figure-link highwire-figure-link-newtab" target="_blank" data-icon-position="" data-hide-link-title="0">
                                   Open in new tab
                                  </a>
                                 </li>
                                </ul>
                               </div>
                               <div class="fig-caption">
                                <span class="fig-label">
                                 Figure 20:
                                </span>
                                <p id="p-136" class="first-child">
                                 Encoding model for simulation 2. The encoding model for the first level was generated in the same manner as in simulation 1 (see
                                 <a id="xref-fig-18-7" class="xref-fig" href="#F18">
                                  Figure 18
                                 </a>
                                 ). For the second level model, the channels weights within each voxel were perturbed by a vector of random values sampled from a normal distribution, and were then rectified and normalized to make sure that they were positive and added up to one for each voxel.
                                </p>
                                <div class="sb-div caption-clear">
                                </div>
                               </div>
                              </div>
                             </div>
                            </div>
                           </div>
                           <div class="section ack" id="ack-1">
                            <h2 class="">
                             Acknowledgements
                            </h2>
                            <p id="p-137">
                             This work was supported in part by the National Science Foundation under grant No. 2020982 to Fabian A. Soto. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation. We thank Jason Hays for developing and teaching us how to use the Python package used for our simulations (PEMGUIN). S.D.G.
                            </p>
                           </div>
                           <div class="section ref-list" id="ref-list-1">
                            <h2 class="">
                             References
                            </h2>
                            <ol class="cit-list ref-use-labels">
                             <li>
                              <span class="ref-label">
                               [1].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-1-1" title="View reference [1] in text" id="ref-1">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.1" data-doi="10.1016/j.neuroimage.2013.11.043">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Allefeld
                                  </span>
                                  <span class="cit-name-given-names">
                                   C
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Haynes
                                  </span>
                                  <span class="cit-name-given-names">
                                   JD
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Searchlight-based multi-voxel pattern analysis of fMRI by cross-validated MANOVA
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  NeuroImage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2014
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  89
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  345
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  357
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.neuroimage.2013.11.043
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroImage%26rft.volume%253D89%26rft.spage%253D345%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2013.11.043%26rft_id%253Dinfo%253Apmid%252F24296330%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2013.11.043&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=24296330&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000332057400032&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [2].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-2-1" title="View reference [2] in text" id="ref-2">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.2" data-doi="10.3389/fpsyg.2014.00672">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Anzellotti
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Caramazza
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The neural mechanisms for the recognition of face identity in humans
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Psychology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2014
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  5
                                 </span>
                                 :
                                 <span class="cit-issue">
                                  672
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.3389/fpsyg.2014.00672
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DFrontiers%2Bin%2BPsychology%26rft_id%253Dinfo%253Adoi%252F10.3389%252Ffpsyg.2014.00672%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.3389/fpsyg.2014.00672&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [3].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-3-1" title="View reference [3] in text" id="ref-3">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.3" data-doi="10.3389/fnhum.2015.00151">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kaplan
                                  </span>
                                  <span class="cit-name-given-names">
                                   JT
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Man
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Greening
                                  </span>
                                  <span class="cit-name-given-names">
                                   SG
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Multivariate cross-classification: Applying machine learning techniques to characterize abstraction in neural representations
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Human Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2015
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  9
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  151
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.3389/fnhum.2015.00151
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DFrontiers%2Bin%2BHuman%2BNeuroscience%26rft.volume%253D9%26rft.spage%253D151%26rft_id%253Dinfo%253Adoi%252F10.3389%252Ffnhum.2015.00151%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.3389/fnhum.2015.00151&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [4].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-4-1" title="View reference [4] in text" id="ref-4">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.4">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Soto
                                  </span>
                                  <span class="cit-name-given-names">
                                   FA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Vucovich
                                  </span>
                                  <span class="cit-name-given-names">
                                   LE
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ashby
                                  </span>
                                  <span class="cit-name-given-names">
                                   FG
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Linking signal detection theory and encoding models to reveal independent neural representations from neuroimaging data
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  PLoS Computational Biology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2018
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  14
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  10
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  e1006470
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DPLoS%2BComputational%2BBiology%26rft.volume%253D14%26rft.spage%253D1006470e%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [5].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-5-1" title="View reference [5] in text" id="ref-5">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.5" data-doi="10.1093/cercor/bht046">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Anzellotti
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Fairhall
                                  </span>
                                  <span class="cit-name-given-names">
                                   SL
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Caramazza
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Decoding representations of face identity that are tolerant to rotation
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Cerebral Cortex
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2014
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  24
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  8
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1988
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1995
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1093/cercor/bht046
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCerebral%2BCortex%26rft_id%253Dinfo%253Adoi%252F10.1093%252Fcercor%252Fbht046%26rft_id%253Dinfo%253Apmid%252F23463339%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1093/cercor/bht046&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23463339&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000340068500003&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [6].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-6-1" title="View reference [6] in text" id="ref-6">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.6" data-doi="10.1523/JNEUROSCI.3156-13.2014">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ramirez
                                  </span>
                                  <span class="cit-name-given-names">
                                   FM
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Cichy
                                  </span>
                                  <span class="cit-name-given-names">
                                   RM
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Allefeld
                                  </span>
                                  <span class="cit-name-given-names">
                                   C
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Haynes
                                  </span>
                                  <span class="cit-name-given-names">
                                   JD
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The neural code for face orientation in the human fusiform face area
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  The Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2014
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  34
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  36
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  12155
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  12167
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/JNEUROSCI.3156-13.2014
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DRamirez%26rft.auinit1%253DF.%2BM.%26rft.volume%253D34%26rft.issue%253D36%26rft.spage%253D12155%26rft.epage%253D12167%26rft.atitle%253DThe%2BNeural%2BCode%2Bfor%2BFace%2BOrientation%2Bin%2Bthe%2BHuman%2BFusiform%2BFace%2BArea%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.3156-13.2014%26rft_id%253Dinfo%253Apmid%252F25186759%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjExOiIzNC8zNi8xMjE1NSI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [7].
                              </span>
                              <div class="cit ref-cit ref-journal no-rev-xref" id="cit-2020.02.27.967505v2.7" data-doi="10.1152/jn.01074.2015">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kaiser
                                  </span>
                                  <span class="cit-name-given-names">
                                   D
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Azzalini
                                  </span>
                                  <span class="cit-name-given-names">
                                   DC
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Peelen
                                  </span>
                                  <span class="cit-name-given-names">
                                   MV
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Shape-independent object category responses revealed by MEG and fMRI decoding
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neurophysiology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2016
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  115
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  4
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  2246
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  2250
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1152/jn.01074.2015
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeurophysiology%26rft_id%253Dinfo%253Adoi%252F10.1152%252Fjn.01074.2015%26rft_id%253Dinfo%253Apmid%252F26740535%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1152/jn.01074.2015&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=26740535&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [8].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-8-1" title="View reference [8] in text" id="ref-8">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.8" data-doi="10.1371/journal.pone.0003690">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Etzel
                                  </span>
                                  <span class="cit-name-given-names">
                                   JA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gazzola
                                  </span>
                                  <span class="cit-name-given-names">
                                   V
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Keysers
                                  </span>
                                  <span class="cit-name-given-names">
                                   C
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Testing simulation theory with cross-modal multivariate classification of fMRI data
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  PLOS ONE
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  3
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  11
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  e3690
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1371/journal.pone.0003690
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.stitle%253DPLoS%2BONE%26rft.aulast%253DEtzel%26rft.auinit1%253DJ.%2BA.%26rft.volume%253D3%26rft.issue%253D11%26rft.spage%253De3690%26rft.epage%253De3690%26rft.atitle%253DTesting%2Bsimulation%2Btheory%2Bwith%2Bcross-modal%2Bmultivariate%2Bclassification%2Bof%2BfMRI%2Bdata.%26rft_id%253Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0003690%26rft_id%253Dinfo%253Apmid%252F18997869%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1371/journal.pone.0003690&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=18997869&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [9].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-9-1" title="View reference [9] in text" id="ref-9">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.9" data-doi="10.1523/ENEURO.0252-17.2018">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Archila-Melendez
                                  </span>
                                  <span class="cit-name-given-names">
                                   ME
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Valente
                                  </span>
                                  <span class="cit-name-given-names">
                                   G
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Correia
                                  </span>
                                  <span class="cit-name-given-names">
                                   JM
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Rouhl
                                  </span>
                                  <span class="cit-name-given-names">
                                   RPW
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kranen-Mastenbroek
                                  </span>
                                  <span class="cit-name-given-names">
                                   V
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Jansma
                                  </span>
                                  <span class="cit-name-given-names">
                                   BM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Sensorimotor representation of speech perception: Cross-decoding of place of articulation features during selective attention to syllables in 7T fMRI
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  eNeuro
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2018
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  5
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  e0252
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  17.2018
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/ENEURO.0252-17.2018
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DeNeuro%26rft_id%253Dinfo%253Adoi%252F10.1523%252FENEURO.0252-17.2018%26rft_id%253Dinfo%253Apmid%252F29610768%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NjoiZW5ldXJvIjtzOjU6InJlc2lkIjtzOjIzOiI1LzIvRU5FVVJPLjAyNTItMTcuMjAxOCI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [10].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-10-1" title="View reference [10] in text" id="ref-10">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.10" data-doi="10.1523/JNEUROSCI.2342-12.2012">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Man
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kaplan
                                  </span>
                                  <span class="cit-name-given-names">
                                   JT
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Damasio
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Meyer
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Sight and sound converge to form modality-invariant representations in temporoparietal cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  32
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  47
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  16629
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  16636
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/JNEUROSCI.2342-12.2012
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DMan%26rft.auinit1%253DK.%26rft.volume%253D32%26rft.issue%253D47%26rft.spage%253D16629%26rft.epage%253D16636%26rft.atitle%253DSight%2Band%2BSound%2BConverge%2Bto%2BForm%2BModality-Invariant%2BRepresentations%2Bin%2BTemporoparietal%2BCortex%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.2342-12.2012%26rft_id%253Dinfo%253Apmid%252F23175818%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjExOiIzMi80Ny8xNjYyOSI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [11].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-11-1" title="View reference [11] in text" id="ref-11">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.11" data-doi="10.1016/j.cortex.2017.01.013">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Anzellotti
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Caramazza
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Multimodal representations of person identity individuated with fMRI
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Cortex
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2017
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  89
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  85
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  97
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCortex%26rft.volume%253D89%26rft.spage%253D85%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.cortex.2017.01.013%26rft_id%253Dinfo%253Apmid%252F28242496%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.cortex.2017.01.013&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=28242496&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [12].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-12-1" title="View reference [12] in text" id="ref-12">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.12" data-doi="10.3389/fninf.2012.00024">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Akama
                                  </span>
                                  <span class="cit-name-given-names">
                                   H
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Murphy
                                  </span>
                                  <span class="cit-name-given-names">
                                   B
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Na
                                  </span>
                                  <span class="cit-name-given-names">
                                   L
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Shimizu
                                  </span>
                                  <span class="cit-name-given-names">
                                   Y
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Poesio
                                  </span>
                                  <span class="cit-name-given-names">
                                   M
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Decoding semantics across fMRI sessions with different stimulus modalities: a practical MVPA study
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Neuroinformatics
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  6
                                 </span>
                                 :
                                 <span class="cit-issue">
                                  24
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.3389/fninf.2012.00024
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DFrontiers%2Bin%2BNeuroinformatics%26rft.volume%253D6%26rft.spage%253D24%26rft_id%253Dinfo%253Adoi%252F10.3389%252Ffninf.2012.00024%26rft_id%253Dinfo%253Apmid%252F22936912%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.3389/fninf.2012.00024&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=22936912&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [13].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-13-1" title="View reference [13] in text" id="ref-13">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.13" data-doi="10.1016/j.neuroimage.2013.01.008">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Soto
                                  </span>
                                  <span class="cit-name-given-names">
                                   FA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Waldschmidt
                                  </span>
                                  <span class="cit-name-given-names">
                                   JG
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Helie
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ashby
                                  </span>
                                  <span class="cit-name-given-names">
                                   FG
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Brain activity across the development of automatic categorization: A comparison of categorization tasks using multi-voxel pattern analysis
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2013
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  71
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  284
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  897
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.neuroimage.2013.01.008
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroimage%26rft.volume%253D71%26rft.spage%253D284%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2013.01.008%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2013.01.008&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [14].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-14-1" title="View reference [14] in text" id="ref-14">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.14" data-doi="10.1016/j.bandl.2011.09.003">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Buchweitz
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Shinkareva
                                  </span>
                                  <span class="cit-name-given-names">
                                   SV
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Mason
                                  </span>
                                  <span class="cit-name-given-names">
                                   RA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Mitchell
                                  </span>
                                  <span class="cit-name-given-names">
                                   TM
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Just
                                  </span>
                                  <span class="cit-name-given-names">
                                   MA
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Identifying bilingual semantic neural representations across languages
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Brain and Language
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  120
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  3
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  282
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  289
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.bandl.2011.09.003
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DBrain%2Band%2Blanguage%26rft.stitle%253DBrain%2BLang%26rft.aulast%253DBuchweitz%26rft.auinit1%253DA.%26rft.volume%253D120%26rft.issue%253D3%26rft.spage%253D282%26rft.epage%253D289%26rft.atitle%253DIdentifying%2Bbilingual%2Bsemantic%2Bneural%2Brepresentations%2Bacross%2Blanguages.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.bandl.2011.09.003%26rft_id%253Dinfo%253Apmid%252F21978845%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.bandl.2011.09.003&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=21978845&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000301759100009&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [15].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-15-1" title="View reference [15] in text" id="ref-15">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.15" data-doi="10.7554/eLife.21397">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Guest
                                  </span>
                                  <span class="cit-name-given-names">
                                   O
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Love
                                  </span>
                                  <span class="cit-name-given-names">
                                   BC
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  What the success of brain imaging implies about the neural code
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Elife
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2017
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  6
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  e21397
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DElife%26rft.volume%253D6%26rft.spage%253De21397%26rft_id%253Dinfo%253Adoi%252F10.7554%252FeLife.21397%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.7554/eLife.21397&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [16].
                              </span>
                              <div class="cit ref-cit ref-journal no-rev-xref" id="cit-2020.02.27.967505v2.16" data-doi="10.1152/jn.90211.2008">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Issa
                                  </span>
                                  <span class="cit-name-given-names">
                                   NP
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Rosenberg
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Husson
                                  </span>
                                  <span class="cit-name-given-names">
                                   TR
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Models and measurements of functional maps in V1
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neurophysiology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  99
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  6
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  2745
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  2754
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeurophysiology%26rft_id%253Dinfo%253Adoi%252F10.1152%252Fjn.90211.2008%26rft_id%253Dinfo%253Apmid%252F18400962%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1152/jn.90211.2008&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=18400962&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000256632600002&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [17].
                              </span>
                              <div class="cit ref-cit ref-journal no-rev-xref" id="cit-2020.02.27.967505v2.17">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ng
                                  </span>
                                  <span class="cit-name-given-names">
                                   J
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Bharath
                                  </span>
                                  <span class="cit-name-given-names">
                                   AA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Zhaoping
                                  </span>
                                  <span class="cit-name-given-names">
                                   L
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  A survey of architecture and function of the primary visual cortex (V1)
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  EURASIP J Appl Signal Process
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2007
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  2007
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  124
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  124
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DEURASIP%2BJ%2BAppl%2BSignal%2BProcess%26rft.volume%253D2007%26rft.spage%253D124%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [18].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-18-1" title="View reference [18] in text" id="ref-18">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.18" data-doi="10.3389/fpsyg.2013.00493">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Alink
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Krugliak
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Walther
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kriegeskorte
                                  </span>
                                  <span class="cit-name-given-names">
                                   N
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  fMRI orientation decoding in V1 does not require global maps or globally coherent orientation stimuli
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Psychology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2013
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  4
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  493
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.3389/fpsyg.2013.00493
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DFrontiers%2Bin%2BPsychology%26rft.volume%253D4%26rft.spage%253D493%26rft_id%253Dinfo%253Adoi%252F10.3389%252Ffpsyg.2013.00493%26rft_id%253Dinfo%253Apmid%252F23964251%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.3389/fpsyg.2013.00493&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23964251&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [19].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-19-1" title="View reference [19] in text" id="ref-19">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.19" data-doi="10.1016/j.neuroimage.2015.11.066">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Pratte
                                  </span>
                                  <span class="cit-name-given-names">
                                   MS
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Sy
                                  </span>
                                  <span class="cit-name-given-names">
                                   JL
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Swisher
                                  </span>
                                  <span class="cit-name-given-names">
                                   JD
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Tong
                                  </span>
                                  <span class="cit-name-given-names">
                                   F
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Radial bias is not necessary for orientation decoding
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  NeuroImage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2016
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  127
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  23
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  33
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.neuroimage.2015.11.066
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroImage%26rft.volume%253D127%26rft.spage%253D23%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2015.11.066%26rft_id%253Dinfo%253Apmid%252F26666900%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2015.11.066&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=26666900&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [20].
                              </span>
                              <div class="cit ref-cit ref-journal no-rev-xref" id="cit-2020.02.27.967505v2.20" data-doi="10.1152/jn.00196.2014">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Maloney
                                  </span>
                                  <span class="cit-name-given-names">
                                   RT
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The basis of orientation decoding in human primary visual cortex: fine- or coarse-scale biases?
                                 </span>
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neurophysiology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2014
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  113
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  3
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1152/jn.00196.2014
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeurophysiology%26rft_id%253Dinfo%253Adoi%252F10.1152%252Fjn.00196.2014%26rft_id%253Dinfo%253Apmid%252F24872532%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1152/jn.00196.2014&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=24872532&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [21].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-21-1" title="View reference [21] in text" id="ref-21">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.21" data-doi="10.1093/cercor/bhi003">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gur
                                  </span>
                                  <span class="cit-name-given-names">
                                   M
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kagan
                                  </span>
                                  <span class="cit-name-given-names">
                                   I
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Snodderly
                                  </span>
                                  <span class="cit-name-given-names">
                                   DM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Orientation and direction selectivity of neurons in V1 of alert monkeys: functional relationships and laminar distributions
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Cerebral Cortex
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  15
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  8
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1207
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1221
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCerebral%2BCortex%26rft_id%253Dinfo%253Adoi%252F10.1093%252Fcercor%252Fbhi003%26rft_id%253Dinfo%253Apmid%252F15616136%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1093/cercor/bhi003&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=15616136&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000230513400013&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [22].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-22-1" title="View reference [22] in text" id="ref-22">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.22" data-doi="10.1523/JNEUROSCI.3577-09.2009">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Brouwer
                                  </span>
                                  <span class="cit-name-given-names">
                                   GJ
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Heeger
                                  </span>
                                  <span class="cit-name-given-names">
                                   DJ
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Decoding and reconstructing color from responses in human visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2009
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  29
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  44
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  13992
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  14003
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/JNEUROSCI.3577-09.2009
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DBrouwer%26rft.auinit1%253DG.%2BJ.%26rft.volume%253D29%26rft.issue%253D44%26rft.spage%253D13992%26rft.epage%253D14003%26rft.atitle%253DDecoding%2Band%2BReconstructing%2BColor%2Bfrom%2BResponses%2Bin%2BHuman%2BVisual%2BCortex%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.3577-09.2009%26rft_id%253Dinfo%253Apmid%252F19890009%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjExOiIyOS80NC8xMzk5MiI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [23].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-23-1" title="View reference [23] in text" id="ref-23">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.23" data-doi="10.1523/JNEUROSCI.2700-19.2019">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ester
                                  </span>
                                  <span class="cit-name-given-names">
                                   EF
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Sprague
                                  </span>
                                  <span class="cit-name-given-names">
                                   TC
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Serences
                                  </span>
                                  <span class="cit-name-given-names">
                                   JT
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Categorical biases in human occipitoparietal cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2020
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  40
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  4
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  917
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  931
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.2700-19.2019%26rft_id%253Dinfo%253Apmid%252F31862856%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjg6IjQwLzQvOTE3IjtzOjQ6ImF0b20iO3M6NDg6Ii9iaW9yeGl2L2Vhcmx5LzIwMjIvMDQvMTUvMjAyMC4wMi4yNy45Njc1MDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [24].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-24-1" title="View reference [24] in text" id="ref-24">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.24" data-doi="10.1016/j.cub.2013.02.013">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Garcia
                                  </span>
                                  <span class="cit-name-given-names">
                                   JO
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Srinivasan
                                  </span>
                                  <span class="cit-name-given-names">
                                   R
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Serences
                                  </span>
                                  <span class="cit-name-given-names">
                                   JT
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Near-real-time feature-selective modulations in human cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Current Biology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2013
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  23
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  6
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  515
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  522
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.cub.2013.02.013
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCurrent%2Bbiology%2B%253A%2B%2BCB%26rft.stitle%253DCurr%2BBiol%26rft.aulast%253DGarcia%26rft.auinit1%253DJ.%2BO.%26rft.volume%253D23%26rft.spage%253D515%26rft.atitle%253DNear-Real-Time%2BFeature-Selective%2BModulations%2Bin%2BHuman%2BCortex.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.cub.2013.02.013%26rft_id%253Dinfo%253Apmid%252F23477721%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.cub.2013.02.013&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23477721&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [25].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-25-1" title="View reference [25] in text" id="ref-25">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.25" data-doi="10.1523/JNEUROSCI.2453-17.2017">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Liu
                                  </span>
                                  <span class="cit-name-given-names">
                                   T
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Cable
                                  </span>
                                  <span class="cit-name-given-names">
                                   D
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gardner
                                  </span>
                                  <span class="cit-name-given-names">
                                   JL
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Inverted encoding models of human population response conflate noise and neural tuning width
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2018
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  38
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  398
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  408
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/JNEUROSCI.2453-17.2017
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.2453-17.2017%26rft_id%253Dinfo%253Apmid%252F29167406%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjg6IjM4LzIvMzk4IjtzOjQ6ImF0b20iO3M6NDg6Ii9iaW9yeGl2L2Vhcmx5LzIwMjIvMDQvMTUvMjAyMC4wMi4yNy45Njc1MDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [26].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-26-1" title="View reference [26] in text" id="ref-26">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.26" data-doi="10.1523/JNEUROSCI.21-20-08286.2001">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Blasdel
                                  </span>
                                  <span class="cit-name-given-names">
                                   G
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Campbell
                                  </span>
                                  <span class="cit-name-given-names">
                                   D
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Functional retinotopy of monkey visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2001
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  21
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  20
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  8286
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  8301
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DBlasdel%26rft.auinit1%253DG.%26rft.volume%253D21%26rft.issue%253D20%26rft.spage%253D8286%26rft.epage%253D8301%26rft.atitle%253DFunctional%2BRetinotopy%2Bof%2BMonkey%2BVisual%2BCortex%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.21-20-08286.2001%26rft_id%253Dinfo%253Apmid%252F11588200%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIyMS8yMC84Mjg2IjtzOjQ6ImF0b20iO3M6NDg6Ii9iaW9yeGl2L2Vhcmx5LzIwMjIvMDQvMTUvMjAyMC4wMi4yNy45Njc1MDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [27].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-27-1" title="View reference [27] in text" id="ref-27">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.27" data-doi="10.1093/cercor/13.1.70">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Freeman
                                  </span>
                                  <span class="cit-name-given-names">
                                   RD
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Cortical columns: a multi-parameter examination
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Cerebral Cortex
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2003
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  13
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  70
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  72
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCerebral%2BCortex%26rft.stitle%253DCereb%2BCortex%26rft.aulast%253DFreeman%26rft.auinit1%253DR.%2BD.%26rft.volume%253D13%26rft.issue%253D1%26rft.spage%253D70%26rft.epage%253D72%26rft.atitle%253DCortical%2BColumns%253A%2BA%2BMulti-parameter%2BExamination%26rft_id%253Dinfo%253Adoi%252F10.1093%252Fcercor%252F13.1.70%26rft_id%253Dinfo%253Apmid%252F12466217%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1093/cercor/13.1.70&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=12466217&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000179667500010&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [28].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-28-1" title="View reference [28] in text" id="ref-28">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.28" data-doi="10.1152/jn.2002.87.6.3126">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Landisman
                                  </span>
                                  <span class="cit-name-given-names">
                                   CE
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ts’o
                                  </span>
                                  <span class="cit-name-given-names">
                                   DY
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Color processing in macaque striate cortex: relationships to ocular dominance, cytochrome oxidase, and orientation
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neurophysiology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2002
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  87
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  6
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  3126
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  3137
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeurophysiology%26rft.stitle%253DJ.%2BNeurophysiol.%26rft.aulast%253DLandisman%26rft.auinit1%253DC.%2BE.%26rft.volume%253D87%26rft.issue%253D6%26rft.spage%253D3126%26rft.epage%253D3137%26rft.atitle%253DColor%2BProcessing%2Bin%2BMacaque%2BStriate%2BCortex%253A%2BRelationships%2Bto%2BOcular%2BDominance%252C%2BCytochrome%2BOxidase%252C%2Band%2BOrientation%26rft_id%253Dinfo%253Adoi%252F10.1152%252Fjn.2002.87.6.3126%26rft_id%253Dinfo%253Apmid%252F12037213%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1152/jn.2002.87.6.3126&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=12037213&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000175878900048&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [29].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-29-1" title="View reference [29] in text" id="ref-29">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.29" data-doi="10.1038/nn.3255">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Nauhaus
                                  </span>
                                  <span class="cit-name-given-names">
                                   I
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Nielsen
                                  </span>
                                  <span class="cit-name-given-names">
                                   KJ
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Disney
                                  </span>
                                  <span class="cit-name-given-names">
                                   AA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Callaway
                                  </span>
                                  <span class="cit-name-given-names">
                                   EM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Orthogonal micro-organization of orientation and spatial frequency in primate primary visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  15
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  12
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1683
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1690
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2Bneuroscience%26rft.stitle%253DNat%2BNeurosci%26rft.aulast%253DNauhaus%26rft.auinit1%253DI.%26rft.volume%253D15%26rft.issue%253D12%26rft.spage%253D1683%26rft.epage%253D1690%26rft.atitle%253DOrthogonal%2Bmicro-organization%2Bof%2Borientation%2Band%2Bspatial%2Bfrequency%2Bin%2Bprimate%2Bprimary%2Bvisual%2Bcortex.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnn.3255%26rft_id%253Dinfo%253Apmid%252F23143516%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nn.3255&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23143516&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [30].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-30-1" title="View reference [30] in text" id="ref-30">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.30" data-doi="10.1073/pnas.0804110105">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Yacoub
                                  </span>
                                  <span class="cit-name-given-names">
                                   E
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Harel
                                  </span>
                                  <span class="cit-name-given-names">
                                   N
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Uğurbil
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  High-field fMRI unveils orientation columns in humans
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Proceedings of the National Academy of Sciences
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  105
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  30
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  10607
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  10612
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DProceedings%2Bof%2Bthe%2BNational%2BAcademy%2Bof%2BSciences%26rft_id%253Dinfo%253Adoi%252F10.1073%252Fpnas.0804110105%26rft_id%253Dinfo%253Apmid%252F18641121%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NDoicG5hcyI7czo1OiJyZXNpZCI7czoxMjoiMTA1LzMwLzEwNjA3IjtzOjQ6ImF0b20iO3M6NDg6Ii9iaW9yeGl2L2Vhcmx5LzIwMjIvMDQvMTUvMjAyMC4wMi4yNy45Njc1MDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [31].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-31-1" title="View reference [31] in text" id="ref-31">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.31" data-doi="10.1038/nature03274">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ohki
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Chung
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ch’ng
                                  </span>
                                  <span class="cit-name-given-names">
                                   YH
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kara
                                  </span>
                                  <span class="cit-name-given-names">
                                   P
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Reid
                                  </span>
                                  <span class="cit-name-given-names">
                                   RC
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Functional imaging with cellular resolution reveals precise micro-architecture in visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  433
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  7026
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  597
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  603
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1038/nature03274
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%26rft.stitle%253DNature%26rft.aulast%253DOhki%26rft.auinit1%253DK.%26rft.volume%253D433%26rft.issue%253D7026%26rft.spage%253D597%26rft.epage%253D603%26rft.atitle%253DFunctional%2Bimaging%2Bwith%2Bcellular%2Bresolution%2Breveals%2Bprecise%2Bmicro-architecture%2Bin%2Bvisual%2Bcortex.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnature03274%26rft_id%253Dinfo%253Apmid%252F15660108%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nature03274&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=15660108&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000226862000035&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [32].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-32-1" title="View reference [32] in text" id="ref-32">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.32" data-doi="10.1523/JNEUROSCI.4042-04.2005">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Van Hooser
                                  </span>
                                  <span class="cit-name-given-names">
                                   SD
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Heimel
                                  </span>
                                  <span class="cit-name-given-names">
                                   JAF
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Chung
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Nelson
                                  </span>
                                  <span class="cit-name-given-names">
                                   SB
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Toth
                                  </span>
                                  <span class="cit-name-given-names">
                                   LJ
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Orientation selectivity without orientation maps in visual cortex of a highly visual mammal
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  25
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  19
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  28
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DVan%2BHooser%26rft.auinit1%253DS.%2BD.%26rft.volume%253D25%26rft.issue%253D1%26rft.spage%253D19%26rft.epage%253D28%26rft.atitle%253DOrientation%2BSelectivity%2Bwithout%2BOrientation%2BMaps%2Bin%2BVisual%2BCortex%2Bof%2Ba%2BHighly%2BVisual%2BMammal%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.4042-04.2005%26rft_id%253Dinfo%253Apmid%252F15634763%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjc6IjI1LzEvMTkiO3M6NDoiYXRvbSI7czo0ODoiL2Jpb3J4aXYvZWFybHkvMjAyMi8wNC8xNS8yMDIwLjAyLjI3Ljk2NzUwNS5hdG9tIjt9czo4OiJmcmFnbWVudCI7czowOiIiO30=" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [33].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-33-1" title="View reference [33] in text" id="ref-33">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.33">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Duyn
                                  </span>
                                  <span class="cit-name-given-names">
                                   JH
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The future of ultra-high field MRI and fMRI for study of the human brain
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  62
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1241
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1248
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.stitle%253DNeuroImage%26rft.aulast%253DDuyn%26rft.auinit1%253DJ.%2BH.%26rft.volume%253D62%26rft.issue%253D2%26rft.spage%253D1241%26rft.epage%253D1248%26rft.atitle%253DThe%2Bfuture%2Bof%2Bultra-high%2Bfield%2BMRI%2Band%2BfMRI%2Bfor%2Bstudy%2Bof%2Bthe%2Bhuman%2Bbrain.%26rft_id%253Dinfo%253Apmid%252F22063093%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=22063093&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [34].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-34-1" title="View reference [34] in text" id="ref-34">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.34" data-doi="10.1038/nature06976">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Logothetis
                                  </span>
                                  <span class="cit-name-given-names">
                                   NK
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  What we can do and what we cannot do with fMRI
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  453
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  7197
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  869
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  878
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1038/nature06976
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%26rft.stitle%253DNature%26rft.aulast%253DLogothetis%26rft.auinit1%253DN.%2BK.%26rft.volume%253D453%26rft.issue%253D7197%26rft.spage%253D869%26rft.epage%253D878%26rft.atitle%253DWhat%2Bwe%2Bcan%2Bdo%2Band%2Bwhat%2Bwe%2Bcannot%2Bdo%2Bwith%2BfMRI.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnature06976%26rft_id%253Dinfo%253Apmid%252F18548064%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nature06976&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=18548064&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000256632000033&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [35].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-35-1" title="View reference [35] in text" id="ref-35">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.35" data-doi="10.1038/nn0505-541">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Boynton
                                  </span>
                                  <span class="cit-name-given-names">
                                   GM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Imaging orientation selectivity: decoding conscious perception in V1
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  8
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  5
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  541
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  542
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2Bneuroscience%26rft.stitle%253DNat%2BNeurosci%26rft.aulast%253DBoynton%26rft.auinit1%253DG.%2BM.%26rft.volume%253D8%26rft.issue%253D5%26rft.spage%253D541%26rft.epage%253D542%26rft.atitle%253DImaging%2Borientation%2Bselectivity%253A%2Bdecoding%2Bconscious%2Bperception%2Bin%2BV1.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnn0505-541%26rft_id%253Dinfo%253Apmid%252F15856054%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nn0505-541&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=15856054&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000228895100004&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [36].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-36-1" title="View reference [36] in text" id="ref-36">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.36" data-doi="10.1038/nn1445">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Haynes
                                  </span>
                                  <span class="cit-name-given-names">
                                   JD
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Rees
                                  </span>
                                  <span class="cit-name-given-names">
                                   G
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Predicting the orientation of invisible stimuli from activity in human primary visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  8
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  5
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  686
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  691
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2Bneuroscience%26rft.stitle%253DNat%2BNeurosci%26rft.aulast%253DHaynes%26rft.auinit1%253DJ.%2BD.%26rft.volume%253D8%26rft.issue%253D5%26rft.spage%253D686%26rft.epage%253D691%26rft.atitle%253DPredicting%2Bthe%2Borientation%2Bof%2Binvisible%2Bstimuli%2Bfrom%2Bactivity%2Bin%2Bhuman%2Bprimary%2Bvisual%2Bcortex.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnn1445%26rft_id%253Dinfo%253Apmid%252F15852013%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nn1445&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=15852013&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000228895100031&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [37].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-37-1" title="View reference [37] in text" id="ref-37">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.37" data-doi="10.1038/nn1444">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kamitani
                                  </span>
                                  <span class="cit-name-given-names">
                                   Y
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Tong
                                  </span>
                                  <span class="cit-name-given-names">
                                   F
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Decoding the visual and subjective contents of the human brain
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2005
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  8
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  5
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  679
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  685
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1038/nn1444
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2Bneuroscience%26rft.stitle%253DNat%2BNeurosci%26rft.aulast%253DKamitani%26rft.auinit1%253DY.%26rft.volume%253D8%26rft.issue%253D5%26rft.spage%253D679%26rft.epage%253D685%26rft.atitle%253DDecoding%2Bthe%2Bvisual%2Band%2Bsubjective%2Bcontents%2Bof%2Bthe%2Bhuman%2Bbrain.%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnn1444%26rft_id%253Dinfo%253Apmid%252F15852014%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nn1444&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=15852014&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000228895100030&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [38].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-38-1" title="View reference [38] in text" id="ref-38">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.38" data-doi="10.1523/JNEUROSCI.5160-10.2011">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Freeman
                                  </span>
                                  <span class="cit-name-given-names">
                                   J
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Brouwer
                                  </span>
                                  <span class="cit-name-given-names">
                                   GJ
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Heeger
                                  </span>
                                  <span class="cit-name-given-names">
                                   DJ
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Merriam
                                  </span>
                                  <span class="cit-name-given-names">
                                   EP
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Orientation decoding depends on maps, not columns
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2011
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  31
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  13
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  4792
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  4804
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft.stitle%253DJ.%2BNeurosci.%26rft.aulast%253DFreeman%26rft.auinit1%253DJ.%26rft.volume%253D31%26rft.issue%253D13%26rft.spage%253D4792%26rft.epage%253D4804%26rft.atitle%253DOrientation%2BDecoding%2BDepends%2Bon%2BMaps%252C%2BNot%2BColumns%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.5160-10.2011%26rft_id%253Dinfo%253Apmid%252F21451017%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjEwOiIzMS8xMy80NzkyIjtzOjQ6ImF0b20iO3M6NDg6Ii9iaW9yeGl2L2Vhcmx5LzIwMjIvMDQvMTUvMjAyMC4wMi4yNy45Njc1MDUuYXRvbSI7fXM6ODoiZnJhZ21lbnQiO3M6MDoiIjt9" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [39].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-39-1" title="View reference [39] in text" id="ref-39">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.39" data-doi="10.1523/JNEUROSCI.2690-16.2016">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Wardle
                                  </span>
                                  <span class="cit-name-given-names">
                                   SG
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ritchie
                                  </span>
                                  <span class="cit-name-given-names">
                                   JB
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Seymour
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Carlson
                                  </span>
                                  <span class="cit-name-given-names">
                                   TA
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Edge-related activity is not necessary to explain orientation decoding in human visual cortex
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2017
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  37
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  5
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1187
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1196
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BNeuroscience%26rft_id%253Dinfo%253Adoi%252F10.1523%252FJNEUROSCI.2690-16.2016%26rft_id%253Dinfo%253Apmid%252F28003346%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Njoiam5ldXJvIjtzOjU6InJlc2lkIjtzOjk6IjM3LzUvMTE4NyI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [40].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-40-1" title="View reference [40] in text" id="ref-40">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.40" data-doi="10.1016/j.neuroimage.2015.12.012">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Walther
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Nili
                                  </span>
                                  <span class="cit-name-given-names">
                                   H
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ejaz
                                  </span>
                                  <span class="cit-name-given-names">
                                   N
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Alink
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Kriegeskorte
                                  </span>
                                  <span class="cit-name-given-names">
                                   N
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Diedrichsen
                                  </span>
                                  <span class="cit-name-given-names">
                                   J
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Reliability of dissimilarity measures for multi-voxel pattern analysis
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  NeuroImage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2016
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  137
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  188
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  200
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.neuroimage.2015.12.012
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroImage%26rft.volume%253D137%26rft.spage%253D188%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2015.12.012%26rft_id%253Dinfo%253Apmid%252F26707889%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2015.12.012&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=26707889&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [41].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-41-1" title="View reference [41] in text" id="ref-41">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.41" data-doi="10.1038/nn.4150">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Van Bergen
                                  </span>
                                  <span class="cit-name-given-names">
                                   RS
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ma
                                  </span>
                                  <span class="cit-name-given-names">
                                   WJ
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Pratte
                                  </span>
                                  <span class="cit-name-given-names">
                                   MS
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Jehee
                                  </span>
                                  <span class="cit-name-given-names">
                                   JFM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Sensory uncertainty decoded from visual cortex predicts behavior
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2015
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  18
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  12
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1728
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1730
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2BNeuroscience%26rft.volume%253D18%26rft.spage%253D1728%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fnn.4150%26rft_id%253Dinfo%253Apmid%252F26502262%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/nn.4150&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=26502262&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [42].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-42-1" title="View reference [42] in text" id="ref-42">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.42" data-doi="10.3389/fnins.2016.00190">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ritchie
                                  </span>
                                  <span class="cit-name-given-names">
                                   JB
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Carlson
                                  </span>
                                  <span class="cit-name-given-names">
                                   TA
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Neural decoding and “inner” psychophysics: A distance-to-bound approach for linking mind, brain, and behavior
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2016
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  10
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.3389/fnins.2016.00190
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DFrontiers%2Bin%2BNeuroscience%26rft.volume%253D10%26rft.spage%253D190%26rft_id%253Dinfo%253Adoi%252F10.3389%252Ffnins.2016.00190%26rft_id%253Dinfo%253Apmid%252F27199652%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.3389/fnins.2016.00190&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=27199652&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [43].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-43-1" title="View reference [43] in text" id="ref-43">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.43" data-doi="10.1371/journal.pone.0030549">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Fortmann-Roe
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Starfield
                                  </span>
                                  <span class="cit-name-given-names">
                                   R
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Getz
                                  </span>
                                  <span class="cit-name-given-names">
                                   WM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Contingent kernel density estimation
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  PLoS ONE
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  7
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  e30549
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1371/journal.pone.0030549
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.stitle%253DPLoS%2BONE%26rft.aulast%253DFortmann-Roe%26rft.auinit1%253DS.%26rft.volume%253D7%26rft.issue%253D2%26rft.spage%253De30549%26rft.epage%253De30549%26rft.atitle%253DContingent%2Bkernel%2Bdensity%2Bestimation.%26rft_id%253Dinfo%253Adoi%252F10.1371%252Fjournal.pone.0030549%26rft_id%253Dinfo%253Apmid%252F22383966%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1371/journal.pone.0030549&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=22383966&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [44].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-44-1" title="View reference [44] in text" id="ref-44">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.44" data-doi="10.1523/ENEURO.0363-18.2019">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gardner
                                  </span>
                                  <span class="cit-name-given-names">
                                   JL
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Liu
                                  </span>
                                  <span class="cit-name-given-names">
                                   T
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Inverted encoding models reconstruct an arbitrary model response, not the stimulus
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  eNeuro
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2019
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  6
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  e0363
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  18.2019
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1523/ENEURO.0363-18.2019
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DeNeuro%26rft_id%253Dinfo%253Adoi%252F10.1523%252FENEURO.0363-18.2019%26rft_id%253Dinfo%253Apmid%252F30923743%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6NjoiZW5ldXJvIjtzOjU6InJlc2lkIjtzOjIzOiI2LzIvRU5FVVJPLjAzNjMtMTguMjAxOSI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [45].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-45-1" title="View reference [45] in text" id="ref-45">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.45" data-doi="10.1016/j.jneumeth.2006.11.017">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Peirce
                                  </span>
                                  <span class="cit-name-given-names">
                                   JW
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  PsychoPy: psychophysics software in Python
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Neuroscience Methods
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2007
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  162
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1-2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  8
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  13
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2Bneuroscience%2Bmethods%26rft.stitle%253DJ%2BNeurosci%2BMethods%26rft.aulast%253DPeirce%26rft.auinit1%253DJ.%2BW.%26rft.volume%253D162%26rft.issue%253D1-2%26rft.spage%253D8%26rft.epage%253D13%26rft.atitle%253DPsychoPy--Psychophysics%2Bsoftware%2Bin%2BPython.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.jneumeth.2006.11.017%26rft_id%253Dinfo%253Apmid%252F17254636%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.jneumeth.2006.11.017&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=17254636&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000246429000002&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [46].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-46-1" title="View reference [46] in text" id="ref-46">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.46" data-doi="10.1016/j.neuroimage.2016.12.040">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Sengupta
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Yakupov
                                  </span>
                                  <span class="cit-name-given-names">
                                   R
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Speck
                                  </span>
                                  <span class="cit-name-given-names">
                                   O
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Pollmann
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Hanke
                                  </span>
                                  <span class="cit-name-given-names">
                                   M
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The effect of acquisition resolution on orientation decoding from V1 BOLD fMRI at 7T
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  NeuroImage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2017
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  148
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  64
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  76
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1016/j.neuroimage.2016.12.040
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroImage%26rft.volume%253D148%26rft.spage%253D64%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2016.12.040%26rft_id%253Dinfo%253Apmid%252F28063973%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2016.12.040&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=28063973&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [47].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-47-1" title="View reference [47] in text" id="ref-47">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.47" data-doi="10.1167/8.10.5">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Henriksson
                                  </span>
                                  <span class="cit-name-given-names">
                                   L
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Nurminen
                                  </span>
                                  <span class="cit-name-given-names">
                                   L
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Hyvärinen
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Vanni
                                  </span>
                                  <span class="cit-name-given-names">
                                   S
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Spatial frequency tuning in human retinotopic visual areas
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Vision
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  8
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  10
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  5
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1167/8.10.5
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BVision%26rft_id%253Dinfo%253Adoi%252F10.1167%252F8.10.5%26rft_id%253Dinfo%253Apmid%252F19146347%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/ijlink/YTozOntzOjQ6InBhdGgiO3M6MTQ6Ii9sb29rdXAvaWpsaW5rIjtzOjU6InF1ZXJ5IjthOjQ6e3M6ODoibGlua1R5cGUiO3M6NDoiQUJTVCI7czoxMToiam91cm5hbENvZGUiO3M6Mzoiam92IjtzOjU6InJlc2lkIjtzOjY6IjgvMTAvNSI7czo0OiJhdG9tIjtzOjQ4OiIvYmlvcnhpdi9lYXJseS8yMDIyLzA0LzE1LzIwMjAuMDIuMjcuOTY3NTA1LmF0b20iO31zOjg6ImZyYWdtZW50IjtzOjA6IiI7fQ==" class="cit-ref-sprinkles cit-ref-sprinkles-ijlink">
                                 <span>
                                  <span class="cit-reflinks-abstract">
                                   Abstract
                                  </span>
                                  <span class="cit-sep cit-reflinks-variant-name-sep">
                                   /
                                  </span>
                                  <span class="cit-reflinks-full-text">
                                   <span class="free-full-text">
                                    FREE
                                   </span>
                                   Full Text
                                  </span>
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [48].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-48-1" title="View reference [48] in text" id="ref-48">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.48" data-doi="10.1016/j.neuroimage.2007.10.033">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Hinds
                                  </span>
                                  <span class="cit-name-given-names">
                                   OP
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Rajendran
                                  </span>
                                  <span class="cit-name-given-names">
                                   N
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Polimeni
                                  </span>
                                  <span class="cit-name-given-names">
                                   JR
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Augustinack
                                  </span>
                                  <span class="cit-name-given-names">
                                   JC
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Wiggins
                                  </span>
                                  <span class="cit-name-given-names">
                                   G
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Wald
                                  </span>
                                  <span class="cit-name-given-names">
                                   LL
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-etal">
                                  et al.
                                 </span>
                                 <span class="cit-article-title">
                                  Accurate prediction of V1 location from cortical folds in a surface coordinate system
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2008
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  39
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  4
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  1585
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  1599
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroimage%26rft.volume%253D39%26rft.spage%253D1585%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2007.10.033%26rft_id%253Dinfo%253Apmid%252F18055222%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2007.10.033&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=18055222&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000253241800010&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [49].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-49-1" title="View reference [49] in text" id="ref-49">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.49" data-doi="10.1016/j.cub.2012.09.014">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Benson
                                  </span>
                                  <span class="cit-name-given-names">
                                   NC
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Butt
                                  </span>
                                  <span class="cit-name-given-names">
                                   OH
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Datta
                                  </span>
                                  <span class="cit-name-given-names">
                                   R
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Radoeva
                                  </span>
                                  <span class="cit-name-given-names">
                                   PD
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Brainard
                                  </span>
                                  <span class="cit-name-given-names">
                                   DH
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Aguirre
                                  </span>
                                  <span class="cit-name-given-names">
                                   GK
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  The retinotopic organization of striate cortex is well predicted by surface topology
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Current Biology
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  22
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  21
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  2081
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  2085
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DCurrent%2Bbiology%2B%253A%2B%2BCB%26rft.stitle%253DCurr%2BBiol%26rft.aulast%253DBenson%26rft.auinit1%253DN.%2BC.%26rft.volume%253D22%26rft.issue%253D21%26rft.spage%253D2081%26rft.epage%253D2085%26rft.atitle%253DThe%2Bretinotopic%2Borganization%2Bof%2Bstriate%2Bcortex%2Bis%2Bwell%2Bpredicted%2Bby%2Bsurface%2Btopology.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.cub.2012.09.014%26rft_id%253Dinfo%253Apmid%252F23041195%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.cub.2012.09.014&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23041195&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [50].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-50-1" title="View reference [50] in text" id="ref-50">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.50" data-doi="10.1016/j.neuroimage.2012.01.021">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Fischl
                                  </span>
                                  <span class="cit-name-given-names">
                                   B
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  FreeSurfer
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  62
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  774
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  781
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.stitle%253DNeuroImage%26rft.aulast%253DFischl%26rft.auinit1%253DB.%26rft.volume%253D62%26rft.issue%253D2%26rft.spage%253D774%26rft.epage%253D781%26rft.atitle%253DFreeSurfer.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2012.01.021%26rft_id%253Dinfo%253Apmid%252F22248573%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2012.01.021&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=22248573&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000306390600031&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [51].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-51-1" title="View reference [51] in text" id="ref-51">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.51">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gorgolewski
                                  </span>
                                  <span class="cit-name-given-names">
                                   K
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Burns
                                  </span>
                                  <span class="cit-name-given-names">
                                   CD
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Madison
                                  </span>
                                  <span class="cit-name-given-names">
                                   C
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Clark
                                  </span>
                                  <span class="cit-name-given-names">
                                   D
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Halchenko
                                  </span>
                                  <span class="cit-name-given-names">
                                   YO
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Waskom
                                  </span>
                                  <span class="cit-name-given-names">
                                   ML
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-etal">
                                  et al.
                                 </span>
                                 <span class="cit-article-title">
                                  Nipype: a flexible, lightweight and extensible neuroimaging data processing framework in python
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Frontiers in Neuroinformatics
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2011
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  5
                                 </span>
                                 :
                                 <span class="cit-issue">
                                  13
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [52].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-52-1" title="View reference [52] in text" id="ref-52">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.52" data-doi="10.1016/j.neuroimage.2011.09.015">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Jenkinson
                                  </span>
                                  <span class="cit-name-given-names">
                                   M
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Beckmann
                                  </span>
                                  <span class="cit-name-given-names">
                                   CF
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Behrens
                                  </span>
                                  <span class="cit-name-given-names">
                                   TE
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Woolrich
                                  </span>
                                  <span class="cit-name-given-names">
                                   MW
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Smith
                                  </span>
                                  <span class="cit-name-given-names">
                                   SM
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Fsl
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2012
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  62
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  2
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  782
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  790
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.stitle%253DNeuroImage%26rft.aulast%253DJenkinson%26rft.auinit1%253DM.%26rft.volume%253D62%26rft.issue%253D2%26rft.spage%253D782%26rft.epage%253D790%26rft.atitle%253DFSL.%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2011.09.015%26rft_id%253Dinfo%253Apmid%252F21979382%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2011.09.015&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=21979382&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000306390600032&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [53].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-53-1" title="View reference [53] in text" id="ref-53">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.53" data-doi="10.1016/j.neuroimage.2014.09.060">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Pedregosa
                                  </span>
                                  <span class="cit-name-given-names">
                                   F
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Eickenberg
                                  </span>
                                  <span class="cit-name-given-names">
                                   M
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ciuciu
                                  </span>
                                  <span class="cit-name-given-names">
                                   P
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Thirion
                                  </span>
                                  <span class="cit-name-given-names">
                                   B
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gramfort
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Data-driven HRF estimation for encoding and decoding models
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Neuroimage
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2015
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  104
                                 </span>
                                 :
                                 <span class="cit-fpage">
                                  209
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  220
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNeuroimage%26rft.volume%253D104%26rft.spage%253D209%26rft_id%253Dinfo%253Adoi%252F10.1016%252Fj.neuroimage.2014.09.060%26rft_id%253Dinfo%253Apmid%252F25304775%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1016/j.neuroimage.2014.09.060&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=25304775&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [54].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-54-1" title="View reference [54] in text" id="ref-54">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.54" data-doi="10.1524/auto.2011.0951">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Pedregosa
                                  </span>
                                  <span class="cit-name-given-names">
                                   F
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Varoquaux
                                  </span>
                                  <span class="cit-name-given-names">
                                   G
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Gramfort
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Michel
                                  </span>
                                  <span class="cit-name-given-names">
                                   V
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Thirion
                                  </span>
                                  <span class="cit-name-given-names">
                                   B
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Grisel
                                  </span>
                                  <span class="cit-name-given-names">
                                   O
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-etal">
                                  et al.
                                 </span>
                                 <span class="cit-article-title">
                                  Scikit-learn: Machine learning in Python
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Machine Learning Research
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2011
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  12
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  Oct
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  2825
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  2830
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BMachine%2BLearning%2BResearch%26rft.volume%253D12%26rft.spage%253D2825%26rft_id%253Dinfo%253Adoi%252F10.1524%252Fauto.2011.0951%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1524/auto.2011.0951&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [55].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-55-1" title="View reference [55] in text" id="ref-55">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.55" data-doi="10.1093/bioinformatics/btp211">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Knijnenburg
                                  </span>
                                  <span class="cit-name-given-names">
                                   TA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Wessels
                                  </span>
                                  <span class="cit-name-given-names">
                                   LFA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Reinders
                                  </span>
                                  <span class="cit-name-given-names">
                                   MJT
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Shmulevich
                                  </span>
                                  <span class="cit-name-given-names">
                                   I
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Fewer permutations, more accurate p-values
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Bioinformatics
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2009
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  25
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  12
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  i161
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  i168
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1093/bioinformatics/btp211
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DBioinformatics%26rft_id%253Dinfo%253Adoi%252F10.1093%252Fbioinformatics%252Fbtp211%26rft_id%253Dinfo%253Apmid%252F19477983%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1093/bioinformatics/btp211&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=19477983&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=000266498300021&link_type=ISI" class="cit-ref-sprinkles cit-ref-sprinkles-newisilink cit-ref-sprinkles-webofscience">
                                 <span>
                                  Web of Science
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [56].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-56-1" title="View reference [56] in text" id="ref-56">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-book" id="cit-2020.02.27.967505v2.56">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Soto
                                  </span>
                                  <span class="cit-name-given-names">
                                   FA
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ashby
                                  </span>
                                  <span class="cit-name-given-names">
                                   GF
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-chapter-title">
                                  Encoding models in neuroimaging
                                 </span>
                                 . In:
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ashby
                                  </span>
                                  <span class="cit-name-given-names">
                                   FG
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Colonius
                                  </span>
                                  <span class="cit-name-given-names">
                                   H
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Dzhafarov
                                  </span>
                                  <span class="cit-name-given-names">
                                   EN
                                  </span>
                                 </span>
                                 , editors.
                                 <span class="cit-source">
                                  The new handbook of mathematical psychology
                                 </span>
                                 . vol.
                                 <span class="cit-vol">
                                  3
                                 </span>
                                 .
                                 <span class="cit-publ-name">
                                  Cambridge University Press
                                 </span>
                                 ;
                                 <span class="cit-pub-date">
                                  2022
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [57].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-57-1" title="View reference [57] in text" id="ref-57">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.57" data-doi="10.1038/s41467-018-05957-0">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Alink
                                  </span>
                                  <span class="cit-name-given-names">
                                   A
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Abdulrahman
                                  </span>
                                  <span class="cit-name-given-names">
                                   H
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Henson
                                  </span>
                                  <span class="cit-name-given-names">
                                   RN
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  Forward models demonstrate that repetition suppression is best modelled by local neural scaling
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Nature Communications
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2018
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  9
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  1
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  3854
                                 </span>
                                 .
                                 <span class="cit-pub-id-sep cit-pub-id-doi-sep">
                                 </span>
                                 <span class="cit-pub-id-scheme">
                                  doi:
                                 </span>
                                 <span class="cit-pub-id cit-pub-id-doi">
                                  10.1038/s41467-018-05957-0
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DNature%2BCommunications%26rft.volume%253D9%26rft.spage%253D3854%26rft_id%253Dinfo%253Adoi%252F10.1038%252Fs41467-018-05957-0%26rft_id%253Dinfo%253Apmid%252F30242150%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1038/s41467-018-05957-0&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=30242150&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                             <li>
                              <span class="ref-label">
                               [58].
                              </span>
                              <a class="rev-xref-ref" href="#xref-ref-58-1" title="View reference [58] in text" id="ref-58">
                               ↵
                              </a>
                              <div class="cit ref-cit ref-journal" id="cit-2020.02.27.967505v2.58" data-doi="10.1162/jocn_a_00357">
                               <div class="cit-metadata">
                                <cite>
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Ester
                                  </span>
                                  <span class="cit-name-given-names">
                                   EF
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Anderson
                                  </span>
                                  <span class="cit-name-given-names">
                                   DE
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Serences
                                  </span>
                                  <span class="cit-name-given-names">
                                   JT
                                  </span>
                                 </span>
                                 ,
                                 <span class="cit-auth">
                                  <span class="cit-name-surname">
                                   Awh
                                  </span>
                                  <span class="cit-name-given-names">
                                   E
                                  </span>
                                 </span>
                                 .
                                 <span class="cit-article-title">
                                  A neural measure of precision in visual working memory
                                 </span>
                                 .
                                 <abbr class="cit-jnl-abbrev">
                                  Journal of Cognitive Neuroscience
                                 </abbr>
                                 .
                                 <span class="cit-pub-date">
                                  2013
                                 </span>
                                 ;
                                 <span class="cit-vol">
                                  25
                                 </span>
                                 (
                                 <span class="cit-issue">
                                  5
                                 </span>
                                 ):
                                 <span class="cit-fpage">
                                  754
                                 </span>
                                 –
                                 <span class="cit-lpage">
                                  761
                                 </span>
                                 .
                                </cite>
                               </div>
                               <div class="cit-extra">
                                <a href="{openurl}?query=rft.jtitle%253DJournal%2Bof%2BCognitive%2BNeuroscience%26rft.stitle%253DJ.%2BCogn.%2BNeurosci.%26rft.aulast%253DEster%26rft.auinit1%253DE.%2BF.%26rft.volume%253D25%26rft.spage%253D754%26rft.atitle%253DA%2BNeural%2BMeasure%2Bof%2BPrecision%2Bin%2BVisual%2BWorking%2BMemory.%26rft_id%253Dinfo%253Adoi%252F10.1162%252Fjocn_a_00357%26rft_id%253Dinfo%253Apmid%252F23469889%26rft.genre%253Darticle%26rft_val_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Ajournal%26ctx_ver%253DZ39.88-2004%26url_ver%253DZ39.88-2004%26url_ctx_fmt%253Dinfo%253Aofi%252Ffmt%253Akev%253Amtx%253Actx" class="cit-ref-sprinkles cit-ref-sprinkles-openurl cit-ref-sprinkles-open-url">
                                 <span>
                                  OpenUrl
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=10.1162/jocn_a_00357&link_type=DOI" class="cit-ref-sprinkles cit-ref-sprinkles-doi cit-ref-sprinkles-crossref">
                                 <span>
                                  CrossRef
                                 </span>
                                </a>
                                <a href="/lookup/external-ref?access_num=23469889&link_type=MED&atom=%2Fbiorxiv%2Fearly%2F2022%2F04%2F15%2F2020.02.27.967505.atom" class="cit-ref-sprinkles cit-ref-sprinkles-medline">
                                 <span>
                                  PubMed
                                 </span>
                                </a>
                               </div>
                              </div>
                             </li>
                            </ol>
                           </div>
                           <span class="highwire-journal-article-marker-end">
                           </span>
                          </div>
                          <span class="related-urls">
                          </span>
                         </div>
                        </div>
                       </div>
                      </div>
                     </div>
                    </div>
                   </div>
                  </div>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-disqus-comment">
                <div class="pane-content">
                 <div id="disqus_thread">
                  <noscript>
                   <p>
                    <a href="http://biorxivstage.disqus.com/?url=https%3A%2F%2Fwww.biorxiv.org%2Fcontent%2F10.1101%2F2020.02.27.967505v2" class="" data-icon-position="" data-hide-link-title="0">
                     View the discussion thread.
                    </a>
                   </p>
                  </noscript>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-highwire-back-to-top">
                <div class="pane-content">
                 <a href="#page" class="back-to-top" data-icon-position="" data-hide-link-title="0">
                  <span class="icon-chevron-up">
                  </span>
                  Back to top
                 </a>
                </div>
               </div>
              </div>
             </div>
            </div>
            <div class="sidebar-right-wrapper grid-10 omega">
             <div class="panel-panel panel-region-sidebar-right">
              <div class="inside">
               <div class="panel-pane pane-highwire-node-pager">
                <div class="pane-content">
                 <div class="pager highwire-pager pager-mini clearfix highwire-node-pager highwire-article-pager">
                  <span class="pager-prev">
                   <a href="/content/10.1101/2022.04.14.487730v1" title="Hormones do not make the mole-rat: no steroid hormone signatures of subordinate behavioral phenotypes" rel="prev" class="pager-link-prev link-icon">
                    <span class="icon-circle-arrow-left">
                    </span>
                    <span class="title">
                     Previous
                    </span>
                   </a>
                  </span>
                  <span class="pager-next">
                   <a href="/content/10.1101/2022.04.07.487155v2" title="A multiscale lipid and cellular atlas of the human kidney" rel="next" class="pager-link-next link-icon-right link-icon">
                    <span class="title">
                     Next
                    </span>
                    <span class="icon-circle-arrow-right">
                    </span>
                   </a>
                  </span>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-custom pane-1">
                <div class="pane-content">
                 Posted April 15, 2022.
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-panels-mini pane-biorxiv-art-tools">
                <div class="pane-content">
                 <div id="mini-panel-biorxiv_art_tools" class="highwire-2col-stacked panel-display">
                  <div class="panel-row-wrapper clearfix">
                   <div class="content-left-wrapper content-column">
                    <div class="panel-panel panel-region-content-left">
                     <div class="inside">
                      <div class="panel-pane pane-highwire-variant-link">
                       <div class="pane-content">
                        <a href="/content/10.1101/2020.02.27.967505v2.full.pdf" target="_self" class="article-dl-pdf-link link-icon">
                         <span class="icon-external-link-sign">
                         </span>
                         <span class="title">
                          Download PDF
                         </span>
                        </a>
                       </div>
                      </div>
                      <div class="panel-separator">
                      </div>
                      <div class="panel-pane pane-biorxiv-supplementary-fragment">
                       <div class="pane-content">
                        <p>
                         <a href="/content/10.1101/2020.02.27.967505v2.supplementary-material">
                          <i class="icon-file">
                          </i>
                          Supplementary Material
                         </a>
                        </p>
                       </div>
                      </div>
                     </div>
                    </div>
                   </div>
                   <div class="content-right-wrapper content-column">
                    <div class="panel-panel panel-region-content-right">
                     <div class="inside">
                      <div class="panel-pane pane-minipanel-dialog-link pane-biorxiv-art-email">
                       <div class="pane-content">
                        <div class="minipanel-dialog-wrapper">
                         <div class="minipanel-dialog-link-link">
                          <a href="/" oncontextmenu="javascript: return false;" class="minipanel-dialog-link-trigger" title="Email this Article" data-icon-position="" data-hide-link-title="0">
                           <i class="icon-envelope">
                           </i>
                           Email
                          </a>
                         </div>
                         <div class="minipanel-dialog-link-mini" style="display:none">
                          <div class="panel-display panel-1col clearfix" id="mini-panel-biorxiv_art_email">
                           <div class="panel-panel panel-col">
                            <div>
                             <div class="panel-pane pane-block pane-forward-form pane-forward">
                              <div class="pane-content">
                               <form action="/content/10.1101/2020.02.27.967505v2.full" method="post" id="forward-form" accept-charset="UTF-8">
                                <div>
                                 <div id="edit-instructions" class="form-item form-item-label-before form-type-item">
                                  <p>
                                   Thank you for your interest in spreading the word about bioRxiv.
                                  </p>
                                  <p>
                                   NOTE: Your email address is requested solely to identify you as the sender of this article.
                                  </p>
                                 </div>
                                 <div class="form-item form-item-label-before form-type-textfield form-item-email">
                                  <label for="edit-email">
                                   Your Email
                                   <span class="form-required" title="This field is required.">
                                    *
                                   </span>
                                  </label>
                                  <input type="text" id="edit-email" name="email" value="" size="58" maxlength="256" class="form-text required"/>
                                 </div>
                                 <div class="form-item form-item-label-before form-type-textfield form-item-name">
                                  <label for="edit-name">
                                   Your Name
                                   <span class="form-required" title="This field is required.">
                                    *
                                   </span>
                                  </label>
                                  <input type="text" id="edit-name" name="name" value="" size="58" maxlength="256" class="form-text required"/>
                                 </div>
                                 <div class="form-item form-item-label-before form-type-textarea form-item-recipients">
                                  <label for="edit-recipients">
                                   Send To
                                   <span class="form-required" title="This field is required.">
                                    *
                                   </span>
                                  </label>
                                  <div class="form-textarea-wrapper resizable">
                                   <textarea id="edit-recipients" name="recipients" cols="50" rows="5" class="form-textarea required"></textarea>
                                  </div>
                                  <div class="description">
                                   Enter multiple addresses on separate lines or separate them with commas.
                                  </div>
                                 </div>
                                 <div id="edit-page" class="form-item form-item-label-before form-type-item">
                                  <label for="edit-page">
                                   You are going to email the following
                                  </label>
                                  <a href="/content/10.1101/2020.02.27.967505v2" class="active" data-icon-position="" data-hide-link-title="0">
                                   Improving the validity of neuroimaging decoding tests of invariant and configural neural representation
                                  </a>
                                 </div>
                                 <div id="edit-subject" class="form-item form-item-label-before form-type-item">
                                  <label for="edit-subject">
                                   Message Subject
                                  </label>
                                  (Your Name) has forwarded a page to you from bioRxiv
                                 </div>
                                 <div id="edit-body" class="form-item form-item-label-before form-type-item">
                                  <label for="edit-body">
                                   Message Body
                                  </label>
                                  (Your Name) thought you would like to see this page from the bioRxiv website.
                                 </div>
                                 <div class="form-item form-item-label-before form-type-textarea form-item-message">
                                  <label for="edit-message--2">
                                   Your Personal Message
                                  </label>
                                  <div class="form-textarea-wrapper resizable">
                                   <textarea id="edit-message--2" name="message" cols="50" rows="10" class="form-textarea"></textarea>
                                  </div>
                                 </div>
                                 <input type="hidden" name="path" value="node/2498488"/>
                                 <input type="hidden" name="path_cid" value=""/>
                                 <input type="hidden" name="forward_footer" value=" "/>
                                 <input type="hidden" name="form_build_id" value="form-z8JETFpoHB5cTVuOvufEBbxjR3DoBQgZ3Mqie6k8baU"/>
                                 <input type="hidden" name="form_id" value="forward_form"/>
                                 <fieldset class="captcha form-wrapper">
                                  <legend>
                                   <span class="fieldset-legend">
                                    CAPTCHA
                                   </span>
                                  </legend>
                                  <div class="fieldset-wrapper">
                                   <div class="fieldset-description">
                                    This question is for testing whether or not you are a human visitor and to prevent automated spam submissions.
                                   </div>
                                   <input type="hidden" name="captcha_sid" value="484467410"/>
                                   <input type="hidden" name="captcha_token" value="f491dfb27fcd76707d97921215737d7f"/>
                                   <input type="hidden" name="captcha_response" value="Google no captcha"/>
                                   <div class="g-recaptcha" data-sitekey="6LfnJVIUAAAAAE-bUOMg0MJGki4lqSvDmhJp19fN" data-theme="light" data-type="image">
                                   </div>
                                  </div>
                                 </fieldset>
                                 <div class="form-actions form-wrapper" id="edit-actions">
                                  <input type="submit" id="edit-submit" name="op" value="Send Message" class="form-submit"/>
                                 </div>
                                </div>
                               </form>
                              </div>
                             </div>
                            </div>
                           </div>
                          </div>
                         </div>
                        </div>
                       </div>
                      </div>
                      <div class="panel-separator">
                      </div>
                      <div class="panel-pane pane-highwire-share-link highwire_clipboard_link_ajax" id="shareit">
                       <div class="pane-content">
                        <a href="/" class="link-icon">
                         <span class="icon-share-alt">
                         </span>
                         <span class="title">
                          Share
                         </span>
                        </a>
                       </div>
                      </div>
                      <div class="panel-separator">
                      </div>
                      <div class="panel-pane pane-panels-mini pane-biorxiv-share highwire_clipboard_form_ajax_shareit">
                       <div class="pane-content">
                        <div class="panel-display omega-12-onecol" id="mini-panel-biorxiv_share">
                         <div class="panel-panel grid-12 panel-region-preface">
                          <div class="inside">
                           <div class="panel-pane pane-highwire-article-citation">
                            <div class="pane-content">
                             <div class="highwire-article-citation highwire-citation-type-highwire-article node2498488--3" data-node-nid="2498488" id="node-2498488--426881956" data-pisa="biorxiv;2020.02.27.967505v2" data-pisa-master="biorxiv;2020.02.27.967505" data-seqnum="2498488" data-apath="/biorxiv/early/2022/04/15/2020.02.27.967505.atom">
                              <div class="highwire-cite highwire-cite-highwire-article highwire-citation-biorxiv-article-pap-list clearfix">
                               <div class="highwire-cite-title">
                                <div class="highwire-cite-title">
                                 Improving the validity of neuroimaging decoding tests of invariant and configural neural representation
                                </div>
                               </div>
                               <div class="highwire-cite-authors">
                                <span class="highwire-citation-authors">
                                 <span class="highwire-citation-author first" data-delta="0">
                                  <span class="nlm-given-names">
                                   Fabian A.
                                  </span>
                                  <span class="nlm-surname">
                                   Soto
                                  </span>
                                 </span>
                                 ,
                                 <span class="highwire-citation-author" data-delta="1">
                                  <span class="nlm-given-names">
                                   Sanjay
                                  </span>
                                  <span class="nlm-surname">
                                   Narasiwodeyar
                                  </span>
                                 </span>
                                </span>
                               </div>
                               <div class="highwire-cite-metadata">
                                <span class="highwire-cite-metadata-journal highwire-cite-metadata">
                                 bioRxiv
                                </span>
                                <span class="highwire-cite-metadata-pages highwire-cite-metadata">
                                 2020.02.27.967505;
                                </span>
                                <span class="highwire-cite-metadata-doi highwire-cite-metadata">
                                 <span class="doi_label">
                                  doi:
                                 </span>
                                 https://doi.org/10.1101/2020.02.27.967505
                                </span>
                               </div>
                              </div>
                             </div>
                            </div>
                           </div>
                          </div>
                         </div>
                         <div class="panel-panel grid-12 panel-region-content">
                          <div class="inside">
                           <div class="panel-pane pane-highwire-article-clipboard-copy">
                            <div class="pane-content">
                             <div class="clipboard-copy">
                              <span class="label-url">
                               <label for="dynamic">
                                Share This Article:
                               </label>
                              </span>
                              <span class="input-text-url">
                               <input type="text" id="dynamic" value="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2" size="50"/>
                              </span>
                              <span class="copy-button button">
                               <button id="copy-dynamic" class="clipboardjs-button" data-clipboard-target="#dynamic" data-clipboard-alert-style="tooltip" data-clipboard-alert-text="Copied!">
                                Copy
                               </button>
                              </span>
                             </div>
                            </div>
                           </div>
                          </div>
                         </div>
                         <div class="panel-panel grid-12 panel-region-postscript">
                          <div class="inside">
                           <div class="panel-pane pane-service-links">
                            <div class="pane-content">
                             <div class="service-links">
                              <a href="http://digg.com/submit?phase=2&url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&title=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="digg" title="Digg this post on digg.com" class="service-links-digg" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/digg.png" alt="Digg logo"/>
                              </a>
                              <a href="http://reddit.com/submit?url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&title=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="reddit" title="Submit this post on reddit.com" class="service-links-reddit" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/reddit.png" alt="Reddit logo"/>
                              </a>
                              <a href="http://twitter.com/share?url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&text=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="twitter" title="Share this on Twitter" class="service-links-twitter" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/twitter.png" alt="Twitter logo"/>
                              </a>
                              <a href="http://www.facebook.com/sharer.php?u=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&t=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="facebook" title="Share on Facebook" class="service-links-facebook" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/fb-blue.png" alt="Facebook logo"/>
                              </a>
                              <a href="http://www.google.com/bookmarks/mark?op=add&bkmk=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&title=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="google" title="Bookmark this post on Google" class="service-links-google" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/google-32.png" alt="Google logo"/>
                              </a>
                              <a href="http://www.linkedin.com/shareArticle?mini=true&url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&title=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation&summary=&source=bioRxiv" id="linkedin" title="Publish this post to LinkedIn" class="service-links-linkedin" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/linkedin-32px.png" alt="LinkedIn logo"/>
                              </a>
                              <a href="http://www.mendeley.com/import/?url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&title=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation" id="mendeley" title="Share on Mendeley" class="service-links-mendeley" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                               <img src="https://www.biorxiv.org/sites/all/modules/highwire/highwire/images/mendeley.png" alt="Mendeley logo"/>
                              </a>
                             </div>
                            </div>
                           </div>
                          </div>
                         </div>
                        </div>
                       </div>
                      </div>
                      <div class="panel-separator">
                      </div>
                      <div class="panel-pane pane-minipanel-dialog-link pane-biorxiv-cite-tool">
                       <div class="pane-content">
                        <div class="minipanel-dialog-wrapper">
                         <div class="minipanel-dialog-link-link">
                          <a href="/" oncontextmenu="javascript: return false;" class="minipanel-dialog-link-trigger link-icon" title="Citation Tools">
                           <span class="icon-globe">
                           </span>
                           <span class="title">
                            Citation Tools
                           </span>
                          </a>
                         </div>
                         <div class="minipanel-dialog-link-mini" style="display:none">
                          <div class="panel-display panel-1col clearfix" id="mini-panel-biorxiv_cite_tool">
                           <div class="panel-panel panel-col">
                            <div>
                             <div class="panel-pane pane-highwire-citation-export">
                              <div class="pane-content">
                               <div class="highwire-citation-export">
                                <div class="highwire-citation-info">
                                 <div class="highwire-article-citation highwire-citation-type-highwire-article cite-tool-node2498488--5" data-node-nid="2498488" id="citation-node-2498488--61449239481" data-pisa="biorxiv;2020.02.27.967505v2" data-pisa-master="biorxiv;2020.02.27.967505" data-seqnum="2498488" data-apath="/biorxiv/early/2022/04/15/2020.02.27.967505.atom">
                                  <div class="highwire-cite highwire-cite-highwire-article highwire-citation-biorxiv-article-pap-list clearfix">
                                   <div class="highwire-cite-title">
                                    <div class="highwire-cite-title">
                                     Improving the validity of neuroimaging decoding tests of invariant and configural neural representation
                                    </div>
                                   </div>
                                   <div class="highwire-cite-authors">
                                    <span class="highwire-citation-authors">
                                     <span class="highwire-citation-author first" data-delta="0">
                                      <span class="nlm-given-names">
                                       Fabian A.
                                      </span>
                                      <span class="nlm-surname">
                                       Soto
                                      </span>
                                     </span>
                                     ,
                                     <span class="highwire-citation-author" data-delta="1">
                                      <span class="nlm-given-names">
                                       Sanjay
                                      </span>
                                      <span class="nlm-surname">
                                       Narasiwodeyar
                                      </span>
                                     </span>
                                    </span>
                                   </div>
                                   <div class="highwire-cite-metadata">
                                    <span class="highwire-cite-metadata-journal highwire-cite-metadata">
                                     bioRxiv
                                    </span>
                                    <span class="highwire-cite-metadata-pages highwire-cite-metadata">
                                     2020.02.27.967505;
                                    </span>
                                    <span class="highwire-cite-metadata-doi highwire-cite-metadata">
                                     <span class="doi_label">
                                      doi:
                                     </span>
                                     https://doi.org/10.1101/2020.02.27.967505
                                    </span>
                                   </div>
                                  </div>
                                 </div>
                                </div>
                                <div class="highwire-citation-formats">
                                 <h2>
                                  Citation Manager Formats
                                 </h2>
                                 <div class="highwire-citation-formats-links">
                                  <span class="Z3988" title="ctx_ver=Z39.88-2004&rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&rft.spage&rft.epage&rft.atitle=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation&rft.volume&rft.issue&rft.date=2022-01-01%2000%3A00%3A00&rft.stitle&rft.jtitle=bioRxiv&rft.au=Soto%2C+Fabian+A.&rft.au=Narasiwodeyar%2C+Sanjay">
                                  </span>
                                  <ul class="hw-citation-links inline button button-alt button-grid clearfix">
                                   <li class="bibtext first">
                                    <a href="/highwire/citation/2498488/bibtext" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     BibTeX
                                    </a>
                                   </li>
                                   <li class="bookends">
                                    <a href="/highwire/citation/2498488/bookends" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Bookends
                                    </a>
                                   </li>
                                   <li class="easybib">
                                    <a href="/highwire/citation/2498488/easybib" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     EasyBib
                                    </a>
                                   </li>
                                   <li class="endnote-tagged">
                                    <a href="/highwire/citation/2498488/endnote-tagged" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     EndNote (tagged)
                                    </a>
                                   </li>
                                   <li class="endnote-8-xml">
                                    <a href="/highwire/citation/2498488/endnote-8-xml" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     EndNote 8 (xml)
                                    </a>
                                   </li>
                                   <li class="medlars">
                                    <a href="/highwire/citation/2498488/medlars" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Medlars
                                    </a>
                                   </li>
                                   <li class="mendeley">
                                    <a href="/highwire/citation/2498488/mendeley" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Mendeley
                                    </a>
                                   </li>
                                   <li class="papers">
                                    <a href="/highwire/citation/2498488/papers" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Papers
                                    </a>
                                   </li>
                                   <li class="refworks-tagged">
                                    <a href="/highwire/citation/2498488/refworks-tagged" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     RefWorks Tagged
                                    </a>
                                   </li>
                                   <li class="reference-manager">
                                    <a href="/highwire/citation/2498488/reference-manager" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Ref Manager
                                    </a>
                                   </li>
                                   <li class="ris">
                                    <a href="/highwire/citation/2498488/ris" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     RIS
                                    </a>
                                   </li>
                                   <li class="zotero last">
                                    <a href="/highwire/citation/2498488/zotero" class="hw-download-citation-link" data-icon-position="" data-hide-link-title="0">
                                     Zotero
                                    </a>
                                   </li>
                                  </ul>
                                 </div>
                                </div>
                               </div>
                              </div>
                             </div>
                            </div>
                           </div>
                          </div>
                         </div>
                        </div>
                       </div>
                      </div>
                     </div>
                    </div>
                   </div>
                  </div>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-service-links">
                <div class="pane-content">
                 <div class="service-links">
                  <div class="item-list">
                   <ul>
                    <li class="first">
                     <a href="http://twitter.com/share?url=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&count=horizontal&via=&text=Improving%20the%20validity%20of%20neuroimaging%20decoding%20tests%20of%20invariant%20and%20configural%20neural%20representation&counturl=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2" class="twitter-share-button service-links-twitter-widget" id="twitter_widget" title="Tweet This" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                      <span class="element-invisible">
                       Tweet Widget
                      </span>
                     </a>
                    </li>
                    <li>
                     <a href="http://www.facebook.com/plugins/like.php?href=https%3A//www.biorxiv.org/content/10.1101/2020.02.27.967505v2&layout=button_count&show_faces=false&action=like&colorscheme=light&width=100&height=21&font=&locale=" id="facebook_like" title="I Like it" class="service-links-facebook-like" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                      <span class="element-invisible">
                       Facebook Like
                      </span>
                     </a>
                    </li>
                    <li class="last">
                     <a href="https://www.biorxiv.org/content/10.1101/2020.02.27.967505v2" id="google_plus_one" title="Plus it" class="service-links-google-plus-one" rel="nofollow" data-icon-position="" data-hide-link-title="0">
                      <span class="element-invisible">
                       Google Plus One
                      </span>
                     </a>
                    </li>
                   </ul>
                  </div>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-highwire-article-collections">
                <h2 class="pane-title">
                 Subject Area
                </h2>
                <div class="pane-content">
                 <div class="highwire-list-wrapper highwire-article-collections">
                  <div class="highwire-list">
                   <ul class="highwire-article-collection-term-list">
                    <li class="first last odd">
                     <span class="highwire-article-collection-term">
                      <a href="/collection/neuroscience" class="highlight" data-icon-position="" data-hide-link-title="0">
                       Neuroscience
                       <i class="icon-caret-right">
                       </i>
                      </a>
                     </span>
                    </li>
                   </ul>
                  </div>
                 </div>
                </div>
               </div>
               <div class="panel-separator">
               </div>
               <div class="panel-pane pane-panels-mini pane-biorxiv-subject-collections block-style-col2">
                <div class="pane-content">
                 <div class="panel-flexible panels-flexible-new clearfix" id="mini-panel-biorxiv_subject_collections">
                  <div class="panel-flexible-inside panels-flexible-new-inside">
                   <div class="panels-flexible-region panels-flexible-region-new-center panels-flexible-region-first panels-flexible-region-last">
                    <div class="inside panels-flexible-region-inside panels-flexible-region-new-center-inside panels-flexible-region-inside-first panels-flexible-region-inside-last">
                     <div class="panel-pane pane-snippet">
                      <div class="pane-content">
                       <div class="snippet biorxiv-subject-areas-table-title" id="biorxiv-subject-areas-table-title">
                        <div class="snippet-content">
                         <b>
                          Subject Areas
                         </b>
                        </div>
                       </div>
                      </div>
                     </div>
                     <div class="panel-separator">
                     </div>
                     <div class="panel-pane pane-snippet">
                      <div class="pane-content">
                       <div class="snippet biorxiv-subject-areas-view-papers" id="biorxiv-subject-areas-view-papers">
                        <div class="snippet-content">
                         <a href="/content/early/recent">
                          <strong>
                           All Articles
                          </strong>
                         </a>
                        </div>
                       </div>
                      </div>
                     </div>
                     <div class="panel-separator">
                     </div>
                     <div class="panel-pane pane-highwire-subject-collections">
                      <div class="pane-content">
                       <ul id="collection" class="collection highwire-list-expand">
                        <li class="outer collection depth-2 child first">
                         <div class="data-wrapper">
                          <a href="/collection/animal-behavior-and-cognition" class="" data-icon-position="" data-hide-link-title="0">
                           Animal Behavior and Cognition
                          </a>
                          <span class="article-count">
                           (4123)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/biochemistry" class="" data-icon-position="" data-hide-link-title="0">
                           Biochemistry
                          </a>
                          <span class="article-count">
                           (8837)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/bioengineering" class="" data-icon-position="" data-hide-link-title="0">
                           Bioengineering
                          </a>
                          <span class="article-count">
                           (6539)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/bioinformatics" class="" data-icon-position="" data-hide-link-title="0">
                           Bioinformatics
                          </a>
                          <span class="article-count">
                           (23503)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/biophysics" class="" data-icon-position="" data-hide-link-title="0">
                           Biophysics
                          </a>
                          <span class="article-count">
                           (11822)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/cancer-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Cancer Biology
                          </a>
                          <span class="article-count">
                           (9242)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/cell-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Cell Biology
                          </a>
                          <span class="article-count">
                           (13358)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/clinical-trials" class="" data-icon-position="" data-hide-link-title="0">
                           Clinical Trials
                          </a>
                          <span class="article-count">
                           (138)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/developmental-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Developmental Biology
                          </a>
                          <span class="article-count">
                           (7456)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/ecology" class="" data-icon-position="" data-hide-link-title="0">
                           Ecology
                          </a>
                          <span class="article-count">
                           (11438)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/epidemiology" class="" data-icon-position="" data-hide-link-title="0">
                           Epidemiology
                          </a>
                          <span class="article-count">
                           (2066)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/evolutionary-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Evolutionary Biology
                          </a>
                          <span class="article-count">
                           (15186)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/genetics" class="" data-icon-position="" data-hide-link-title="0">
                           Genetics
                          </a>
                          <span class="article-count">
                           (10460)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/genomics" class="" data-icon-position="" data-hide-link-title="0">
                           Genomics
                          </a>
                          <span class="article-count">
                           (14058)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/immunology" class="" data-icon-position="" data-hide-link-title="0">
                           Immunology
                          </a>
                          <span class="article-count">
                           (9196)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/microbiology" class="" data-icon-position="" data-hide-link-title="0">
                           Microbiology
                          </a>
                          <span class="article-count">
                           (22242)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/molecular-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Molecular Biology
                          </a>
                          <span class="article-count">
                           (8840)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/neuroscience" class="" data-icon-position="" data-hide-link-title="0">
                           Neuroscience
                          </a>
                          <span class="article-count">
                           (47702)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/paleontology" class="" data-icon-position="" data-hide-link-title="0">
                           Paleontology
                          </a>
                          <span class="article-count">
                           (352)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/pathology" class="" data-icon-position="" data-hide-link-title="0">
                           Pathology
                          </a>
                          <span class="article-count">
                           (1433)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/pharmacology-and-toxicology" class="" data-icon-position="" data-hide-link-title="0">
                           Pharmacology and Toxicology
                          </a>
                          <span class="article-count">
                           (2493)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/physiology" class="" data-icon-position="" data-hide-link-title="0">
                           Physiology
                          </a>
                          <span class="article-count">
                           (3742)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/plant-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Plant Biology
                          </a>
                          <span class="article-count">
                           (8103)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/scientific-communication-and-education" class="" data-icon-position="" data-hide-link-title="0">
                           Scientific Communication and Education
                          </a>
                          <span class="article-count">
                           (1439)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/synthetic-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Synthetic Biology
                          </a>
                          <span class="article-count">
                           (2230)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child">
                         <div class="data-wrapper">
                          <a href="/collection/systems-biology" class="" data-icon-position="" data-hide-link-title="0">
                           Systems Biology
                          </a>
                          <span class="article-count">
                           (6050)
                          </span>
                         </div>
                        </li>
                        <li class="outer collection depth-2 child last">
                         <div class="data-wrapper">
                          <a href="/collection/zoology" class="" data-icon-position="" data-hide-link-title="0">
                           Zoology
                          </a>
                          <span class="article-count">
                           (1259)
                          </span>
                         </div>
                        </li>
                       </ul>
                      </div>
                     </div>
                    </div>
                   </div>
                  </div>
                 </div>
                </div>
               </div>
              </div>
             </div>
            </div>
           </div>
          </div>
         </div>
        </div>
       </div>
      </div>
     </div>
    </div>
   </section>
  </div>
  <div class="region region-page-bottom" id="region-page-bottom">
   <div class="region-inner region-page-bottom-inner">
   </div>
  </div>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__VNH5GD8Zz7g6_hGCOZjVjdMndxxC6naiExSSJKX3k_A__kzmEdtbqCsJx5Z9yg2Qy0PptB__ufXm-TxUOl0KZzUw__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__2WRbxlwOW0MEUc_hSWU5MBepQg6Lch6O5SZwefpJ6IE__HCL0YQJqLkOhrLPZZYGqosGvtFsEHMGghHIkSx4y9vA__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js" defer="defer">
  </script>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__N7ERJBYsOWyRnJgyoM125_Aiez2MOJGaUofG1JdWWBg__2cpwCQ7-xzTVeVvg_KOzwA1jka23oWApDPpgjoZKDCY__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript" src="//d33xdlntwy0kbs.cloudfront.net/cshl_custom.js">
  </script>
  <script type="text/javascript" src="https://www.biorxiv.org/sites/default/files/advagg_js/js__BmqjBnkz3MgYCAoc25s1lDRMEjLhC3mEPVonUFIHi08__Unwv5-ZIuHBfFwytsjEx1niBVJ7n1T4lPws7VrkHXM4__9MyDscWUfs9SQBQB2wQzcEwFsvz4ksctP725Io-yBDU.js">
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
function euCookieComplianceLoadScripts() {}
//--&gt;&lt;!]]&gt;
  </script>
  <script type="text/javascript">
   &lt;!--//--&gt;&lt;![CDATA[//&gt;&lt;!--
var eu_cookie_compliance_cookie_name = "";
//--&gt;&lt;!]]&gt;
  </script>
 </body>
</html>
