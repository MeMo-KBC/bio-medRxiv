{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelfunction and model analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fonduer.supervision import Labeler\n",
    "from fonduer.features import Featurizer\n",
    "from fonduer.candidates.models import Candidate\n",
    "\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "from MeMoKBC.pipeline.utils import get_session, load_candidates, match_label_matrix\n",
    "from MeMoKBC.definitions.candidates import NameFullAbbr, NameAbbrTask\n",
    "from MeMoKBC.pipeline.lfs.name_short_long_lfs import short_long_lfs\n",
    "from MeMoKBC.pipeline.lfs.name_short_task_lfs import name_abbr_task_lfs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = get_session(db_name=\"pipeline2\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define candidates and Labeler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = [NameAbbrTask, NameFullAbbr]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load candidates and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train_NAT, L_train_NFA = match_label_matrix(session, candidates, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LF analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameFull + Abrreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NFA,\n",
    "    lfs=sorted(short_long_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NameAbbr + Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFAnalysis(\n",
    "    L_train_NAT,\n",
    "    lfs=sorted(name_abbr_task_lfs, key=lambda lf: lf.name)\n",
    ").lf_summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model analysis !! continue when LFs are ready !!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of models\n",
    "\n",
    "| Modelname | Candidate | description | n_epochs |\n",
    "| --------- | --------- | ----------- | -------- |\n",
    "| label_model_v1_NFA | NameFullAbbr | label model with random label functions | 500 |\n",
    "| label_model_v1_NFT | NameFullTask | label model with random label functions | 500 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "gen_model_NFT = LabelModel(cardinality=2)\n",
    "gen_model_NFA = LabelModel(cardinality=2)\n",
    "\n",
    "\n",
    "if Path(\"models/label_model_NFA_v1.pkl\").is_file() and Path(\"models/label_model_NFT_v1.pkl\").is_file():\n",
    "    gen_model_NFA.load(source=\"models/label_model_NFA_v1.pkl\")\n",
    "    gen_model_NFT.load(source=\"models/label_model_NFT_v1.pkl\")\n",
    "    print(\"Loaded Models\")\n",
    "else:\n",
    "    gen_model_NFT.fit(L_train_NFT, n_epochs=500, log_freq=100)\n",
    "    gen_model_NFT.save(\"models/label_model_NFT_v1.pkl\")\n",
    "\n",
    "    gen_model_NFA.fit(L_train_NFA, n_epochs=500, log_freq=100)\n",
    "    gen_model_NFA.save(\"models/label_model_NFA_v1.pkl\")\n",
    "    print(\"Fit and saved models\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating train marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals_NFA = gen_model_NFA.predict_proba(L_train_NFA)\n",
    "train_marginals_NFT = gen_model_NFT.predict_proba(L_train_NFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_figheight(4)\n",
    "fig.set_figwidth(12)\n",
    "fig.set_tight_layout(\"w_pad\")\n",
    "\n",
    "bins=20\n",
    "\n",
    "ax[0].hist(train_marginals_NFA[:, 0], bins=bins)\n",
    "ax[0].set_title(\"NFA(TRUE)\")\n",
    "\n",
    "ax[1].hist(train_marginals_NFT[:, 0], bins=bins)\n",
    "ax[1].set_title(\"NFT(TRUE)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate on LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_cands = load_candidates(session, split=1, candidate_list=candidates)\n",
    "\n",
    "L_dev_NFA, L_dev_NFT = labeler.get_label_matrices(dev_cands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extract words from train_cands and count them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# calculate the diff between true and false prediction probability of each candidate\n",
    "# the bigger the difference the more certain the model is\n",
    "# Example True = 0.4 False = 0.6\n",
    "# diff = 0.6 - 0.4 = 0.2 --> model is very unsure \n",
    "diffs = train_marginals_NFT.max(axis=1) - train_marginals_NFT.min(axis=1)\n",
    "\n",
    "# filter out all candidates where labelmodel is very unsure\n",
    "# unsure is a diff of smaller then 0.000001\n",
    "train_idxs = np.where(diffs > 0.2)[0].astype(np.int64)\n",
    "filtered = train_marginals_NFT[train_idxs, 1]\n",
    "\n",
    "# Cast continous values to binary for logistic regression model\n",
    "y = np.where(filtered > 0.5, 1, 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get feature matrix and filter with previous filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = Featurizer(session, candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_train_NFT = featurizer.get_feature_matrices(train_cands)[0]\n",
    "X = F_train_NFT[train_idxs, :]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, BayesianRidge\n",
    "\n",
    "clf = LogisticRegression(max_iter=200).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cands = load_candidates(session, 2, candidates)\n",
    "F_test_NFT = featurizer.get_feature_matrices(test_cands)[0]\n",
    "\n",
    "preds = clf.predict(F_test_NFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = BayesianRidge().fit(X.toarray(), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
